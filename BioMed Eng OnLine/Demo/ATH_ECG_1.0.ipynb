{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: ECG-MIT-BIH, https://www.physionet.org/content/mitdb/1.0.0/ \n",
    "        AAMI EC57: N-normal heartbeat; S-Supraventricular ectopic beat; V-Ventricular ectopic beat; F-Fushion beat\n",
    "        Dataset Statistics: \n",
    "        trainset：N = 14555， S = 1837, V = 3220, F = 388 (22 subjects)\n",
    "        testset：N = 14854， S = 944,  V = 3788, F = 414 (22 subjects)\n",
    "3.Performance Metric: \n",
    "  1)Accuracy(Acc):  for evaluating the precison of top 1 in the returned list;\n",
    "  2)Specificity(Spe): for evaluating the misdiagnosis rate of normal\n",
    "  3)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml(S,V,F)\n",
    "4.Algorithm: Attention-based Triplet Hashing Network(ATH), Cross-loss(Focal+Triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n"
     ]
    }
   ],
   "source": [
    "#read train image with CV\n",
    "train_dir = '/data/fjsdata/ECG/MIT-BIH/train' #the path of images\n",
    "trI, trY = [],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/fjsdata/ECG/MIT-BIH/test' #the path of images\n",
    "teI, teY = [],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf)\n",
    "trQ_sf, trP_sf, trN_sf = onlineGenImgPairs() #sample \n",
    "assert (trQ_sf.shape==trP_sf.shape)\n",
    "assert (trQ_sf.shape==trN_sf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.0843884Eopch:     1 mean_loss = 2.201908\n",
      " 2000 / 2000 : loss = 2.8193097Eopch:     2 mean_loss = 0.894042\n",
      " 2000 / 2000 : loss = 0.088306Eopch:     3 mean_loss = 0.397001\n",
      " 2000 / 2000 : loss = 0.7511359Eopch:     4 mean_loss = 0.247977\n",
      " 2000 / 2000 : loss = 0.067857Eopch:     5 mean_loss = 0.211742\n",
      " 2000 / 2000 : loss = 0.031822Eopch:     6 mean_loss = 0.120529\n",
      " 2000 / 2000 : loss = 0.0337641Eopch:     7 mean_loss = 0.116483\n",
      " 2000 / 2000 : loss = 0.014268Eopch:     8 mean_loss = 0.091599\n",
      " 2000 / 2000 : loss = 0.0417497Eopch:     9 mean_loss = 0.121599\n",
      " 2000 / 2000 : loss = 0.047742Eopch:    10 mean_loss = 0.055734\n",
      "best_loss = 0.055734\n",
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "Accuracy: 0.751500\n",
      "[[11378   464  2825   187]\n",
      " [  331   331   272    10]\n",
      " [  352    92  3305    39]\n",
      " [  262     1   135    16]]\n",
      "Specificity: 0.765989\n",
      "Sensitivity of S: 0.350636\n",
      "Sensitivity of V: 0.872492\n",
      "Sensitivity of F: 0.038647\n"
     ]
    }
   ],
   "source": [
    "#ATH-Triplet Loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.hash = nn.Sequential(\n",
    "            nn.Linear(16*128*128, hash_size),\n",
    "            nn.ReLU(inplace=True)#nn.Sigmoid()#nn.Tanh()\n",
    "        )\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hash(x)\n",
    "        return x_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "#define model\n",
    "model = ASHNet(hash_size=36).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define triplet loss\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance with hash\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.018829Eopch:     1 mean_loss = 0.179908\n",
      " 2000 / 2000 : loss = 0.028544Eopch:     2 mean_loss = 0.047202\n",
      " 2000 / 2000 : loss = 0.000724Eopch:     3 mean_loss = 0.020276\n",
      " 2000 / 2000 : loss = 0.001304Eopch:     4 mean_loss = 0.015025\n",
      " 2000 / 2000 : loss = 0.055858Eopch:     5 mean_loss = 0.011000\n",
      " 2000 / 2000 : loss = 0.001074Eopch:     6 mean_loss = 0.008110\n",
      " 2000 / 2000 : loss = 9.2e-056Eopch:     7 mean_loss = 0.003257\n",
      " 2000 / 2000 : loss = 0.000713Eopch:     8 mean_loss = 0.002618\n",
      " 2000 / 2000 : loss = 5.7e-053Eopch:     9 mean_loss = 0.004282\n",
      " 2000 / 2000 : loss = 0.006657Eopch:    10 mean_loss = 0.001906\n",
      "best_loss = 0.001906\n",
      " 1999 / 2000 Accuracy: 0.766200\n",
      "[[11921   263  2636    34]\n",
      " [  501   210   233     0]\n",
      " [  483   104  3193     8]\n",
      " [  306     4   104     0]]\n",
      "Specificity: 0.802545\n",
      "Sensitivity of S: 0.222458\n",
      "Sensitivity of V: 0.842925\n",
      "Sensitivity of F: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#ATH-CE Loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(16*128*128, class_size),\n",
    "            #nn.ReLU(inplace=True)#nn.Sigmoid()#nn.Tanh()\n",
    "        )\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_class = self.dense(x)\n",
    "        return x_class\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "    \n",
    "#define model\n",
    "model = ASHNet(class_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_batch.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.009352Eopch:     1 mean_loss = 0.365388\n",
      " 2000 / 2000 : loss = 0.130224Eopch:     2 mean_loss = 0.055437\n",
      " 2000 / 2000 : loss = 0.000106Eopch:     3 mean_loss = 0.033067\n",
      " 2000 / 2000 : loss = 3e-06057Eopch:     4 mean_loss = 0.025777\n",
      " 2000 / 2000 : loss = 0.000155Eopch:     5 mean_loss = 0.016148\n",
      " 2000 / 2000 : loss = 4e-06491Eopch:     6 mean_loss = 0.015006\n",
      " 2000 / 2000 : loss = 2.3e-057Eopch:     7 mean_loss = 0.008080\n",
      " 2000 / 2000 : loss = 3e-06507Eopch:     8 mean_loss = 0.010156\n",
      " 2000 / 2000 : loss = 5e-06156Eopch:     9 mean_loss = 0.004989\n",
      " 2000 / 2000 : loss = 8.4e-052Eopch:    10 mean_loss = 0.006018\n",
      "best_loss = 0.004989\n",
      " 1999 / 2000 Accuracy: 0.718300\n",
      "[[10663   371  3790    30]\n",
      " [  411   163   369     1]\n",
      " [  220    25  3540     3]\n",
      " [  266     5   143     0]]\n",
      "Specificity: 0.717854\n",
      "Sensitivity of S: 0.172669\n",
      "Sensitivity of V: 0.934530\n",
      "Sensitivity of F: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#Resnet CE Loss\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #fully connected\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(16*128*128, class_size),\n",
    "            #nn.ReLU(inplace=True)#nn.Sigmoid()#nn.Tanh()\n",
    "        )\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_class = self.dense(x)\n",
    "        return x_class\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "    \n",
    "#define model\n",
    "model = ResNet(class_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_batch.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.004956Eopch:     1 mean_loss = 0.065076\n",
      " 2000 / 2000 : loss = 0.000564Eopch:     2 mean_loss = 0.004498\n",
      " 2000 / 2000 : loss = 0.000259Eopch:     3 mean_loss = 0.002403\n",
      " 2000 / 2000 : loss = 2e-06103Eopch:     4 mean_loss = 0.003098\n",
      " 2000 / 2000 : loss = 0.000245Eopch:     5 mean_loss = 0.003271\n",
      " 2000 / 2000 : loss = 0.001885Eopch:     6 mean_loss = 0.001760\n",
      " 2000 / 2000 : loss = 1.4e-053Eopch:     7 mean_loss = 0.000738\n",
      " 2000 / 2000 : loss = 0.050783Eopch:     8 mean_loss = 0.030995\n",
      " 2000 / 2000 : loss = 0.000288Eopch:     9 mean_loss = 0.003126\n",
      " 2000 / 2000 : loss = 4e-06056Eopch:    10 mean_loss = 0.000267\n",
      "best_loss = 0.000267\n",
      " 1999 / 2000 Accuracy: 0.775100\n",
      "[[12489   127  2227    11]\n",
      " [  642    99   202     1]\n",
      " [  754   117  2914     3]\n",
      " [  355     0    59     0]]\n",
      "Specificity: 0.840784\n",
      "Sensitivity of S: 0.104873\n",
      "Sensitivity of V: 0.769271\n",
      "Sensitivity of F: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#Resnet Focal Loss\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #fully connected\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(16*128*128, class_size),\n",
    "            #nn.ReLU(inplace=True)#nn.Sigmoid()#nn.Tanh()\n",
    "        )\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_class = self.dense(x)\n",
    "        return x_class\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "        \n",
    "#define model\n",
    "model = ResNet(class_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = FocalLoss(gamma=2,alpha=[0.7,0.1,0.15,0.05]).cuda() #define focal loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_batch.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 36.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare data，classes=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()[0:100]\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()[0:100]\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()[0:100]\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()[0:100]\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f450892d490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADXCAYAAAC51IK9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADlUlEQVR4nO3bMYoVQRRA0WoZUDBxcBOGgjBiqO7CjbgRtyOGYuBSRBNhjMoN2AX9aa4w/5z00fCiG1R1bXPOAUDj0f9eAOCaiC5ASHQBQqILEBJdgJDoAoRuVsPtzfA/GcBB8+vY9mbL6I6Xp+8CcNXW0X0RbQFwJbbVi7Qv473jBYCD3o7Pu8cLy+j+HM9FF+Cg2/HjsjPdX+PZ+dsAPHC3i9kyuvfjycmrAFw30QUIeRwBEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgNA259wffhv7QwD+ab4e295sHd3tu+gCHDTnq8uiO/5sogtw1ON5WXR/b6ILcNTTuR/dm9WHn87fBeDB+7iYLaP7bt6dvArAdVtG9277UO0B8GCsrsrWF2kAnMrjCICQ6AKERBcgJLoAIdEFCIkuQOgvHTE5GzQUTo8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    " \n",
    "# normalizing the output\n",
    "def normalize_output(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "image_path = '/data/tmpexec/ecg/test/9929-2.png' #V:Ventricular ectopic beat\n",
    "oriImg = cv2.imread(image_path)\n",
    "height, width, _ = oriImg.shape\n",
    "#plt.axis('off')\n",
    "#plt.imshow(oriImg)\n",
    "data = []\n",
    "oriImg = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "data.append(oriImg)\n",
    "data = torch.from_numpy(np.array(data)).type(torch.FloatTensor).cuda() \n",
    "\n",
    "activation = {}\n",
    "best_net.sa.register_forward_hook(get_activation('sa'))#spatial attention\n",
    "output = best_net(data.permute(0, 3, 1, 2))\n",
    "feature = activation['sa'].squeeze()\n",
    "feature_0 = feature[0].cpu().numpy()\n",
    "feature_0 = normalize_output(feature_0)\n",
    "feature_0 = np.uint8(255 * feature_0)\n",
    "#plot\n",
    "featuremap = cv2.applyColorMap(cv2.resize(feature_0,(width, height)), cv2.COLORMAP_JET)\n",
    "plt.axis('off')\n",
    "plt.imshow(featuremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py   \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#define FocalLoss gamma=[0,0.5,1,2,5] alpha=[0.25,0.25,0.25,0.25,0.25]\n",
    "criterion  = FocalLoss(gamma=2).cuda() \n",
    "#train model with focal loss\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _, out_class = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_class, y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#performance with class\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    _, out_class = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_class.cpu().data.numpy().tolist()) #record feature\n",
    "    out_class = F.log_softmax(out_class,dim=1) \n",
    "    pred = out_class.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1999 / 2000 Completed buliding index in 24 seconds\n",
      "mHR@5=0.767000, mAP@5=0.755568, mRR@5=0.969637\n",
      "mHR@10=0.767155, mAP@10=0.752808, mRR@10=0.959251\n",
      "mHR@15=0.766840, mAP@15=0.751467, mRR@15=0.952275\n",
      "mHR@20=0.766660, mAP@20=0.750577, mRR@20=0.948231\n",
      " 1999 / 2000 Accuracy: 0.619650\n",
      "[[8303 1254 4892  397    0]\n",
      " [ 149  350  430   15    0]\n",
      " [  26   10 3687   65    0]\n",
      " [ 165    8  188   53    0]\n",
      " [   0    2    6    0    0]]\n",
      "Specificity: 0.559275\n",
      "Sensitivity of S: 0.370763\n",
      "Sensitivity of V: 0.973337\n",
      "Sensitivity of F: 0.128019\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance with hash\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.000080108642578\n",
      "net.0.net.0.weight\n",
      "tensor([0.1009, 0.1183, 0.0598], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.973249435424805\n",
      "net.0.net.0.weight\n",
      "tensor([0.1016, 0.1175, 0.0605], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.716821670532227\n",
      "net.0.net.0.weight\n",
      "tensor([0.1024, 0.1167, 0.0607], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.584300994873047\n",
      "net.0.net.0.weight\n",
      "tensor([0.1027, 0.1160, 0.0608], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.504169464111328\n",
      "net.0.net.0.weight\n",
      "tensor([0.1026, 0.1154, 0.0610], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.44349479675293\n",
      "net.0.net.0.weight\n",
      "tensor([0.1025, 0.1150, 0.0611], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.424943923950195\n",
      "net.0.net.0.weight\n",
      "tensor([0.1025, 0.1145, 0.0611], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.4094181060791\n",
      "net.0.net.0.weight\n",
      "tensor([0.1024, 0.1139, 0.0610], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.38896369934082\n",
      "net.0.net.0.weight\n",
      "tensor([0.1023, 0.1132, 0.0609], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.37741470336914\n",
      "net.0.net.0.weight\n",
      "tensor([0.1020, 0.1127, 0.0609], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "torch.Size([10, 36])\n"
     ]
    }
   ],
   "source": [
    "#test network: valid\n",
    "xq = torch.rand(10,3,256,256).cuda()\n",
    "xp = torch.rand(10,3,256,256).cuda()\n",
    "xn = torch.rand(10,3,256,256).cuda()\n",
    "model = ASHNet(hash_size=36, class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define pairwise loss\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outq,_ = model(xq)#out.grad_fn\n",
    "    outp,_ = model(xp)\n",
    "    outn,_ = model(xn)\n",
    "    loss = criterion(outq,outp,outn)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x = torch.rand(10,3,256,256).cuda()\n",
    "out,_ = model(x)\n",
    "#out = torch.sign(out) #Binarization,[-1,1]->{-1,1}\n",
    "print (out.size())\n",
    "x = x.cpu()\n",
    "xq = xq.cpu()\n",
    "xp = xp.cpu()\n",
    "xn = xn.cpu()\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of DS1 is: (20000,360)\n",
      "0    14854\n",
      "2     3788\n",
      "1      944\n",
      "3      414\n",
      "Name: 1, dtype: int64\n",
      "The shape of DS2 is: (20000,360)\n",
      "0    14555\n",
      "2     3220\n",
      "1     1837\n",
      "3      388\n",
      "Name: 1, dtype: int64\n",
      "Completed buliding index in 24 seconds\n",
      "Accuracy: 0.807700\n",
      "[[12810   419  1340   285]\n",
      " [  638   148   151     7]\n",
      " [  518    79  3158    33]\n",
      " [  277     1    98    38]]\n",
      "Specificity: 0.862394\n",
      "Sensitivity of S: 0.156780\n",
      "Sensitivity of V: 0.833685\n",
      "Sensitivity of F: 0.091787\n"
     ]
    }
   ],
   "source": [
    "#Beats generation,\n",
    "#we defined a single ECG beat image by centering the Q-wave peak signal while\n",
    "#excluding the first and the last 20 ECG signals from the previous and afterward Q-wave peak signal\n",
    "#https://github.com/MIT-LCP/wfdb-python/blob/master/demo.ipynb\n",
    "#https://archive.physionet.org/physiobank/database/html/mitdbdir/mitdbdir.htm\n",
    "#http://www.tara.tcd.ie/bitstream/handle/2262/17623/automatic.pdf?sequence=1\n",
    "def labeltotext(val):\n",
    "    if val in ['N','L','R','e','j'] :\n",
    "        return 0 #N\n",
    "    elif val in ['A','a','J','S']:\n",
    "        return 1 #S\n",
    "    elif val in ['V','E']:\n",
    "        return 2 #V\n",
    "    elif val == 'F':\n",
    "        return 3 #F\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "rootdir = '/data/fjsdata/physionet/MIT-BIH/mitdb/'\n",
    "right_len = 180 #right sample length around of peak value of QRS\n",
    "left_len = 180 #left sample length around of peak value of QRS\n",
    "#get trainset\n",
    "trData = [] #[QRS value, label]\n",
    "for bt in [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]:#22 records for train\n",
    "    file = os.path.join(rootdir,str(bt))\n",
    "    try:\n",
    "        annotation = wfdb.rdann(file, 'atr') \n",
    "        qrs_spl = annotation.sample #numpy.ndarray\n",
    "        qrs_sym = annotation.symbol #list\n",
    "        record = wfdb.rdrecord(file)\n",
    "        signal = record.p_signal #numpy.ndarray\n",
    "        max_len = record.sig_len #length of samples\n",
    "        lead_name =  record.sig_name #names of lead channels,list\n",
    "        for i in range(annotation.ann_len):\n",
    "            if qrs_sym[i] in ['N','L','R','e','j','A','a','J','S','V','E','F']:#seven diseases samples\n",
    "                pos = qrs_spl[i] #corresponding position of peak value of QRS\n",
    "                if pos+right_len<=max_len and pos-left_len>=0:\n",
    "                    max_idx = pos+right_len#np.min([max_len, pos+trunc_len])\n",
    "                    min_idx = pos-left_len#np.max([0, pos-trunc_len])\n",
    "                    QRS_value = signal[:,0][min_idx:max_idx] #only one lead\n",
    "                    trData.append([QRS_value,labeltotext(qrs_sym[i])])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "NOR = 14854 #normal samples    \n",
    "trData = pd.DataFrame(np.array(trData))\n",
    "NData =  trData[trData[1]==0].sample(n=NOR, random_state=1)\n",
    "UNData = trData[trData[1]!=0]\n",
    "trData = pd.concat([NData,UNData],axis=0).sample(frac=1) #shuffle\n",
    "X_DS1 = pd.DataFrame(trData[0].values.tolist())\n",
    "y_DS1 = trData[1]\n",
    "print('The shape of DS1 is: (%d,%d)'%(X_DS1.shape[0],X_DS1.shape[1]))\n",
    "print(trData[1].value_counts())\n",
    "\n",
    "#get testset\n",
    "teData = [] #[QRS value, label]\n",
    "for bt in [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]:#22 records for test\n",
    "    file = os.path.join(rootdir,str(bt))\n",
    "    try:\n",
    "        annotation = wfdb.rdann(file, 'atr') \n",
    "        qrs_spl = annotation.sample #numpy.ndarray\n",
    "        qrs_sym = annotation.symbol #list\n",
    "        record = wfdb.rdrecord(file)\n",
    "        signal = record.p_signal #numpy.ndarray\n",
    "        max_len = record.sig_len #length of samples\n",
    "        lead_name =  record.sig_name #names of lead channels,list\n",
    "        for i in range(annotation.ann_len):\n",
    "            if qrs_sym[i] in ['N','L','R','e','j','A','a','J','S','V','E','F']:#seven diseases samples\n",
    "                pos = qrs_spl[i] #corresponding position of peak value of QRS\n",
    "                if pos+right_len<=max_len and pos-left_len>=0:\n",
    "                    max_idx = pos+right_len#np.min([max_len, pos+trunc_len])\n",
    "                    min_idx = pos-left_len#np.max([0, pos-trunc_len])\n",
    "                    QRS_value = signal[:,0][min_idx:max_idx] #only one lead\n",
    "                    teData.append([QRS_value,labeltotext(qrs_sym[i])])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "NOR = 14555 #normal samples    \n",
    "teData = pd.DataFrame(np.array(teData))\n",
    "NData =  teData[teData[1]==0].sample(n=NOR, random_state=1)\n",
    "UNData = teData[teData[1]!=0]\n",
    "teData = pd.concat([NData,UNData],axis=0).sample(frac=1) #shuffle\n",
    "X_DS2 = pd.DataFrame(teData[0].values.tolist())\n",
    "y_DS2 = teData[1]\n",
    "print('The shape of DS2 is: (%d,%d)'%(X_DS2.shape[0],X_DS2.shape[1]))\n",
    "print(teData[1].value_counts())\n",
    "\n",
    "#model: faiss+index\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(right_len+left_len) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(X_DS2, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(X_DS1, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(y_DS2)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(y_DS1.tolist(), y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(y_DS1))\n",
    "cm = confusion_matrix(y_DS1.tolist(), y_pred, labels=labels ) #labels=['N','S','V','F']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999 / 20000 "
     ]
    }
   ],
   "source": [
    "#import ecg_plot#pip install ecg_plot, https://pypi.org/project/ecg-plot/\n",
    "#from scipy.misc import electrocardiogram \n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.electrocardiogram.html\n",
    "fs = 360\n",
    "for idx,row in X_DS2.iterrows():\n",
    "    label = np.array(y_DS2)[idx]\n",
    "    svpath = os.path.join('/data/fjsdata/ECG/MIT-BIH/train',str(idx)+'-'+str(label))\n",
    "    ecg = np.array(row)\n",
    "    time = np.arange(ecg.size) / fs\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(time, ecg)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(svpath,dpi=100) #(500=5*100,300=3*100)\n",
    "    plt.close()\n",
    "    sys.stdout.write('\\r{} / {} '.format(idx,X_DS2.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "for idx,row in X_DS1.iterrows():\n",
    "    label = np.array(y_DS1)[idx]\n",
    "    svpath = os.path.join('/data/fjsdata/ECG/MIT-BIH/test',str(idx)+'-'+str(label))\n",
    "    ecg = np.array(row)\n",
    "    time = np.arange(ecg.size) / fs\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(time, ecg)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(svpath,dpi=100) #(500=5*100,300=3*100)\n",
    "    plt.close()\n",
    "    sys.stdout.write('\\r{} / {} '.format(idx,X_DS1.shape[0]))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
