{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993, \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777\n",
    "3.Performance Metric for unbalanced sample(triplet loss): \n",
    "  1)AUC (Area Under Curve);\n",
    "  2)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml\n",
    "4.Performance Metric for retrieval (Spatial Attention Mechanism):\n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "5.Algorithm: Attention-based Triplet Hashing Network(ATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "import gc\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score  \n",
    "from functools import reduce\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, type_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.hashlayer = nn.Linear(1*32*32, hash_size)\n",
    "        self.typelayer = nn.Linear(1*32*32, type_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hashlayer(x)\n",
    "        x_type = self.typelayer(x)\n",
    "        return x_hash, x_type\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py  \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "#https://github.com/qianjinhao/circle-loss\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss    \n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])#[0:4555]\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])#[0:993]\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 / 9000 The length of train set is 9000\n",
      "1000 / 1000 The length of test set is 1000\n",
      "Completed data handle in 864 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read data with List storage Name:[name],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 1\n",
    "    elif itype =='DR': return 2\n",
    "    elif itype =='glaucoma': return 3\n",
    "    elif itype =='myopia': return 4\n",
    "    else: return 0 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trN, trI, trY = [],[],[]\n",
    "norm = 6993\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    trN.append(iname)\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                trN.append(iname)\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trN))\n",
    "#read test image with CV\n",
    "teN, teI, teY = [],[],[]\n",
    "norm = 777\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    teN.append(iname)\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                teN.append(iname)\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teN))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 21.200235Eopch:     1 mean_loss = 20.429771\n",
      " 900 / 900 : loss = 30.571327Eopch:     2 mean_loss = 19.220858\n",
      " 900 / 900 : loss = 7.9419574Eopch:     3 mean_loss = 17.568094\n",
      " 900 / 900 : loss = 17.738335Eopch:     4 mean_loss = 17.299311\n",
      " 900 / 900 : loss = 19.930496Eopch:     5 mean_loss = 16.870456\n",
      " 900 / 900 : loss = 17.8923688Eopch:     6 mean_loss = 15.735021\n",
      " 900 / 900 : loss = 23.531904Eopch:     7 mean_loss = 15.024917\n",
      " 900 / 900 : loss = 24.6160392Eopch:     8 mean_loss = 14.390769\n",
      " 900 / 900 : loss = 6.7055695Eopch:     9 mean_loss = 13.462625\n",
      " 900 / 900 : loss = 20.385605Eopch:    10 mean_loss = 13.578785\n",
      " 900 / 900 : loss = 8.25832687Eopch:    11 mean_loss = 13.179333\n",
      " 900 / 900 : loss = 14.015612Eopch:    12 mean_loss = 12.600564\n",
      " 900 / 900 : loss = 24.046417Eopch:    13 mean_loss = 11.843047\n",
      " 900 / 900 : loss = 14.485544Eopch:    14 mean_loss = 11.285809\n",
      " 900 / 900 : loss = 3.2039542Eopch:    15 mean_loss = 11.199707\n",
      " 900 / 900 : loss = 3.6915384Eopch:    16 mean_loss = 10.568858\n",
      " 900 / 900 : loss = 23.470479Eopch:    17 mean_loss = 10.340764\n",
      " 900 / 900 : loss = 9.1720118Eopch:    18 mean_loss = 9.248077\n",
      " 900 / 900 : loss = 4.4470382Eopch:    19 mean_loss = 9.015467\n",
      " 900 / 900 : loss = 7.3875514Eopch:    20 mean_loss = 8.597583\n",
      " 900 / 900 : loss = 4.3346956Eopch:    21 mean_loss = 8.095929\n",
      " 900 / 900 : loss = 2.2933847Eopch:    22 mean_loss = 7.785250\n",
      " 900 / 900 : loss = 3.2392998Eopch:    23 mean_loss = 7.289272\n",
      " 900 / 900 : loss = 1.3272182Eopch:    24 mean_loss = 6.915914\n",
      " 900 / 900 : loss = 23.530083Eopch:    25 mean_loss = 6.573798\n",
      " 900 / 900 : loss = 5.1360942Eopch:    26 mean_loss = 6.428198\n",
      " 900 / 900 : loss = 2.1182858Eopch:    27 mean_loss = 6.041907\n",
      " 900 / 900 : loss = 3.5690524Eopch:    28 mean_loss = 5.655355\n",
      " 900 / 900 : loss = 25.834633Eopch:    29 mean_loss = 5.433940\n",
      " 900 / 900 : loss = 6.0431318Eopch:    30 mean_loss = 4.924679\n",
      " 900 / 900 : loss = 15.801379Eopch:    31 mean_loss = 4.922872\n",
      " 900 / 900 : loss = 2.6253973Eopch:    32 mean_loss = 4.487342\n",
      " 900 / 900 : loss = 9.4061623Eopch:    33 mean_loss = 4.329884\n",
      " 900 / 900 : loss = 18.515757Eopch:    34 mean_loss = 4.215573\n",
      " 900 / 900 : loss = 1.5600226Eopch:    35 mean_loss = 3.969746\n",
      " 900 / 900 : loss = 4.2339985Eopch:    36 mean_loss = 3.820341\n",
      " 900 / 900 : loss = 2.4357973Eopch:    37 mean_loss = 3.723032\n",
      " 900 / 900 : loss = 2.8135165Eopch:    38 mean_loss = 3.622788\n",
      " 900 / 900 : loss = 2.2395816Eopch:    39 mean_loss = 3.525901\n",
      " 900 / 900 : loss = 6.7122282Eopch:    40 mean_loss = 3.421439\n",
      " 900 / 900 : loss = 1.5497053Eopch:    41 mean_loss = 3.309886\n",
      " 900 / 900 : loss = 1.9770243Eopch:    42 mean_loss = 3.124247\n",
      " 900 / 900 : loss = 4.8107618Eopch:    43 mean_loss = 3.249007\n",
      " 900 / 900 : loss = 3.5126825Eopch:    44 mean_loss = 3.187127\n",
      " 900 / 900 : loss = 1.3354467Eopch:    45 mean_loss = 2.970028\n",
      " 900 / 900 : loss = 3.4330063Eopch:    46 mean_loss = 2.906879\n",
      " 900 / 900 : loss = 2.0517198Eopch:    47 mean_loss = 2.956210\n",
      " 900 / 900 : loss = 4.1368947Eopch:    48 mean_loss = 2.901032\n",
      " 900 / 900 : loss = 3.0365535Eopch:    49 mean_loss = 2.703130\n",
      " 900 / 900 : loss = 5.3332814Eopch:    50 mean_loss = 2.838776\n",
      "best_loss = 2.703130\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------\n",
    "#ATH-Triplet+CE\n",
    "#--------------------------------------------------------\n",
    "#sample  triplet labels\n",
    "#trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "plot_tripletloss = []\n",
    "for epoch in range(50):#iteration\n",
    "    losses, hash_losses, class_loss = [], [], []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_q_y = trQ_y[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_p_y = trP_y[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    train_n_y = trN_y[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(train_q_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(train_p_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(train_n_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, Q_type = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, P_type = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, N_type = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss,#F.log_softmax+F.nll_loss\n",
    "        hash_loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        type_loss = ce_loss(Q_type,Q_y_batch) + ce_loss(P_type,P_y_batch) + ce_loss(N_type,N_y_batch) \n",
    "        loss = hash_loss+type_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "        hash_losses.append(hash_loss.item())\n",
    "        class_loss.append(type_loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    plot_tripletloss.append(np.mean(hash_losses))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100  Completed buliding index in 29 seconds\n",
      "mHR@10=0.758200, mAP@10=0.724293, mRR@10=0.931240\n",
      "[[719   9  21   7  21]\n",
      " [ 61   2   2   1   6]\n",
      " [ 19   1   1   4   2]\n",
      " [ 34   1   3   4   3]\n",
      " [ 22  11   3   9  34]]\n",
      "Sensitivity(TPR) of Normal: 0.925354\n",
      "Sensitivity(TPR) of AMD: 0.027778\n",
      "Sensitivity(TPR) of DR: 0.037037\n",
      "Sensitivity(TPR) of Glaucoma: 0.088889\n",
      "Sensitivity(TPR) of Myopia: 0.430380\n",
      "AUC (Area Under Curve) of Micro: 0.904978\n"
     ]
    }
   ],
   "source": [
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of AMD: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity(TPR) of Myopia: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89929.jpg:0-Distance:0.032626\n",
      "89573.jpg:0-Distance:0.037654\n",
      "479988.jpg:0-Distance:0.037944\n",
      "91525.jpg:0-Distance:0.038395\n",
      "87373.jpg:0-Distance:0.039187\n"
     ]
    }
   ],
   "source": [
    "#figure 1 for problem introduction\n",
    "image_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_AMD/97499.jpg' #DR-481483.jpg\n",
    "Input_feature = []\n",
    "Input_feature.append( cv2.resize(cv2.imread(image_dir).astype(np.float32), (256, 256)))\n",
    "data = torch.from_numpy(np.array(Input_feature)).type(torch.FloatTensor).cuda()\n",
    "Output_feature,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "Output_feature=np.array(Output_feature.cpu().data.numpy().tolist())\n",
    "map_item_score = {}\n",
    "for j, trVal in enumerate(trF):\n",
    "    map_item_score[j] = pdist(np.vstack([Output_feature[0],trVal]),'cosine')#hamming\n",
    "#for j, teVal in enumerate(teF):\n",
    "#    map_item_score[j] = pdist(np.vstack([Output_feature[0],teVal]),'cosine')#hamming\n",
    "ranklist = heapq.nsmallest(5, map_item_score, key=map_item_score.get)\n",
    "for j in ranklist:\n",
    "    print ('%s:%d-Distance:%.6f'%(trN[j],trY[j],map_item_score[j]))\n",
    "    #print ('%s:%d-Distance:%.6f'%(teN[j],teY[j],map_item_score[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486088.jpg:1-495841.jpg:1-Distance:0.064581\n",
      "97499.jpg:1-495123.jpg:1-Distance:0.042261\n",
      "97499.jpg:1-490331.jpg:1-Distance:0.043471\n",
      "484540.jpg:1-86112.jpg:1-Distance:0.045048\n",
      "490471.jpg:1-908794.jpg:1-Distance:0.064827\n",
      "88664.jpg:1-496865.jpg:1-Distance:0.060555\n",
      "88612.jpg:1-480835.jpg:1-Distance:0.089665\n",
      "88313.jpg:1-494053.jpg:1-Distance:0.043001\n",
      "83261.jpg:1-495487.jpg:1-Distance:0.059042\n",
      "83261.jpg:1-96679.jpg:1-Distance:0.064415\n"
     ]
    }
   ],
   "source": [
    "#figure 1 for problem introduction\n",
    "for i in range(len(teY)):\n",
    "    if teY[i]==1 :#AMD\n",
    "    #if teN[i] in ['28901_right','19414_right']: \n",
    "        itype = teY[i]\n",
    "        teVal = teF[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'cosine')#hamming\n",
    "        ranklist = heapq.nsmallest(5, map_item_score, key=map_item_score.get)\n",
    "        for j in ranklist:\n",
    "            if trY[j]==1:\n",
    "                print ('%s:%d-%s:%d-Distance:%.6f'%(teN[i],teY[i],trN[j],trY[j],map_item_score[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994459 -> Myopia\n",
      "0.005446 -> Glaucoma\n",
      "0.000076 -> Norm\n",
      "0.000019 -> AMD\n",
      "0.000000 -> DR\n",
      "(1, 1, 32, 32)\n",
      "/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_myopia/100090.jpg ->top1 prediction: Myopia\n"
     ]
    }
   ],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = 1,1,32,32#feature_conv.shape\n",
    "    \n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc,h*w)))\n",
    "        cam = weight_softmax[class_idx]*(feature_conv.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "#last conv layer followed with one channel by last fully connected layer\n",
    "final_conv = 'sa' \n",
    "best_net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "#get weights parameters\n",
    "params = list(best_net.parameters())\n",
    "#get the last and second last weights, like [classes, hiden nodes]\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy()) \n",
    "# define class type\n",
    "classes = {0:'Norm', 1: 'AMD', 2: 'DR', 3:'Glaucoma', 4:'Myopia', }\n",
    "#read image\n",
    "image_dir='/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_myopia'\n",
    "for file in ['100090.jpg']:#os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, file)\n",
    "    img = []\n",
    "    img.append( cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256)))#(256, 256) is the model input size\n",
    "    data = torch.from_numpy(np.array(img)).type(torch.FloatTensor).cuda()\n",
    "    _,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()#softmax\n",
    "    probs, idx = h_x.sort(0, True) #probabilities of classes\n",
    "\n",
    "    if classes[idx[0].item()] == 'Myopia':\n",
    "        # output: the prediction\n",
    "        for i in range(0, len(classes)):\n",
    "            line = '{:.6f} -> {}'.format(probs[i], classes[idx[i].item()])\n",
    "            print(line)\n",
    "        #get the class activation maps\n",
    "        print (features_blobs[-1].shape)\n",
    "        feature_layer = features_blobs[-1].squeeze()[0]\n",
    "        feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "        CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "        # render the CAM and show\n",
    "        print('%s ->top1 prediction: %s' %(image_path, classes[idx[0].item()]))\n",
    "        img = cv2.imread(root)\n",
    "        height, width, _ = img.shape\n",
    "        CAM = cv2.resize(CAMs[0], (width, height))\n",
    "        heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "        #result = heatmap * 0.3 + img * 0.5\n",
    "        #result = heatmap * 0.7 + img * 0.3\n",
    "        result = heatmap \n",
    "        cv2.imwrite('/data/tmpexec/tmi/'+file+'_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "(128, 128)\n",
      "(128,)\n",
      "output CAM.jpg for the top1 prediction: Myopia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (features_blobs[0].shape)\n",
    "feature_layer = features_blobs[0].squeeze()\n",
    "print (feature_layer.shape)\n",
    "#feature_layer = np.mean(feature_layer, axis=0)\n",
    "feature_layer = np.max(feature_layer, axis=0)\n",
    "print (feature_layer.shape)\n",
    "feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "#result = heatmap * 0.3 + img * 0.5\n",
    "result = heatmap \n",
    "cv2.imwrite('/data/tmpexec/tmi/iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
