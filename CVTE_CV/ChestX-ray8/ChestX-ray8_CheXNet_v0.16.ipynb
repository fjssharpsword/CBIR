{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78468 / 78468 The length of trainset is 78468\n",
      "11219 / 11219 The length of validset is 11219\n",
      "22433 / 22433 The length of testset is 22433\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "\n",
    "#preparing the trainset and  testset\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "trN, trI, trY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt', \"r\") as file_descriptor: #tarinset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            trN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = np.array([int(i) for i in image_label]) \n",
    "            if (image_label.sum()==0): trY.append(np.array([1,0]))#normal\n",
    "            else: trY.append(np.array([0,1])) #disease\n",
    "            #img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            #img = cv2.normalize(img, None, 0, 1, cv2.NORM_MINMAX) #normalization\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            trI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),78468))\n",
    "        sys.stdout.flush()\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)   \n",
    "print('The length of trainset is %d'%len(trN))\n",
    "        \n",
    "valN, valI, valY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt', \"r\") as file_descriptor: #valset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            valN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = np.array([int(i) for i in image_label]) \n",
    "            if (image_label.sum()==0): valY.append(np.array([1,0]))#normal\n",
    "            else: valY.append(np.array([0,1])) #disease\n",
    "            #img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            #img = cv2.normalize(img, None, 0, 1, cv2.NORM_MINMAX) #normalization\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            valI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(valN),11219))\n",
    "        sys.stdout.flush()\n",
    "valI = np.array(valI)\n",
    "valY = np.array(valY) \n",
    "print('The length of validset is %d'%len(valN))\n",
    "\n",
    "teN, teI, teY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt', \"r\") as file_descriptor: #testset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            teN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = np.array([int(i) for i in image_label]) \n",
    "            if (image_label.sum()==0): teY.append(np.array([1,0]))#normal\n",
    "            else: teY.append(np.array([0,1])) #disease\n",
    "            #img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            #img = cv2.normalize(img, None, 0, 1, cv2.NORM_MINMAX) #normalization\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))                    \n",
    "            teI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),22433))\n",
    "        sys.stdout.flush()\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)    \n",
    "print('The length of testset is %d'%len(teN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.dense_net_121 = torchvision.models.densenet121(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_121.classifier.in_features\n",
    "        self.dense_net_121.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet169(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet169, self).__init__()\n",
    "        self.dense_net_169 = torchvision.models.densenet169(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_169.classifier.in_features\n",
    "        self.dense_net_169.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_169(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet201(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet201, self).__init__()\n",
    "        self.dense_net_201 = torchvision.models.densenet201(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_201.classifier.in_features\n",
    "        self.dense_net_201.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_201(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 374 / 374 : validation loss = 0.876867Eopch:     1 val_loss = 0.889715\n",
      " 374 / 374 : validation loss = 0.850758Eopch:     2 val_loss = 0.862862\n",
      " 374 / 374 : validation loss = 0.633622Eopch:     3 val_loss = 0.613785\n",
      " 374 / 374 : validation loss = 0.615302Eopch:     4 val_loss = 0.608205\n",
      " 374 / 374 : validation loss = 0.627072Eopch:     5 val_loss = 0.606242\n",
      " 374 / 374 : validation loss = 0.619299Eopch:     6 val_loss = 0.606683\n",
      " 374 / 374 : validation loss = 0.622918Eopch:     7 val_loss = 0.604374\n",
      " 374 / 374 : validation loss = 0.645583Eopch:     8 val_loss = 0.601725\n",
      " 374 / 374 : validation loss = 0.653046Eopch:     9 val_loss = 0.605568\n",
      " 374 / 374 : validation loss = 0.649842Eopch:    10 val_loss = 0.603732\n",
      " 374 / 374 : validation loss = 0.620221Eopch:    11 val_loss = 0.603774\n",
      " 374 / 374 : validation loss = 0.660497Eopch:    12 val_loss = 0.602804\n",
      " 374 / 374 : validation loss = 0.656437Eopch:    13 val_loss = 0.601452\n",
      " 374 / 374 : validation loss = 0.633242Eopch:    14 val_loss = 0.602039\n",
      " 374 / 374 : validation loss = 0.640371Eopch:    15 val_loss = 0.601637\n",
      " 374 / 374 : validation loss = 0.643713Eopch:    16 val_loss = 0.606847\n",
      " 374 / 374 : validation loss = 0.649883Eopch:    17 val_loss = 0.603169\n",
      " 374 / 374 : validation loss = 0.654456Eopch:    18 val_loss = 0.605148\n",
      " 374 / 374 : validation loss = 0.646437Eopch:    19 val_loss = 0.607327\n",
      " 374 / 374 : validation loss = 0.681581Eopch:    20 val_loss = 0.606804\n",
      " 374 / 374 : validation loss = 0.681406Eopch:    21 val_loss = 0.608994\n",
      " 374 / 374 : validation loss = 0.682321Eopch:    22 val_loss = 0.611677\n",
      " 374 / 374 : validation loss = 0.685451Eopch:    23 val_loss = 0.613922\n",
      " 374 / 374 : validation loss = 0.692299Eopch:    24 val_loss = 0.616930\n",
      " 374 / 374 : validation loss = 0.698191Eopch:    25 val_loss = 0.620655\n",
      " 374 / 374 : validation loss = 0.685456Eopch:    26 val_loss = 0.616519\n",
      " 374 / 374 : validation loss = 0.687105Eopch:    27 val_loss = 0.616983\n",
      " 374 / 374 : validation loss = 0.689014Eopch:    28 val_loss = 0.617638\n",
      " 374 / 374 : validation loss = 0.691071Eopch:    29 val_loss = 0.618400\n",
      " 374 / 374 : validation loss = 0.692759Eopch:    30 val_loss = 0.619169\n",
      " 374 / 374 : validation loss = 0.694916Eopch:    31 val_loss = 0.619962\n",
      " 374 / 374 : validation loss = 0.689451Eopch:    32 val_loss = 0.619284\n",
      " 374 / 374 : validation loss = 0.686368Eopch:    33 val_loss = 0.619024\n",
      " 374 / 374 : validation loss = 0.684305Eopch:    34 val_loss = 0.618882\n",
      " 374 / 374 : validation loss = 0.683001Eopch:    35 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.682199Eopch:    36 val_loss = 0.618807\n",
      " 374 / 374 : validation loss = 0.681753Eopch:    37 val_loss = 0.618830\n",
      " 374 / 374 : validation loss = 0.681651Eopch:    38 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681576Eopch:    39 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681503Eopch:    40 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681437Eopch:    41 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681366Eopch:    42 val_loss = 0.618822\n",
      " 374 / 374 : validation loss = 0.681292Eopch:    43 val_loss = 0.618823\n",
      " 374 / 374 : validation loss = 0.681287Eopch:    44 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681285Eopch:    45 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681283Eopch:    46 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681284Eopch:    47 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681278Eopch:    48 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681276Eopch:    49 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681274Eopch:    50 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681272Eopch:    51 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681272Eopch:    52 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681268Eopch:    53 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681266Eopch:    54 val_loss = 0.618821\n",
      " 374 / 374 : validation loss = 0.681264Eopch:    55 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681262Eopch:    56 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681269Eopch:    57 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681258Eopch:    58 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681256Eopch:    59 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681254Eopch:    60 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681252Eopch:    61 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681256Eopch:    62 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681248Eopch:    63 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681246Eopch:    64 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681244Eopch:    65 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681242Eopch:    66 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681243Eopch:    67 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681238Eopch:    68 val_loss = 0.618820\n",
      " 374 / 374 : validation loss = 0.681236Eopch:    69 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681234Eopch:    70 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681232Eopch:    71 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681239Eopch:    72 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681228Eopch:    73 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681226Eopch:    74 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681224Eopch:    75 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681222Eopch:    76 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681227Eopch:    77 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681218Eopch:    78 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681216Eopch:    79 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681214Eopch:    80 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681212Eopch:    81 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681215Eopch:    82 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681209Eopch:    83 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681206Eopch:    84 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681205Eopch:    85 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681203Eopch:    86 val_loss = 0.618819\n",
      " 374 / 374 : validation loss = 0.681201Eopch:    87 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681199Eopch:    88 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681197Eopch:    89 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681195Eopch:    90 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681194Eopch:    91 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681192Eopch:    92 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681199Eopch:    93 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681188Eopch:    94 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681186Eopch:    95 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681184Eopch:    96 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681182Eopch:    97 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681181Eopch:    98 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681179Eopch:    99 val_loss = 0.618818\n",
      " 374 / 374 : validation loss = 0.681177Eopch:   100 val_loss = 0.618818\n",
      "best_loss = 0.601452\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 2 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 30 #'Batch Size': 32\n",
    "for epoch in range(100):#'Max Epoch': 1000\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch)#forwordï¼Œ .permute(0, 3, 1, 2)\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            sys.stdout.write('\\r {} / {} : validation loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    print(\"Eopch: %5d val_loss = %.6f\" % (epoch + 1, np.mean(loss_val)))\n",
    "    if np.mean(loss_val) < best_loss:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 747 / 748 The average AUROC is 0.7468\n",
      "The AUROC of Normal is 0.7468\n",
      "The AUROC of Abnormal is 0.7468\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forwordï¼Œ.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Normal', 'Abnormal'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
