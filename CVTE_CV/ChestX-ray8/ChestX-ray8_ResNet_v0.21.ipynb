{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', \\\n",
    "       'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.filters as filters\n",
    "from scipy.ndimage import binary_dilation\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "torch.cuda.set_device(1)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86524 / 86524 The length of trainset is 86524\n",
      "25596 / 25596 The length of testset is 25596\n",
      "The length of testset is 984\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia','Pneumothorax', \\\n",
    "               'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] \n",
    "#preparing the trainset and  testset\n",
    "trData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_train.csv\" , sep=',') #trainset\n",
    "trN, trI, trY = [],[],[]\n",
    "for _, row in trData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        trN.append(name)#'image_index'\n",
    "        trY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        trI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "\n",
    "teData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_test.csv\" , sep=',') #testset\n",
    "teN, teI, teY = [],[],[]\n",
    "for _, row in teData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        teN.append(name)#'image_index'\n",
    "        teY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        teI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)\n",
    "\n",
    "#preparing bounding box dataset\n",
    "boxdata = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_BBox.csv\" , sep=',')\n",
    "boxdata = boxdata[['Image Index','Finding Label','Bbox [x', 'y', 'w', 'h]']]\n",
    "#print('Dataset statistic, records: %d, fields: %d' % (boxdata.shape[0], boxdata.shape[1]))\n",
    "#print(boxdata.columns.values.tolist())\n",
    "bbN, bbI, bbY, bBox = [],[],[],[]\n",
    "for _, row in boxdata.iterrows():\n",
    "    bbN.append(row['Image Index'])\n",
    "    \n",
    "    img = Image_Processing(os.path.join(img_path, row['Image Index']))\n",
    "    bbI.append(img)\n",
    "    \n",
    "    labels = np.zeros(len(CLASS_NAMES))\n",
    "    labels[CLASS_NAMES.index(row['Finding Label'])] = 1\n",
    "    bbY.append(labels)\n",
    "    \n",
    "    bBox.append(np.array([row['Bbox [x'], row['y'], row['w'], row['h]']])) #xywh  \n",
    "print('The length of testset is %d'%len(bbN))\n",
    "bbI = np.array(bbI)\n",
    "bbY = np.array(bbY)\n",
    "bBox = np.array(bBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=15):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return torch.sigmoid(x) \n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2885 / 2885 : train loss = 0.368399Eopch:     1 mean_loss = 0.197488\n",
      " 2885 / 2885 : train loss = 0.368903Eopch:     2 mean_loss = 0.191759\n",
      " 2885 / 2885 : train loss = 0.371321Eopch:     3 mean_loss = 0.189331\n",
      " 2885 / 2885 : train loss = 0.363233Eopch:     4 mean_loss = 0.186021\n",
      " 2885 / 2885 : train loss = 0.363221Eopch:     5 mean_loss = 0.184178\n",
      " 2885 / 2885 : train loss = 0.357144Eopch:     6 mean_loss = 0.183012\n",
      " 2885 / 2885 : train loss = 0.353979Eopch:     7 mean_loss = 0.182206\n",
      " 2885 / 2885 : train loss = 0.351326Eopch:     8 mean_loss = 0.181476\n",
      " 2885 / 2885 : train loss = 0.349111Eopch:     9 mean_loss = 0.180845\n",
      " 2885 / 2885 : train loss = 0.348364Eopch:    10 mean_loss = 0.180339\n",
      " 2885 / 2885 : train loss = 0.356071Eopch:    11 mean_loss = 0.179788\n",
      " 2885 / 2885 : train loss = 0.355092Eopch:    12 mean_loss = 0.179180\n",
      " 2885 / 2885 : train loss = 0.351477Eopch:    13 mean_loss = 0.178832\n",
      " 2885 / 2885 : train loss = 0.345133Eopch:    14 mean_loss = 0.178391\n",
      " 2885 / 2885 : train loss = 0.346769Eopch:    15 mean_loss = 0.178043\n",
      " 2885 / 2885 : train loss = 0.351766Eopch:    16 mean_loss = 0.177621\n",
      " 2885 / 2885 : train loss = 0.356798Eopch:    17 mean_loss = 0.177342\n",
      " 2885 / 2885 : train loss = 0.352952Eopch:    18 mean_loss = 0.177111\n",
      " 2885 / 2885 : train loss = 0.353594Eopch:    19 mean_loss = 0.176783\n",
      " 2885 / 2885 : train loss = 0.354333Eopch:    20 mean_loss = 0.176501\n",
      " 2885 / 2885 : train loss = 0.354041Eopch:    21 mean_loss = 0.176263\n",
      " 2885 / 2885 : train loss = 0.363401Eopch:    22 mean_loss = 0.176023\n",
      " 2885 / 2885 : train loss = 0.347358Eopch:    23 mean_loss = 0.175744\n",
      " 2885 / 2885 : train loss = 0.351156Eopch:    24 mean_loss = 0.175556\n",
      " 2885 / 2885 : train loss = 0.344603Eopch:    25 mean_loss = 0.175342\n",
      " 2885 / 2885 : train loss = 0.339834Eopch:    26 mean_loss = 0.175140\n",
      " 2885 / 2885 : train loss = 0.344311Eopch:    27 mean_loss = 0.175044\n",
      " 2885 / 2885 : train loss = 0.339677Eopch:    28 mean_loss = 0.174897\n",
      " 2885 / 2885 : train loss = 0.349631Eopch:    29 mean_loss = 0.174717\n",
      " 2885 / 2885 : train loss = 0.341265Eopch:    30 mean_loss = 0.174507\n",
      "best_loss = 0.174507\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = len(CLASS_NAMES) #class numbers\n",
    "model = resnet50(num_classes=N_CLASSES).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 30 #'Batch Size': 32\n",
    "for epoch in range(30):#'Max Epoch': 1000\n",
    "    losses = []\n",
    "    losses_tensor = 0.\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()  \n",
    "            losses.append(loss.item())\n",
    "            losses_tensor += loss\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    scheduler.step(losses_tensor.item())\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 853 / 854 The average AUROC is 0.6438\n",
      "The AUROC of Atelectasis is 0.6572\n",
      "The AUROC of Cardiomegaly is 0.6932\n",
      "The AUROC of Effusion is 0.7518\n",
      "The AUROC of Infiltration is 0.6169\n",
      "The AUROC of Mass is 0.6026\n",
      "The AUROC of Nodule is 0.5829\n",
      "The AUROC of Pneumonia is 0.6145\n",
      "The AUROC of Pneumothorax is 0.6331\n",
      "The AUROC of Consolidation is 0.6883\n",
      "The AUROC of Edema is 0.7467\n",
      "The AUROC of Emphysema is 0.6208\n",
      "The AUROC of Fibrosis is 0.6373\n",
      "The AUROC of Pleural_Thickening is 0.6322\n",
      "The AUROC of Hernia is 0.4951\n",
      "The AUROC of No Finding is 0.6844\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch)#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32 / 33 The average AUROC is 0.6486\n",
      "The AUROC of Atelectasis is 0.6186\n",
      "The AUROC of Cardiomegaly is 0.8208\n",
      "The AUROC of Effusion is 0.6941\n",
      "The AUROC of Infiltration is 0.5757\n",
      "The AUROC of Mass is 0.5927\n",
      "The AUROC of Nodule is 0.6926\n",
      "The AUROC of Pneumonia is 0.5010\n",
      "The AUROC of Pneumothorax is 0.6934\n"
     ]
    }
   ],
   "source": [
    "#performance of boxset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(bbY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(bbY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(bbI)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(bbY)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forwordï¼Œ.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
