{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2）Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, path_to_img_dir, path_to_dataset_file, transform=None):\n",
    "        \"\"\"\n",
    "        初始化PyTorch的Dataset类以使用dataloader类\n",
    "        :param path_to_img_dir: 存储ChestX-ray14 Dataset的图片文件的路径\n",
    "        :param path_to_dataset_file: 存储`test.txt`, `train.txt`等文件的路径（训练集、测试集划分及图片所属的标签）\n",
    "        :param transform: 对图片要做的transform处理\n",
    "        \"\"\"\n",
    "        self.list_image_paths = []\n",
    "        self.list_image_labels = []\n",
    "        self.transform = transform\n",
    "        with open(path_to_dataset_file, \"r\") as file_descriptor:\n",
    "            lines = file_descriptor.readlines()\n",
    "            for line in lines:\n",
    "                line_items = line.split()\n",
    "                image_path = os.path.join(path_to_img_dir, line_items[0].split('/')[1])  # line_items为图片的相对路径信息\n",
    "                image_label = line_items[1:]  # 从第二个开始，都为标签信息\n",
    "                image_label = [int(i) for i in image_label]  # 通过list生成向量\n",
    "                self.list_image_paths.append(image_path)\n",
    "                self.list_image_labels.append(image_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        :param index: get item 时提供的索引index数值\n",
    "        :return:\n",
    "            imageData: 图片数据\n",
    "            imageLabel: 标签信息\n",
    "        \"\"\"\n",
    "        image_path = self.list_image_paths[index]\n",
    "        image_data = Image.open(image_path).convert('RGB')\n",
    "        image_label = torch.FloatTensor(self.list_image_labels[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "\n",
    "        return image_data, image_label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "            len: 数据集的总长度\n",
    "        \"\"\"\n",
    "        return len(self.list_image_paths)\n",
    "\n",
    "\n",
    "PATH_TO_IMAGES_DIR = '/data/fjsdata/NIH-CXR/images/images/'\n",
    "PATH_TO_TRAIN_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt'\n",
    "PATH_TO_VAL_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt'\n",
    "PATH_TO_TEST_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt'\n",
    "def get_train_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_train = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                     path_to_dataset_file=PATH_TO_TRAIN_FILE, transform=transform_seq)\n",
    "    data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_train\n",
    "\n",
    "\n",
    "def get_validation_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_validation = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                          path_to_dataset_file=PATH_TO_VAL_FILE, transform=transform_seq)\n",
    "    data_loader_validation = DataLoader(dataset=dataset_validation, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_validation\n",
    "\n",
    "\n",
    "def get_test_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_test = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                    path_to_dataset_file=PATH_TO_TEST_FILE, transform=transform_seq)\n",
    "    data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.dense_net_121 = torchvision.models.densenet121(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_121.classifier.in_features\n",
    "        self.dense_net_121.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet169(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet169, self).__init__()\n",
    "        self.dense_net_169 = torchvision.models.densenet169(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_169.classifier.in_features\n",
    "        self.dense_net_169.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_169(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet201(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet201, self).__init__()\n",
    "        self.dense_net_201 = torchvision.models.densenet201(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_201.classifier.in_features\n",
    "        self.dense_net_201.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_201(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 50 / Step: 351 : validation loss = 0.120729best_loss = 0.155802\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = 14 #class numbers\n",
    "network_model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#network_model = torch.nn.DataParallel(network_model).cuda()  # make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.RandomResizedCrop(224))\n",
    "transform_list.append(transforms.RandomHorizontalFlip())\n",
    "transform_list.append(transforms.ToTensor())\n",
    "transform_list.append(normalize)\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get data loader object\n",
    "dataloader_train = get_train_dataloader(batch_size=32, shuffle=True, num_workers=0, transform_seq=transform_sequence)\n",
    "dataloader_val = get_validation_dataloader(batch_size=32,shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "optimizer = torch.optim.Adam(network_model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "loss  = torch.nn.BCELoss()\n",
    "# start training network\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch_index in range(50):#max epoch = 1000\n",
    "    network_model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for batch_index, (image, label) in enumerate(dataloader_train):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            loss_tensor = loss(var_output, var_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : train loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%loss_tensor.item())))\n",
    "            sys.stdout.flush()  \n",
    "\n",
    "    # Validation Process\n",
    "    network_model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        loss_val = 0.\n",
    "        mean_loss_tensor = 0.\n",
    "        for batch_index, (image, label) in enumerate(dataloader_val):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            curr_loss_tensor = loss(var_output, var_label)  # the output of loss() is a tensor\n",
    "            mean_loss_tensor += curr_loss_tensor  # tensor op.\n",
    "            loss_val += curr_loss_tensor.item()  # scalar op.\n",
    "\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : validation loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%curr_loss_tensor.item())))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    loss_val = loss_val / len(dataloader_val)  # scalar\n",
    "    mean_loss_tensor = mean_loss_tensor / len(dataloader_val)  # tensor\n",
    "\n",
    "    # End validation process\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    if loss_val < best_loss:\n",
    "        best_loss = loss_val\n",
    "        best_net = copy.deepcopy(network_model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "network_model = network_model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 702Mean AUROC is 0.806135.\n",
      "Atelectasis 0.7907389432406127\n",
      "Cardiomegaly 0.8885952989011331\n",
      "Effusion 0.8750552670285461\n",
      "Infiltration 0.6894257037061751\n",
      "Mass 0.8030819337916288\n",
      "Nodule 0.7122465767918077\n",
      "Pneumonia 0.7406898634730557\n",
      "Pneumothorax 0.8404609463518928\n",
      "Consolidation 0.7981445303186975\n",
      "Edema 0.8818940188646465\n",
      "Emphysema 0.8625747312828134\n",
      "Fibrosis 0.795573602119328\n",
      "Pleural_Thickening 0.7511479829367191\n",
      "Hernia 0.8562624013474802\n"
     ]
    }
   ],
   "source": [
    "def compute_auroc(ground_truth, prediction):\n",
    "        out_auroc = []\n",
    "        np_ground_truth = ground_truth.cpu().numpy()\n",
    "        np_prediction = prediction.cpu().numpy()\n",
    "        for i in range(N_CLASSES):\n",
    "            # calculate the roc_auc_score of each class\n",
    "            out_auroc.append(roc_auc_score(np_ground_truth[:, i], np_prediction[:, i]))\n",
    "        return out_auroc\n",
    "    \n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.TenCrop(224))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get test data loader\n",
    "data_loader_test = get_test_dataloader(batch_size=32, shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "# initialize test output with tensor of type CUDA-float\n",
    "output_ground_truth = torch.FloatTensor().cuda()\n",
    "output_prediction = torch.FloatTensor().cuda()\n",
    "\n",
    "# start testing\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for batch_index, (image, label) in enumerate(data_loader_test):\n",
    "        label = label.cuda()\n",
    "        output_ground_truth = torch.cat((output_ground_truth, label), 0)\n",
    "        batch_size, n_crops, num_channels, height, width = image.size()\n",
    "        var_image = torch.autograd.Variable(image.view(-1, num_channels, height, width).cuda())\n",
    "        out = best_net(var_image)\n",
    "        out_mean = out.view(batch_size, n_crops, -1).mean(1)\n",
    "        output_prediction = torch.cat((output_prediction, out_mean.data), 0)\n",
    "        sys.stdout.write('\\r Step: {}'.format(batch_index+1))\n",
    "        sys.stdout.flush()\n",
    "    auroc_individual = compute_auroc(output_ground_truth, output_prediction)\n",
    "    auroc_mean = np.array(auroc_individual).mean()\n",
    "\n",
    "print('Mean AUROC is %f.' % auroc_mean)\n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "for i in range(len(auroc_individual)):\n",
    "    print(CLASS_NAMES[i], auroc_individual[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "======================================10.13========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 10 / Step: 1122 : validation loss = 0.225984best_loss = 0.169151\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = 14 #class numbers\n",
    "network_model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.RandomResizedCrop(224))\n",
    "transform_list.append(transforms.RandomHorizontalFlip())\n",
    "transform_list.append(transforms.ToTensor())\n",
    "transform_list.append(normalize)\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get data loader object\n",
    "dataloader_train = get_train_dataloader(batch_size=10, shuffle=True, num_workers=0, transform_seq=transform_sequence)\n",
    "dataloader_val = get_validation_dataloader(batch_size=10,shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "optimizer = torch.optim.Adam(network_model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "loss  = torch.nn.BCELoss()\n",
    "# start training network\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch_index in range(10):\n",
    "    network_model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for batch_index, (image, label) in enumerate(dataloader_train):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            loss_tensor = loss(var_output, var_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : train loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%loss_tensor.item())))\n",
    "            sys.stdout.flush()  \n",
    "\n",
    "    # Validation Process\n",
    "    network_model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        loss_val = 0.\n",
    "        mean_loss_tensor = 0.\n",
    "        for batch_index, (image, label) in enumerate(dataloader_val):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            curr_loss_tensor = loss(var_output, var_label)  # the output of loss() is a tensor\n",
    "            mean_loss_tensor += curr_loss_tensor  # tensor op.\n",
    "            loss_val += curr_loss_tensor.item()  # scalar op.\n",
    "\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : validation loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%curr_loss_tensor.item())))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    loss_val = loss_val / len(dataloader_val)  # scalar\n",
    "    mean_loss_tensor = mean_loss_tensor / len(dataloader_val)  # tensor\n",
    "\n",
    "    # End validation process\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    if loss_val < best_loss:\n",
    "        best_loss = loss_val\n",
    "        best_net = copy.deepcopy(network_model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "network_model = network_model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 2244Mean AUROC is 0.730311.\n",
      "Atelectasis 0.7469168284416781\n",
      "Cardiomegaly 0.7560946199038443\n",
      "Effusion 0.8137915098699412\n",
      "Infiltration 0.65920680386488\n",
      "Mass 0.6741468493218802\n",
      "Nodule 0.6113608581746037\n",
      "Pneumonia 0.6705774919547087\n",
      "Pneumothorax 0.742925412293853\n",
      "Consolidation 0.7702796667583343\n",
      "Edema 0.8471743165469209\n",
      "Emphysema 0.7195747929353377\n",
      "Fibrosis 0.7217389334420734\n",
      "Pleural_Thickening 0.6699292889223916\n",
      "Hernia 0.8206400956166486\n"
     ]
    }
   ],
   "source": [
    "def compute_auroc(ground_truth, prediction):\n",
    "        out_auroc = []\n",
    "        np_ground_truth = ground_truth.cpu().numpy()\n",
    "        np_prediction = prediction.cpu().numpy()\n",
    "        for i in range(N_CLASSES):\n",
    "            # calculate the roc_auc_score of each class\n",
    "            out_auroc.append(roc_auc_score(np_ground_truth[:, i], np_prediction[:, i]))\n",
    "        return out_auroc\n",
    "    \n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.TenCrop(224))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get test data loader\n",
    "data_loader_test = get_test_dataloader(batch_size=10, shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "# initialize test output with tensor of type CUDA-float\n",
    "output_ground_truth = torch.FloatTensor().cuda()\n",
    "output_prediction = torch.FloatTensor().cuda()\n",
    "\n",
    "# start testing\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for batch_index, (image, label) in enumerate(data_loader_test):\n",
    "        label = label.cuda()\n",
    "        output_ground_truth = torch.cat((output_ground_truth, label), 0)\n",
    "        batch_size, n_crops, num_channels, height, width = image.size()\n",
    "        var_image = torch.autograd.Variable(image.view(-1, num_channels, height, width).cuda())\n",
    "        out = best_net(var_image)\n",
    "        out_mean = out.view(batch_size, n_crops, -1).mean(1)\n",
    "        output_prediction = torch.cat((output_prediction, out_mean.data), 0)\n",
    "        sys.stdout.write('\\r Step: {}'.format(batch_index+1))\n",
    "        sys.stdout.flush()\n",
    "    auroc_individual = compute_auroc(output_ground_truth, output_prediction)\n",
    "    auroc_mean = np.array(auroc_individual).mean()\n",
    "\n",
    "print('Mean AUROC is %f.' % auroc_mean)\n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "for i in range(len(auroc_individual)):\n",
    "    print(CLASS_NAMES[i], auroc_individual[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=============10.14============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 32 / Step: 2248 : train loss = 0.1438641229"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55d60ac4133e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnetwork_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set network as train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mvar_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d3aac7f002c8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0moh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m     def rotate(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_CLASSES = 14 #class numbers\n",
    "network_model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.RandomResizedCrop(224))\n",
    "transform_list.append(transforms.RandomHorizontalFlip())\n",
    "transform_list.append(transforms.ToTensor())\n",
    "transform_list.append(normalize)\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get data loader object\n",
    "dataloader_train = get_train_dataloader(batch_size=20, shuffle=True, num_workers=0, transform_seq=transform_sequence)\n",
    "dataloader_val = get_validation_dataloader(batch_size=20,shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "optimizer = torch.optim.Adam(network_model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "loss  = torch.nn.BCELoss()\n",
    "# start training network\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch_index in range(50):\n",
    "    network_model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for batch_index, (image, label) in enumerate(dataloader_train):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            loss_tensor = loss(var_output, var_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : train loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%loss_tensor.item())))\n",
    "            sys.stdout.flush()  \n",
    "\n",
    "    # Validation Process\n",
    "    network_model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        loss_val = 0.\n",
    "        mean_loss_tensor = 0.\n",
    "        for batch_index, (image, label) in enumerate(dataloader_val):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            curr_loss_tensor = loss(var_output, var_label)  # the output of loss() is a tensor\n",
    "            mean_loss_tensor += curr_loss_tensor  # tensor op.\n",
    "            loss_val += curr_loss_tensor.item()  # scalar op.\n",
    "\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : validation loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%curr_loss_tensor.item())))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    loss_val = loss_val / len(dataloader_val)  # scalar\n",
    "    mean_loss_tensor = mean_loss_tensor / len(dataloader_val)  # tensor\n",
    "\n",
    "    # End validation process\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    if loss_val < best_loss:\n",
    "        best_loss = loss_val\n",
    "        best_net = copy.deepcopy(network_model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "network_model = network_model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 1122Mean AUROC is 0.779045.\n",
      "Atelectasis 0.7737328897373732\n",
      "Cardiomegaly 0.8692771773087993\n",
      "Effusion 0.8558411893608466\n",
      "Infiltration 0.6732160875291814\n",
      "Mass 0.7577059118464835\n",
      "Nodule 0.684745079410051\n",
      "Pneumonia 0.6945413988471985\n",
      "Pneumothorax 0.8098944028330188\n",
      "Consolidation 0.7863079351974734\n",
      "Edema 0.8680557296580482\n",
      "Emphysema 0.8093709327704315\n",
      "Fibrosis 0.7583328514630457\n",
      "Pleural_Thickening 0.723760766735066\n",
      "Hernia 0.8418444060219774\n"
     ]
    }
   ],
   "source": [
    "def compute_auroc(ground_truth, prediction):\n",
    "        out_auroc = []\n",
    "        np_ground_truth = ground_truth.cpu().numpy()\n",
    "        np_prediction = prediction.cpu().numpy()\n",
    "        for i in range(N_CLASSES):\n",
    "            # calculate the roc_auc_score of each class\n",
    "            out_auroc.append(roc_auc_score(np_ground_truth[:, i], np_prediction[:, i]))\n",
    "        return out_auroc\n",
    "    \n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.TenCrop(224))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get test data loader\n",
    "data_loader_test = get_test_dataloader(batch_size=20, shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "# initialize test output with tensor of type CUDA-float\n",
    "output_ground_truth = torch.FloatTensor().cuda()\n",
    "output_prediction = torch.FloatTensor().cuda()\n",
    "\n",
    "# start testing\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for batch_index, (image, label) in enumerate(data_loader_test):\n",
    "        label = label.cuda()\n",
    "        output_ground_truth = torch.cat((output_ground_truth, label), 0)\n",
    "        batch_size, n_crops, num_channels, height, width = image.size()\n",
    "        var_image = torch.autograd.Variable(image.view(-1, num_channels, height, width).cuda())\n",
    "        out = best_net(var_image)\n",
    "        out_mean = out.view(batch_size, n_crops, -1).mean(1)\n",
    "        output_prediction = torch.cat((output_prediction, out_mean.data), 0)\n",
    "        sys.stdout.write('\\r Step: {}'.format(batch_index+1))\n",
    "        sys.stdout.flush()\n",
    "    auroc_individual = compute_auroc(output_ground_truth, output_prediction)\n",
    "    auroc_mean = np.array(auroc_individual).mean()\n",
    "\n",
    "print('Mean AUROC is %f.' % auroc_mean)\n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "for i in range(len(auroc_individual)):\n",
    "    print(CLASS_NAMES[i], auroc_individual[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
