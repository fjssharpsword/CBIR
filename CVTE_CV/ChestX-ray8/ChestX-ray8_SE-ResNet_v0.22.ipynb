{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', \\\n",
    "       'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.filters as filters\n",
    "from scipy.ndimage import binary_dilation\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86524 / 86524 The length of trainset is 86524\n",
      "25596 / 25596 The length of testset is 25596\n",
      "The length of testset is 984\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia','Pneumothorax', \\\n",
    "               'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] \n",
    "#preparing the trainset and  testset\n",
    "trData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_train.csv\" , sep=',') #trainset\n",
    "trN, trI, trY = [],[],[]\n",
    "for _, row in trData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        trN.append(name)#'image_index'\n",
    "        trY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        trI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "\n",
    "teData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_test.csv\" , sep=',') #testset\n",
    "teN, teI, teY = [],[],[]\n",
    "for _, row in teData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        teN.append(name)#'image_index'\n",
    "        teY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        teI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)\n",
    "\n",
    "#preparing bounding box dataset\n",
    "boxdata = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_BBox.csv\" , sep=',')\n",
    "boxdata = boxdata[['Image Index','Finding Label','Bbox [x', 'y', 'w', 'h]']]\n",
    "#print('Dataset statistic, records: %d, fields: %d' % (boxdata.shape[0], boxdata.shape[1]))\n",
    "#print(boxdata.columns.values.tolist())\n",
    "bbN, bbI, bbY, bBox = [],[],[],[]\n",
    "for _, row in boxdata.iterrows():\n",
    "    bbN.append(row['Image Index'])\n",
    "    \n",
    "    img = Image_Processing(os.path.join(img_path, row['Image Index']))\n",
    "    bbI.append(img)\n",
    "    \n",
    "    labels = np.zeros(len(CLASS_NAMES))\n",
    "    labels[CLASS_NAMES.index(row['Finding Label'])] = 1\n",
    "    bbY.append(labels)\n",
    "    \n",
    "    bBox.append(np.array([row['Bbox [x'], row['y'], row['w'], row['h]']])) #xywh  \n",
    "print('The length of testset is %d'%len(bbN))\n",
    "bbI = np.array(bbI)\n",
    "bbY = np.array(bbY)\n",
    "bBox = np.array(bBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/moskomule/senet.pytorch\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision.models import ResNet\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(planes * 4, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def se_resnet18(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet34(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1_000, pretrained=False):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(load_state_dict_from_url(\n",
    "            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "class CifarSEBasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, reduction=16):\n",
    "        super(CifarSEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        if inplanes != planes:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                                            nn.BatchNorm2d(planes))\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CifarSEResNet(nn.Module):\n",
    "    def __init__(self, block, n_size, num_classes=10, reduction=16):\n",
    "        super(CifarSEResNet, self).__init__()\n",
    "        self.inplane = 16\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, 16, blocks=n_size, stride=1, reduction=reduction)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 32, blocks=n_size, stride=2, reduction=reduction)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 64, blocks=n_size, stride=2, reduction=reduction)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride, reduction):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inplane, planes, stride, reduction))\n",
    "            self.inplane = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class CifarSEPreActResNet(CifarSEResNet):\n",
    "    def __init__(self, block, n_size, num_classes=10, reduction=16):\n",
    "        super(CifarSEPreActResNet, self).__init__(\n",
    "            block, n_size, num_classes, reduction)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.initialize()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "\n",
    "def se_resnet20(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet32(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet56(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet20(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet32(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet56(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2885 / 2885 : train loss = 0.359811Eopch:     1 mean_loss = 0.195170\n",
      " 2885 / 2885 : train loss = 0.362229Eopch:     2 mean_loss = 0.191093\n",
      " 2885 / 2885 : train loss = 0.362996Eopch:     3 mean_loss = 0.190088\n",
      " 2885 / 2885 : train loss = 0.362256Eopch:     4 mean_loss = 0.188838\n",
      " 2885 / 2885 : train loss = 0.366804Eopch:     5 mean_loss = 0.187657\n",
      " 2885 / 2885 : train loss = 0.358908Eopch:     6 mean_loss = 0.186781\n",
      " 2885 / 2885 : train loss = 0.356144Eopch:     7 mean_loss = 0.185932\n",
      " 2885 / 2885 : train loss = 0.364562Eopch:     8 mean_loss = 0.185173\n",
      " 2885 / 2885 : train loss = 0.361445Eopch:     9 mean_loss = 0.184506\n",
      " 2885 / 2885 : train loss = 0.363009Eopch:    10 mean_loss = 0.183680\n",
      " 2885 / 2885 : train loss = 0.360384Eopch:    11 mean_loss = 0.182974\n",
      " 2885 / 2885 : train loss = 0.359273Eopch:    12 mean_loss = 0.182413\n",
      " 2885 / 2885 : train loss = 0.355195Eopch:    13 mean_loss = 0.181864\n",
      " 2885 / 2885 : train loss = 0.352689Eopch:    14 mean_loss = 0.181513\n",
      " 2885 / 2885 : train loss = 0.351017Eopch:    15 mean_loss = 0.181170\n",
      " 2885 / 2885 : train loss = 0.351432Eopch:    16 mean_loss = 0.180885\n",
      " 2885 / 2885 : train loss = 0.356932Eopch:    17 mean_loss = 0.180598\n",
      " 2885 / 2885 : train loss = 0.354772Eopch:    18 mean_loss = 0.180326\n",
      " 2885 / 2885 : train loss = 0.354787Eopch:    19 mean_loss = 0.180042\n",
      " 2885 / 2885 : train loss = 0.357227Eopch:    20 mean_loss = 0.179768\n",
      " 2885 / 2885 : train loss = 0.354798Eopch:    21 mean_loss = 0.179566\n",
      " 2885 / 2885 : train loss = 0.351782Eopch:    22 mean_loss = 0.179268\n",
      " 2885 / 2885 : train loss = 0.354116Eopch:    23 mean_loss = 0.179026\n",
      " 2885 / 2885 : train loss = 0.355957Eopch:    24 mean_loss = 0.178777\n",
      " 2885 / 2885 : train loss = 0.358199Eopch:    25 mean_loss = 0.178540\n",
      " 2885 / 2885 : train loss = 0.359102Eopch:    26 mean_loss = 0.178287\n",
      " 2885 / 2885 : train loss = 0.360723Eopch:    27 mean_loss = 0.178086\n",
      " 2885 / 2885 : train loss = 0.358058Eopch:    28 mean_loss = 0.177897\n",
      " 2885 / 2885 : train loss = 0.355377Eopch:    29 mean_loss = 0.177729\n",
      " 2885 / 2885 : train loss = 0.359158Eopch:    30 mean_loss = 0.177505\n",
      "best_loss = 0.177505\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = len(CLASS_NAMES) #class numbers\n",
    "model = se_resnet20(num_classes=N_CLASSES).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 30 #'Batch Size': 32\n",
    "for epoch in range(30):#'Max Epoch': 1000\n",
    "    losses = []\n",
    "    losses_tensor = 0.\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()  \n",
    "            losses.append(loss.item())\n",
    "            losses_tensor += loss\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    scheduler.step(losses_tensor.item())\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 853 / 854 The average AUROC is 0.6197\n",
      "The AUROC of Atelectasis is 0.6316\n",
      "The AUROC of Cardiomegaly is 0.5891\n",
      "The AUROC of Effusion is 0.7172\n",
      "The AUROC of Infiltration is 0.6015\n",
      "The AUROC of Mass is 0.5335\n",
      "The AUROC of Nodule is 0.5733\n",
      "The AUROC of Pneumonia is 0.6407\n",
      "The AUROC of Pneumothorax is 0.5874\n",
      "The AUROC of Consolidation is 0.6617\n",
      "The AUROC of Edema is 0.7647\n",
      "The AUROC of Emphysema is 0.5979\n",
      "The AUROC of Fibrosis is 0.6070\n",
      "The AUROC of Pleural_Thickening is 0.6048\n",
      "The AUROC of Hernia is 0.5316\n",
      "The AUROC of No Finding is 0.6529\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch)#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32 / 33 The average AUROC is 0.5997\n",
      "The AUROC of Atelectasis is 0.5439\n",
      "The AUROC of Cardiomegaly is 0.5827\n",
      "The AUROC of Effusion is 0.6926\n",
      "The AUROC of Infiltration is 0.5902\n",
      "The AUROC of Mass is 0.5139\n",
      "The AUROC of Nodule is 0.6947\n",
      "The AUROC of Pneumonia is 0.5324\n",
      "The AUROC of Pneumothorax is 0.6475\n"
     ]
    }
   ],
   "source": [
    "#performance of boxset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(bbY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(bbY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(bbI)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(bbY)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forwordï¼Œ.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
