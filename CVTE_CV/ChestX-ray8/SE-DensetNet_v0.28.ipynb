{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2）Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.filters as filters\n",
    "from scipy.ndimage import binary_dilation\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.patches as patches\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "torch.cuda.set_device(4)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78468 / 78468 The length of trainset is 78468\n",
      "11219 / 11219 The length of validset is 11219\n",
      "22433 / 22433 The length of testset is 22433\n",
      "The length of boxset is 984\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             #transforms.RandomCrop(crop_size),\n",
    "                                             #transforms.RandomHorizontalFlip(),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia','Pneumothorax', \\\n",
    "               'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "#preparing the trainset and  testset\n",
    "trN, trI, trY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt', \"r\") as file_descriptor: #tarinset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            trN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            trY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            trI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),78468))\n",
    "        sys.stdout.flush()\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)   \n",
    "print('The length of trainset is %d'%len(trN))\n",
    "        \n",
    "valN, valI, valY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt', \"r\") as file_descriptor: #valset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            valN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            valY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            valI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(valN),11219))\n",
    "        sys.stdout.flush()\n",
    "valI = np.array(valI)\n",
    "valY = np.array(valY) \n",
    "print('The length of validset is %d'%len(valN))\n",
    "\n",
    "teN, teI, teY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt', \"r\") as file_descriptor: #testset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            teN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            teY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))                    \n",
    "            teI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),22433))\n",
    "        sys.stdout.flush()\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)    \n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "#preparing bounding box dataset\n",
    "boxdata = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_BBox.csv\" , sep=',')\n",
    "boxdata = boxdata[['Image Index','Finding Label','Bbox [x', 'y', 'w', 'h]']]\n",
    "#print('Dataset statistic, records: %d, fields: %d' % (boxdata.shape[0], boxdata.shape[1]))\n",
    "#print(boxdata.columns.values.tolist())\n",
    "bbN, bbI, bbY, bBox = [],[],[],[]\n",
    "for _, row in boxdata.iterrows():\n",
    "    bbN.append(row['Image Index'])\n",
    "    \n",
    "    img = Image_Processing(os.path.join(img_path, row['Image Index']))\n",
    "    bbI.append(img)\n",
    "    \n",
    "    labels = np.zeros(len(CLASS_NAMES))\n",
    "    labels[CLASS_NAMES.index(row['Finding Label'])] = 1\n",
    "    bbY.append(labels)\n",
    "    \n",
    "    bBox.append(np.array([row['Bbox [x'], row['y'], row['w'], row['h]']])) #xywh  \n",
    "print('The length of boxset is %d'%len(bbN))\n",
    "bbI = np.array(bbI)\n",
    "bbY = np.array(bbY)\n",
    "bBox = np.array(bBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/zhouyuangan/SE_DenseNet\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        assert channel > reduction, \"Make sure your input channel bigger than reduction which equals to {}\".format(reduction)\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, channel // reduction),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channel // reduction, channel),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "    \n",
    "__all__ = ['SEDenseNet', 'se_densenet121', 'se_densenet169', 'se_densenet201', 'se_densenet161']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def se_densenet121(t_num_classes=14, pretrained=False, is_strict=False, **kwargs):\n",
    "    r\"\"\"Densenet-121 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SEDenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                     **kwargs)\n",
    "    if pretrained:\n",
    "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "        # They are also in the checkpoints in model_urls. This pattern is used\n",
    "        # to find such keys.\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
    "        for key in list(state_dict.keys()):\n",
    "            res = pattern.match(key)\n",
    "            if res:\n",
    "                new_key = res.group(1) + res.group(2)\n",
    "                state_dict[new_key] = state_dict[key]\n",
    "                del state_dict[key]\n",
    "        model.load_state_dict(state_dict, strict=is_strict)\n",
    "        num_fc_kernels = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(nn.Linear(num_fc_kernels, t_num_classes), nn.Sigmoid())\n",
    "    return model\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        # Add SELayer at here, like SE-PRE block in original paper illustrates\n",
    "        self.add_module(\"selayer\", SELayer(channel=num_input_features)),\n",
    "\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),        \n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class SEDenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
    "\n",
    "        super(SEDenseNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # Add SELayer at first convolution\n",
    "        self.features.add_module(\"SELayer_0a\", SELayer(channel=num_init_features))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            # Add a SELayer \n",
    "            self.features.add_module(\"SELayer_%da\" % (i + 1), SELayer(channel=num_features))\n",
    "\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "\n",
    "            if i != len(block_config) - 1:\n",
    "                # Add a SELayer behind each transition block\n",
    "                self.features.add_module(\"SELayer_%db\" % (i + 1), SELayer(channel=num_features))\n",
    "\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Add SELayer\n",
    "        self.features.add_module(\"SELayer_0b\", SELayer(channel=num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out #torch.sigmoid(out)\n",
    "    \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 351 / 351 : validation loss = 0.129927Eopch:     1 val_loss = 0.161166 avg_auroc= 0.768539\n",
      " 351 / 351 : validation loss = 0.163462Eopch:     2 val_loss = 0.160750 avg_auroc= 0.767045\n",
      " 351 / 351 : validation loss = 0.116292Eopch:     3 val_loss = 0.157894 avg_auroc= 0.784334\n",
      " 351 / 351 : validation loss = 0.128489Eopch:     4 val_loss = 0.155430 avg_auroc= 0.794796\n",
      " 351 / 351 : validation loss = 0.118833Eopch:     5 val_loss = 0.153596 avg_auroc= 0.795274\n",
      " 351 / 351 : validation loss = 0.124126Eopch:     6 val_loss = 0.153504 avg_auroc= 0.801452\n",
      " 351 / 351 : validation loss = 0.107716Eopch:     7 val_loss = 0.151384 avg_auroc= 0.809802\n",
      " 351 / 351 : validation loss = 0.121392Eopch:     8 val_loss = 0.151530 avg_auroc= 0.806710\n",
      " 351 / 351 : validation loss = 0.127934Eopch:     9 val_loss = 0.152678 avg_auroc= 0.807270\n",
      " 351 / 351 : validation loss = 0.119517Eopch:    10 val_loss = 0.151601 avg_auroc= 0.809541\n",
      " 351 / 351 : validation loss = 0.123993Eopch:    11 val_loss = 0.152648 avg_auroc= 0.807740\n",
      " 351 / 351 : validation loss = 0.136044Eopch:    12 val_loss = 0.151215 avg_auroc= 0.813114\n",
      " 351 / 351 : validation loss = 0.134384Eopch:    13 val_loss = 0.151996 avg_auroc= 0.813855\n",
      " 351 / 351 : validation loss = 0.123578Eopch:    14 val_loss = 0.151867 avg_auroc= 0.805684\n",
      " 351 / 351 : validation loss = 0.114801Eopch:    15 val_loss = 0.150974 avg_auroc= 0.813709\n",
      " 351 / 351 : validation loss = 0.142434Eopch:    16 val_loss = 0.151668 avg_auroc= 0.814261\n",
      " 351 / 351 : validation loss = 0.119655Eopch:    17 val_loss = 0.153436 avg_auroc= 0.808560\n",
      " 351 / 351 : validation loss = 0.109491Eopch:    18 val_loss = 0.151558 avg_auroc= 0.811567\n",
      " 351 / 351 : validation loss = 0.109491Eopch:    19 val_loss = 0.150963 avg_auroc= 0.812997\n",
      " 351 / 351 : validation loss = 0.127536Eopch:    20 val_loss = 0.152869 avg_auroc= 0.806198\n",
      " 351 / 351 : validation loss = 0.127961Eopch:    21 val_loss = 0.151178 avg_auroc= 0.810952\n",
      " 351 / 351 : validation loss = 0.119927Eopch:    22 val_loss = 0.148795 avg_auroc= 0.820684\n",
      " 351 / 351 : validation loss = 0.118708Eopch:    23 val_loss = 0.149740 avg_auroc= 0.818727\n",
      " 351 / 351 : validation loss = 0.119031Eopch:    24 val_loss = 0.150363 avg_auroc= 0.817502\n",
      " 351 / 351 : validation loss = 0.116146Eopch:    25 val_loss = 0.150784 avg_auroc= 0.816213\n",
      " 351 / 351 : validation loss = 0.123359Eopch:    26 val_loss = 0.151889 avg_auroc= 0.815220\n",
      " 351 / 351 : validation loss = 0.122807Eopch:    27 val_loss = 0.153201 avg_auroc= 0.810857\n",
      " 351 / 351 : validation loss = 0.117691Eopch:    28 val_loss = 0.153969 avg_auroc= 0.809691\n",
      " 351 / 351 : validation loss = 0.121046Eopch:    29 val_loss = 0.154334 avg_auroc= 0.808531\n",
      " 351 / 351 : validation loss = 0.122939Eopch:    30 val_loss = 0.155006 avg_auroc= 0.808258\n",
      " 351 / 351 : validation loss = 0.118747Eopch:    31 val_loss = 0.155259 avg_auroc= 0.807907\n",
      " 351 / 351 : validation loss = 0.119094Eopch:    32 val_loss = 0.155144 avg_auroc= 0.806515\n",
      " 351 / 351 : validation loss = 0.121725Eopch:    33 val_loss = 0.155777 avg_auroc= 0.806444\n",
      " 351 / 351 : validation loss = 0.120955Eopch:    34 val_loss = 0.156099 avg_auroc= 0.806443\n",
      " 351 / 351 : validation loss = 0.121832Eopch:    35 val_loss = 0.156350 avg_auroc= 0.806219\n",
      " 351 / 351 : validation loss = 0.123828Eopch:    36 val_loss = 0.156296 avg_auroc= 0.805396\n",
      " 351 / 351 : validation loss = 0.116445Eopch:    37 val_loss = 0.156277 avg_auroc= 0.805650\n",
      " 351 / 351 : validation loss = 0.118895Eopch:    38 val_loss = 0.156851 avg_auroc= 0.805915\n",
      " 351 / 351 : validation loss = 0.121695Eopch:    39 val_loss = 0.156207 avg_auroc= 0.805267\n",
      " 351 / 351 : validation loss = 0.122238Eopch:    40 val_loss = 0.156447 avg_auroc= 0.805368\n",
      " 351 / 351 : validation loss = 0.117386Eopch:    41 val_loss = 0.156430 avg_auroc= 0.805849\n",
      " 351 / 351 : validation loss = 0.120941Eopch:    42 val_loss = 0.156431 avg_auroc= 0.804083\n",
      " 351 / 351 : validation loss = 0.119012Eopch:    43 val_loss = 0.156569 avg_auroc= 0.803953\n",
      " 351 / 351 : validation loss = 0.119017Eopch:    44 val_loss = 0.156293 avg_auroc= 0.805576\n",
      " 351 / 351 : validation loss = 0.123476Eopch:    45 val_loss = 0.156463 avg_auroc= 0.803753\n",
      " 351 / 351 : validation loss = 0.114668Eopch:    46 val_loss = 0.156047 avg_auroc= 0.805208\n",
      " 351 / 351 : validation loss = 0.118429Eopch:    47 val_loss = 0.156955 avg_auroc= 0.805641\n",
      " 351 / 351 : validation loss = 0.118812Eopch:    48 val_loss = 0.156466 avg_auroc= 0.806019\n",
      " 351 / 351 : validation loss = 0.120642Eopch:    49 val_loss = 0.156614 avg_auroc= 0.804428\n",
      " 351 / 351 : validation loss = 0.120287Eopch:    50 val_loss = 0.156349 avg_auroc= 0.805139\n",
      "best_loss = 0.148795 best_auroc = 0.820684\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = len(CLASS_NAMES) #class numbers\n",
    "model = se_densenet121(t_num_classes=N_CLASSES, pretrained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "AUROC_best = 0.\n",
    "batchSize = 32 #'Batch Size': 32\n",
    "for epoch in range(50):#'Max Epoch': 50\n",
    "    model.train()  # set network as train mode\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    num_batches = len(shuffled_idx) // batchSize + 1\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(shuffled_idx), (i+1)*batchSize])\n",
    "            selected_idx = shuffled_idx[min_idx:max_idx]\n",
    "            I_batch = torch.from_numpy(trI[selected_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[selected_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrix， .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred = torch.FloatTensor().cuda()\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch)#forword， .permute(0, 3, 1, 2)\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            gt = torch.cat((gt, y_batch), 0)\n",
    "            pred = torch.cat((pred, y_outputs.data), 0)\n",
    "            sys.stdout.write('\\r {} / {} : validation loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    AUROCs = compute_AUCs(gt, pred)\n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print(\"Eopch: %5d val_loss = %.6f avg_auroc= %.6f\" % (epoch + 1, np.mean(loss_val), AUROC_avg))\n",
    "    #if np.mean(loss_val) < best_loss:\n",
    "    if AUROC_avg > AUROC_best:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        AUROC_best = AUROC_avg\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f best_auroc = %0.6f\" % (best_loss, AUROC_best))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 701 / 702 The average AUROC is 0.8205\n",
      "The AUROC of Atelectasis is 0.7963\n",
      "The AUROC of Cardiomegaly is 0.9085\n",
      "The AUROC of Effusion is 0.8769\n",
      "The AUROC of Infiltration is 0.6974\n",
      "The AUROC of Mass is 0.8144\n",
      "The AUROC of Nodule is 0.7509\n",
      "The AUROC of Pneumonia is 0.7566\n",
      "The AUROC of Pneumothorax is 0.8467\n",
      "The AUROC of Consolidation is 0.7996\n",
      "The AUROC of Edema is 0.8864\n",
      "The AUROC of Emphysema is 0.8907\n",
      "The AUROC of Fibrosis is 0.8041\n",
      "The AUROC of Pleural_Thickening is 0.7547\n",
      "The AUROC of Hernia is 0.9035\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forword，.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30 / 31 The average AUROC is 0.7817\n",
      "The AUROC of Atelectasis is 0.7114\n",
      "The AUROC of Cardiomegaly is 0.9380\n",
      "The AUROC of Effusion is 0.7939\n",
      "The AUROC of Infiltration is 0.6930\n",
      "The AUROC of Mass is 0.7889\n",
      "The AUROC of Nodule is 0.7756\n",
      "The AUROC of Pneumonia is 0.6539\n",
      "The AUROC of Pneumothorax is 0.8994\n"
     ]
    }
   ],
   "source": [
    "#performance of box\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(bbY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(bbY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(bbI)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(bbY)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forword，.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
