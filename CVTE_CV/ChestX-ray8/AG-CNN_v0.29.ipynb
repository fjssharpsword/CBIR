{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.filters as filters\n",
    "from scipy.ndimage import binary_dilation\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.patches as patches\n",
    "from collections import OrderedDict\n",
    "from skimage.measure import label\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/Ien001/AG-CNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# encoding: utf-8\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from collections import OrderedDict\n",
    " \n",
    "__all__ = ['DenseNet', 'Densenet121_AG']\n",
    " \n",
    "model_urls = {\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
    "}\n",
    "\n",
    "def Densenet121_AG(pretrained=False, **kwargs):\n",
    "    r\"\"\"Densenet-121 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                     **kwargs)\n",
    "    if pretrained:\n",
    "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "        # They are also in the checkpoints in model_urls. This pattern is used\n",
    "        # to find such keys.\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
    "        for key in list(state_dict.keys()):\n",
    "            res = pattern.match(key)\n",
    "            if res:\n",
    "                new_key = res.group(1) + res.group(2)\n",
    "                state_dict[new_key] = state_dict[key]\n",
    "                del state_dict[key]\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    " \n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    " \n",
    " \n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    " \n",
    " \n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    " \n",
    " \n",
    "class DenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
    " \n",
    "        super(DenseNet, self).__init__()\n",
    " \n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    " \n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    " \n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    " \n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    " \n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out_after_pooling = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out_after_pooling)\n",
    "        out = self.Sigmoid(out)\n",
    "        return out, features, out_after_pooling\n",
    "\n",
    "\n",
    "class Fusion_Branch(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Fusion_Branch, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, global_pool, local_pool):\n",
    "        #fusion = torch.cat((global_pool.unsqueeze(2), local_pool.unsqueeze(2)), 2).cuda()\n",
    "        #fusion = fusion.max(2)[0]#.squeeze(2).cuda()\n",
    "        #print(fusion.shape)\n",
    "        fusion = torch.cat((global_pool,local_pool), 1).cuda()\n",
    "        fusion_var = torch.autograd.Variable(fusion)\n",
    "        x = self.fc(fusion_var)\n",
    "        x = self.Sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    def __init__(self, data_dir, image_list_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        with open(image_list_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                items = line.split()\n",
    "                image_name= items[0].split('/')[1]\n",
    "                label = items[1:]\n",
    "                label = [int(i) for i in label]\n",
    "                image_name = os.path.join(data_dir, image_name)\n",
    "                image_names.append(image_name)\n",
    "                labels.append(label)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************load data********************\n",
      "********************load data succeed!********************\n",
      "********************load model********************\n",
      "=> no checkpoint found\n",
      "********************load model succeed!********************\n",
      "********************begin training!********************\n",
      "Epoch 1/50\n",
      "----------\n",
      "step: 0 totalloss: 0.705 loss1: 0.709 loss2: 0.662 loss3: 0.719\n",
      "step: 500 totalloss: 0.656 loss1: 0.709 loss2: 0.661 loss3: 0.229\n",
      "step: 1000 totalloss: 0.647 loss1: 0.706 loss2: 0.662 loss3: 0.153\n",
      "step: 1500 totalloss: 0.639 loss1: 0.701 loss2: 0.663 loss3: 0.117\n",
      "step: 2000 totalloss: 0.646 loss1: 0.702 loss2: 0.663 loss3: 0.177\n",
      " Epoch over  Loss: 0.64864\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.475\n",
      "The AUROC of Atelectasis is 0.5033\n",
      "The AUROC of Cardiomegaly is 0.4456\n",
      "The AUROC of Effusion is 0.4767\n",
      "The AUROC of Infiltration is 0.4672\n",
      "The AUROC of Mass is 0.4967\n",
      "The AUROC of Nodule is 0.4978\n",
      "The AUROC of Pneumonia is 0.5419\n",
      "The AUROC of Pneumothorax is 0.5104\n",
      "The AUROC of Consolidation is 0.4615\n",
      "The AUROC of Edema is 0.3776\n",
      "The AUROC of Emphysema is 0.4315\n",
      "The AUROC of Fibrosis is 0.4683\n",
      "The AUROC of Pleural_Thickening is 0.5080\n",
      "The AUROC of Hernia is 0.4587\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.499\n",
      "The AUROC of Atelectasis is 0.5724\n",
      "The AUROC of Cardiomegaly is 0.5024\n",
      "The AUROC of Effusion is 0.4713\n",
      "The AUROC of Infiltration is 0.5008\n",
      "The AUROC of Mass is 0.4918\n",
      "The AUROC of Nodule is 0.4851\n",
      "The AUROC of Pneumonia is 0.5293\n",
      "The AUROC of Pneumothorax is 0.4594\n",
      "The AUROC of Consolidation is 0.4566\n",
      "The AUROC of Edema is 0.5049\n",
      "The AUROC of Emphysema is 0.5149\n",
      "The AUROC of Fibrosis is 0.4982\n",
      "The AUROC of Pleural_Thickening is 0.5059\n",
      "The AUROC of Hernia is 0.4947\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.648\n",
      "The AUROC of Atelectasis is 0.6809\n",
      "The AUROC of Cardiomegaly is 0.6684\n",
      "The AUROC of Effusion is 0.7388\n",
      "The AUROC of Infiltration is 0.6123\n",
      "The AUROC of Mass is 0.5637\n",
      "The AUROC of Nodule is 0.5262\n",
      "The AUROC of Pneumonia is 0.6175\n",
      "The AUROC of Pneumothorax is 0.6545\n",
      "The AUROC of Consolidation is 0.7179\n",
      "The AUROC of Edema is 0.7877\n",
      "The AUROC of Emphysema is 0.6056\n",
      "The AUROC of Fibrosis is 0.6390\n",
      "The AUROC of Pleural_Thickening is 0.5848\n",
      "The AUROC of Hernia is 0.6739\n",
      "Training one epoch complete in 74m 18s\n",
      "Epoch 2/50\n",
      "----------\n",
      "step: 0 totalloss: 0.643 loss1: 0.699 loss2: 0.662 loss3: 0.169\n",
      "step: 500 totalloss: 0.651 loss1: 0.701 loss2: 0.663 loss3: 0.241\n",
      "step: 1000 totalloss: 0.636 loss1: 0.699 loss2: 0.658 loss3: 0.109\n",
      "step: 1500 totalloss: 0.645 loss1: 0.700 loss2: 0.658 loss3: 0.185\n",
      "step: 2000 totalloss: 0.635 loss1: 0.697 loss2: 0.656 loss3: 0.124\n",
      " Epoch over  Loss: 0.64378\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.474\n",
      "The AUROC of Atelectasis is 0.5047\n",
      "The AUROC of Cardiomegaly is 0.4483\n",
      "The AUROC of Effusion is 0.4779\n",
      "The AUROC of Infiltration is 0.4700\n",
      "The AUROC of Mass is 0.4952\n",
      "The AUROC of Nodule is 0.5009\n",
      "The AUROC of Pneumonia is 0.5397\n",
      "The AUROC of Pneumothorax is 0.5161\n",
      "The AUROC of Consolidation is 0.4683\n",
      "The AUROC of Edema is 0.3642\n",
      "The AUROC of Emphysema is 0.4311\n",
      "The AUROC of Fibrosis is 0.4699\n",
      "The AUROC of Pleural_Thickening is 0.5125\n",
      "The AUROC of Hernia is 0.4324\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.507\n",
      "The AUROC of Atelectasis is 0.5715\n",
      "The AUROC of Cardiomegaly is 0.5167\n",
      "The AUROC of Effusion is 0.4789\n",
      "The AUROC of Infiltration is 0.5075\n",
      "The AUROC of Mass is 0.4788\n",
      "The AUROC of Nodule is 0.4793\n",
      "The AUROC of Pneumonia is 0.5296\n",
      "The AUROC of Pneumothorax is 0.4739\n",
      "The AUROC of Consolidation is 0.4819\n",
      "The AUROC of Edema is 0.5236\n",
      "The AUROC of Emphysema is 0.5154\n",
      "The AUROC of Fibrosis is 0.5223\n",
      "The AUROC of Pleural_Thickening is 0.5192\n",
      "The AUROC of Hernia is 0.4942\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.652\n",
      "The AUROC of Atelectasis is 0.6781\n",
      "The AUROC of Cardiomegaly is 0.6973\n",
      "The AUROC of Effusion is 0.7413\n",
      "The AUROC of Infiltration is 0.6119\n",
      "The AUROC of Mass is 0.5743\n",
      "The AUROC of Nodule is 0.5353\n",
      "The AUROC of Pneumonia is 0.5806\n",
      "The AUROC of Pneumothorax is 0.6589\n",
      "The AUROC of Consolidation is 0.7340\n",
      "The AUROC of Edema is 0.7942\n",
      "The AUROC of Emphysema is 0.6039\n",
      "The AUROC of Fibrosis is 0.6468\n",
      "The AUROC of Pleural_Thickening is 0.6136\n",
      "The AUROC of Hernia is 0.6528\n",
      "Training one epoch complete in 65m 52s\n",
      "Epoch 3/50\n",
      "----------\n",
      "step: 0 totalloss: 0.637 loss1: 0.698 loss2: 0.657 loss3: 0.129\n",
      "step: 500 totalloss: 0.642 loss1: 0.695 loss2: 0.659 loss3: 0.201\n",
      "step: 1000 totalloss: 0.647 loss1: 0.697 loss2: 0.651 loss3: 0.240\n",
      "step: 1500 totalloss: 0.636 loss1: 0.693 loss2: 0.654 loss3: 0.159\n",
      "step: 2000 totalloss: 0.636 loss1: 0.694 loss2: 0.653 loss3: 0.154\n",
      " Epoch over  Loss: 0.63918\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.475\n",
      "The AUROC of Atelectasis is 0.4978\n",
      "The AUROC of Cardiomegaly is 0.4537\n",
      "The AUROC of Effusion is 0.4786\n",
      "The AUROC of Infiltration is 0.4702\n",
      "The AUROC of Mass is 0.5036\n",
      "The AUROC of Nodule is 0.5030\n",
      "The AUROC of Pneumonia is 0.5303\n",
      "The AUROC of Pneumothorax is 0.5106\n",
      "The AUROC of Consolidation is 0.4736\n",
      "The AUROC of Edema is 0.3576\n",
      "The AUROC of Emphysema is 0.4328\n",
      "The AUROC of Fibrosis is 0.4602\n",
      "The AUROC of Pleural_Thickening is 0.5115\n",
      "The AUROC of Hernia is 0.4595\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.504\n",
      "The AUROC of Atelectasis is 0.5840\n",
      "The AUROC of Cardiomegaly is 0.5083\n",
      "The AUROC of Effusion is 0.4752\n",
      "The AUROC of Infiltration is 0.4973\n",
      "The AUROC of Mass is 0.4826\n",
      "The AUROC of Nodule is 0.4679\n",
      "The AUROC of Pneumonia is 0.5178\n",
      "The AUROC of Pneumothorax is 0.4651\n",
      "The AUROC of Consolidation is 0.4666\n",
      "The AUROC of Edema is 0.5553\n",
      "The AUROC of Emphysema is 0.5112\n",
      "The AUROC of Fibrosis is 0.5028\n",
      "The AUROC of Pleural_Thickening is 0.5116\n",
      "The AUROC of Hernia is 0.5090\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.649\n",
      "The AUROC of Atelectasis is 0.6783\n",
      "The AUROC of Cardiomegaly is 0.7026\n",
      "The AUROC of Effusion is 0.7565\n",
      "The AUROC of Infiltration is 0.6142\n",
      "The AUROC of Mass is 0.5830\n",
      "The AUROC of Nodule is 0.5308\n",
      "The AUROC of Pneumonia is 0.6006\n",
      "The AUROC of Pneumothorax is 0.6784\n",
      "The AUROC of Consolidation is 0.7286\n",
      "The AUROC of Edema is 0.8066\n",
      "The AUROC of Emphysema is 0.6209\n",
      "The AUROC of Fibrosis is 0.6362\n",
      "The AUROC of Pleural_Thickening is 0.6161\n",
      "The AUROC of Hernia is 0.5334\n",
      "Training one epoch complete in 65m 15s\n",
      "Epoch 4/50\n",
      "----------\n",
      "step: 0 totalloss: 0.633 loss1: 0.688 loss2: 0.652 loss3: 0.168\n",
      "step: 500 totalloss: 0.629 loss1: 0.691 loss2: 0.650 loss3: 0.111\n",
      "step: 1000 totalloss: 0.639 loss1: 0.693 loss2: 0.650 loss3: 0.199\n",
      "step: 1500 totalloss: 0.637 loss1: 0.690 loss2: 0.650 loss3: 0.197\n",
      "step: 2000 totalloss: 0.626 loss1: 0.685 loss2: 0.647 loss3: 0.129\n",
      " Epoch over  Loss: 0.63465\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.477\n",
      "The AUROC of Atelectasis is 0.5014\n",
      "The AUROC of Cardiomegaly is 0.4490\n",
      "The AUROC of Effusion is 0.4748\n",
      "The AUROC of Infiltration is 0.4782\n",
      "The AUROC of Mass is 0.5032\n",
      "The AUROC of Nodule is 0.5019\n",
      "The AUROC of Pneumonia is 0.5307\n",
      "The AUROC of Pneumothorax is 0.5138\n",
      "The AUROC of Consolidation is 0.4728\n",
      "The AUROC of Edema is 0.3738\n",
      "The AUROC of Emphysema is 0.4320\n",
      "The AUROC of Fibrosis is 0.4617\n",
      "The AUROC of Pleural_Thickening is 0.5139\n",
      "The AUROC of Hernia is 0.4647\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.502\n",
      "The AUROC of Atelectasis is 0.5833\n",
      "The AUROC of Cardiomegaly is 0.5079\n",
      "The AUROC of Effusion is 0.4796\n",
      "The AUROC of Infiltration is 0.4977\n",
      "The AUROC of Mass is 0.4765\n",
      "The AUROC of Nodule is 0.4767\n",
      "The AUROC of Pneumonia is 0.5250\n",
      "The AUROC of Pneumothorax is 0.4582\n",
      "The AUROC of Consolidation is 0.4729\n",
      "The AUROC of Edema is 0.5423\n",
      "The AUROC of Emphysema is 0.5117\n",
      "The AUROC of Fibrosis is 0.4969\n",
      "The AUROC of Pleural_Thickening is 0.4978\n",
      "The AUROC of Hernia is 0.5032\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.656\n",
      "The AUROC of Atelectasis is 0.6883\n",
      "The AUROC of Cardiomegaly is 0.6950\n",
      "The AUROC of Effusion is 0.7517\n",
      "The AUROC of Infiltration is 0.6187\n",
      "The AUROC of Mass is 0.5820\n",
      "The AUROC of Nodule is 0.5389\n",
      "The AUROC of Pneumonia is 0.6181\n",
      "The AUROC of Pneumothorax is 0.6541\n",
      "The AUROC of Consolidation is 0.7332\n",
      "The AUROC of Edema is 0.8076\n",
      "The AUROC of Emphysema is 0.6012\n",
      "The AUROC of Fibrosis is 0.6491\n",
      "The AUROC of Pleural_Thickening is 0.5975\n",
      "The AUROC of Hernia is 0.6516\n",
      "Training one epoch complete in 65m 20s\n",
      "Epoch 5/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 totalloss: 0.634 loss1: 0.685 loss2: 0.650 loss3: 0.204\n",
      "step: 500 totalloss: 0.627 loss1: 0.686 loss2: 0.648 loss3: 0.136\n",
      "step: 1000 totalloss: 0.627 loss1: 0.682 loss2: 0.646 loss3: 0.165\n",
      "step: 1500 totalloss: 0.636 loss1: 0.685 loss2: 0.643 loss3: 0.233\n",
      "step: 2000 totalloss: 0.631 loss1: 0.686 loss2: 0.642 loss3: 0.180\n",
      " Epoch over  Loss: 0.63019\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.479\n",
      "The AUROC of Atelectasis is 0.5026\n",
      "The AUROC of Cardiomegaly is 0.4546\n",
      "The AUROC of Effusion is 0.4770\n",
      "The AUROC of Infiltration is 0.4799\n",
      "The AUROC of Mass is 0.4986\n",
      "The AUROC of Nodule is 0.5024\n",
      "The AUROC of Pneumonia is 0.5410\n",
      "The AUROC of Pneumothorax is 0.5231\n",
      "The AUROC of Consolidation is 0.4689\n",
      "The AUROC of Edema is 0.4057\n",
      "The AUROC of Emphysema is 0.4308\n",
      "The AUROC of Fibrosis is 0.4638\n",
      "The AUROC of Pleural_Thickening is 0.5144\n",
      "The AUROC of Hernia is 0.4491\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.504\n",
      "The AUROC of Atelectasis is 0.5851\n",
      "The AUROC of Cardiomegaly is 0.5038\n",
      "The AUROC of Effusion is 0.4726\n",
      "The AUROC of Infiltration is 0.5067\n",
      "The AUROC of Mass is 0.4887\n",
      "The AUROC of Nodule is 0.4811\n",
      "The AUROC of Pneumonia is 0.5344\n",
      "The AUROC of Pneumothorax is 0.4587\n",
      "The AUROC of Consolidation is 0.4537\n",
      "The AUROC of Edema is 0.5405\n",
      "The AUROC of Emphysema is 0.5122\n",
      "The AUROC of Fibrosis is 0.4963\n",
      "The AUROC of Pleural_Thickening is 0.4830\n",
      "The AUROC of Hernia is 0.5367\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.661\n",
      "The AUROC of Atelectasis is 0.6818\n",
      "The AUROC of Cardiomegaly is 0.7109\n",
      "The AUROC of Effusion is 0.7500\n",
      "The AUROC of Infiltration is 0.6153\n",
      "The AUROC of Mass is 0.5835\n",
      "The AUROC of Nodule is 0.5414\n",
      "The AUROC of Pneumonia is 0.6116\n",
      "The AUROC of Pneumothorax is 0.6717\n",
      "The AUROC of Consolidation is 0.7413\n",
      "The AUROC of Edema is 0.8080\n",
      "The AUROC of Emphysema is 0.5774\n",
      "The AUROC of Fibrosis is 0.6477\n",
      "The AUROC of Pleural_Thickening is 0.6225\n",
      "The AUROC of Hernia is 0.6853\n",
      "Training one epoch complete in 65m 55s\n",
      "Epoch 6/50\n",
      "----------\n",
      "step: 0 totalloss: 0.632 loss1: 0.680 loss2: 0.642 loss3: 0.235\n",
      "step: 500 totalloss: 0.628 loss1: 0.682 loss2: 0.640 loss3: 0.189\n",
      "step: 1000 totalloss: 0.618 loss1: 0.678 loss2: 0.641 loss3: 0.119\n",
      "step: 1500 totalloss: 0.623 loss1: 0.682 loss2: 0.636 loss3: 0.142\n",
      "step: 2000 totalloss: 0.623 loss1: 0.679 loss2: 0.641 loss3: 0.162\n",
      " Epoch over  Loss: 0.62579\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.480\n",
      "The AUROC of Atelectasis is 0.5045\n",
      "The AUROC of Cardiomegaly is 0.4467\n",
      "The AUROC of Effusion is 0.4780\n",
      "The AUROC of Infiltration is 0.4892\n",
      "The AUROC of Mass is 0.4983\n",
      "The AUROC of Nodule is 0.5042\n",
      "The AUROC of Pneumonia is 0.5364\n",
      "The AUROC of Pneumothorax is 0.5169\n",
      "The AUROC of Consolidation is 0.4788\n",
      "The AUROC of Edema is 0.3999\n",
      "The AUROC of Emphysema is 0.4311\n",
      "The AUROC of Fibrosis is 0.4741\n",
      "The AUROC of Pleural_Thickening is 0.5175\n",
      "The AUROC of Hernia is 0.4388\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.505\n",
      "The AUROC of Atelectasis is 0.5752\n",
      "The AUROC of Cardiomegaly is 0.5049\n",
      "The AUROC of Effusion is 0.4780\n",
      "The AUROC of Infiltration is 0.4987\n",
      "The AUROC of Mass is 0.4827\n",
      "The AUROC of Nodule is 0.4868\n",
      "The AUROC of Pneumonia is 0.5233\n",
      "The AUROC of Pneumothorax is 0.4654\n",
      "The AUROC of Consolidation is 0.4589\n",
      "The AUROC of Edema is 0.5467\n",
      "The AUROC of Emphysema is 0.5172\n",
      "The AUROC of Fibrosis is 0.5128\n",
      "The AUROC of Pleural_Thickening is 0.5054\n",
      "The AUROC of Hernia is 0.5108\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.667\n",
      "The AUROC of Atelectasis is 0.6794\n",
      "The AUROC of Cardiomegaly is 0.6751\n",
      "The AUROC of Effusion is 0.7576\n",
      "The AUROC of Infiltration is 0.6233\n",
      "The AUROC of Mass is 0.5931\n",
      "The AUROC of Nodule is 0.5446\n",
      "The AUROC of Pneumonia is 0.6192\n",
      "The AUROC of Pneumothorax is 0.6869\n",
      "The AUROC of Consolidation is 0.7395\n",
      "The AUROC of Edema is 0.8090\n",
      "The AUROC of Emphysema is 0.6131\n",
      "The AUROC of Fibrosis is 0.6397\n",
      "The AUROC of Pleural_Thickening is 0.6166\n",
      "The AUROC of Hernia is 0.7385\n",
      "Training one epoch complete in 66m 13s\n",
      "Epoch 7/50\n",
      "----------\n",
      "step: 0 totalloss: 0.626 loss1: 0.679 loss2: 0.642 loss3: 0.190\n",
      "step: 500 totalloss: 0.623 loss1: 0.675 loss2: 0.639 loss3: 0.193\n",
      "step: 1000 totalloss: 0.614 loss1: 0.672 loss2: 0.638 loss3: 0.123\n",
      "step: 1500 totalloss: 0.618 loss1: 0.674 loss2: 0.637 loss3: 0.147\n",
      "step: 2000 totalloss: 0.621 loss1: 0.670 loss2: 0.635 loss3: 0.216\n",
      " Epoch over  Loss: 0.62139\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.479\n",
      "The AUROC of Atelectasis is 0.5063\n",
      "The AUROC of Cardiomegaly is 0.4469\n",
      "The AUROC of Effusion is 0.4792\n",
      "The AUROC of Infiltration is 0.4891\n",
      "The AUROC of Mass is 0.5026\n",
      "The AUROC of Nodule is 0.5016\n",
      "The AUROC of Pneumonia is 0.5405\n",
      "The AUROC of Pneumothorax is 0.5186\n",
      "The AUROC of Consolidation is 0.4871\n",
      "The AUROC of Edema is 0.4024\n",
      "The AUROC of Emphysema is 0.4271\n",
      "The AUROC of Fibrosis is 0.4833\n",
      "The AUROC of Pleural_Thickening is 0.5232\n",
      "The AUROC of Hernia is 0.4044\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.499\n",
      "The AUROC of Atelectasis is 0.5805\n",
      "The AUROC of Cardiomegaly is 0.4943\n",
      "The AUROC of Effusion is 0.4817\n",
      "The AUROC of Infiltration is 0.5082\n",
      "The AUROC of Mass is 0.4894\n",
      "The AUROC of Nodule is 0.4630\n",
      "The AUROC of Pneumonia is 0.5232\n",
      "The AUROC of Pneumothorax is 0.4595\n",
      "The AUROC of Consolidation is 0.4622\n",
      "The AUROC of Edema is 0.5070\n",
      "The AUROC of Emphysema is 0.5305\n",
      "The AUROC of Fibrosis is 0.5012\n",
      "The AUROC of Pleural_Thickening is 0.4906\n",
      "The AUROC of Hernia is 0.4943\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.645\n",
      "The AUROC of Atelectasis is 0.6772\n",
      "The AUROC of Cardiomegaly is 0.6538\n",
      "The AUROC of Effusion is 0.7552\n",
      "The AUROC of Infiltration is 0.6235\n",
      "The AUROC of Mass is 0.5871\n",
      "The AUROC of Nodule is 0.5448\n",
      "The AUROC of Pneumonia is 0.5808\n",
      "The AUROC of Pneumothorax is 0.6774\n",
      "The AUROC of Consolidation is 0.7363\n",
      "The AUROC of Edema is 0.8063\n",
      "The AUROC of Emphysema is 0.6160\n",
      "The AUROC of Fibrosis is 0.6449\n",
      "The AUROC of Pleural_Thickening is 0.6042\n",
      "The AUROC of Hernia is 0.5221\n",
      "Training one epoch complete in 65m 50s\n",
      "Epoch 8/50\n",
      "----------\n",
      "step: 0 totalloss: 0.620 loss1: 0.668 loss2: 0.638 loss3: 0.223\n",
      "step: 500 totalloss: 0.623 loss1: 0.675 loss2: 0.630 loss3: 0.203\n",
      "step: 1000 totalloss: 0.617 loss1: 0.670 loss2: 0.632 loss3: 0.180\n",
      "step: 1500 totalloss: 0.612 loss1: 0.670 loss2: 0.630 loss3: 0.131\n",
      "step: 2000 totalloss: 0.615 loss1: 0.667 loss2: 0.630 loss3: 0.186\n",
      " Epoch over  Loss: 0.61707\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.480\n",
      "The AUROC of Atelectasis is 0.4997\n",
      "The AUROC of Cardiomegaly is 0.4560\n",
      "The AUROC of Effusion is 0.4805\n",
      "The AUROC of Infiltration is 0.4979\n",
      "The AUROC of Mass is 0.4960\n",
      "The AUROC of Nodule is 0.5093\n",
      "The AUROC of Pneumonia is 0.5324\n",
      "The AUROC of Pneumothorax is 0.5320\n",
      "The AUROC of Consolidation is 0.4669\n",
      "The AUROC of Edema is 0.3938\n",
      "The AUROC of Emphysema is 0.4370\n",
      "The AUROC of Fibrosis is 0.4606\n",
      "The AUROC of Pleural_Thickening is 0.5230\n",
      "The AUROC of Hernia is 0.4418\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.506\n",
      "The AUROC of Atelectasis is 0.5763\n",
      "The AUROC of Cardiomegaly is 0.5026\n",
      "The AUROC of Effusion is 0.4798\n",
      "The AUROC of Infiltration is 0.4926\n",
      "The AUROC of Mass is 0.4899\n",
      "The AUROC of Nodule is 0.4830\n",
      "The AUROC of Pneumonia is 0.5231\n",
      "The AUROC of Pneumothorax is 0.4600\n",
      "The AUROC of Consolidation is 0.4577\n",
      "The AUROC of Edema is 0.5595\n",
      "The AUROC of Emphysema is 0.5385\n",
      "The AUROC of Fibrosis is 0.4722\n",
      "The AUROC of Pleural_Thickening is 0.4976\n",
      "The AUROC of Hernia is 0.5506\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.657\n",
      "The AUROC of Atelectasis is 0.6854\n",
      "The AUROC of Cardiomegaly is 0.6603\n",
      "The AUROC of Effusion is 0.7565\n",
      "The AUROC of Infiltration is 0.6208\n",
      "The AUROC of Mass is 0.5769\n",
      "The AUROC of Nodule is 0.5350\n",
      "The AUROC of Pneumonia is 0.6116\n",
      "The AUROC of Pneumothorax is 0.6814\n",
      "The AUROC of Consolidation is 0.7099\n",
      "The AUROC of Edema is 0.8061\n",
      "The AUROC of Emphysema is 0.6088\n",
      "The AUROC of Fibrosis is 0.6240\n",
      "The AUROC of Pleural_Thickening is 0.6280\n",
      "The AUROC of Hernia is 0.6983\n",
      "Training one epoch complete in 65m 43s\n",
      "Epoch 9/50\n",
      "----------\n",
      "step: 0 totalloss: 0.619 loss1: 0.668 loss2: 0.635 loss3: 0.214\n",
      "step: 500 totalloss: 0.609 loss1: 0.662 loss2: 0.631 loss3: 0.161\n",
      "step: 1000 totalloss: 0.610 loss1: 0.665 loss2: 0.626 loss3: 0.150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1500 totalloss: 0.613 loss1: 0.664 loss2: 0.626 loss3: 0.187\n",
      "step: 2000 totalloss: 0.607 loss1: 0.661 loss2: 0.625 loss3: 0.159\n",
      " Epoch over  Loss: 0.61272\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.480\n",
      "The AUROC of Atelectasis is 0.5043\n",
      "The AUROC of Cardiomegaly is 0.4546\n",
      "The AUROC of Effusion is 0.4831\n",
      "The AUROC of Infiltration is 0.5045\n",
      "The AUROC of Mass is 0.4959\n",
      "The AUROC of Nodule is 0.5047\n",
      "The AUROC of Pneumonia is 0.5397\n",
      "The AUROC of Pneumothorax is 0.5286\n",
      "The AUROC of Consolidation is 0.4707\n",
      "The AUROC of Edema is 0.4034\n",
      "The AUROC of Emphysema is 0.4336\n",
      "The AUROC of Fibrosis is 0.4650\n",
      "The AUROC of Pleural_Thickening is 0.5225\n",
      "The AUROC of Hernia is 0.4159\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.507\n",
      "The AUROC of Atelectasis is 0.5761\n",
      "The AUROC of Cardiomegaly is 0.5062\n",
      "The AUROC of Effusion is 0.4803\n",
      "The AUROC of Infiltration is 0.5023\n",
      "The AUROC of Mass is 0.4876\n",
      "The AUROC of Nodule is 0.4823\n",
      "The AUROC of Pneumonia is 0.5307\n",
      "The AUROC of Pneumothorax is 0.4898\n",
      "The AUROC of Consolidation is 0.4653\n",
      "The AUROC of Edema is 0.5362\n",
      "The AUROC of Emphysema is 0.5099\n",
      "The AUROC of Fibrosis is 0.5007\n",
      "The AUROC of Pleural_Thickening is 0.4943\n",
      "The AUROC of Hernia is 0.5423\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.665\n",
      "The AUROC of Atelectasis is 0.6871\n",
      "The AUROC of Cardiomegaly is 0.7024\n",
      "The AUROC of Effusion is 0.7486\n",
      "The AUROC of Infiltration is 0.6252\n",
      "The AUROC of Mass is 0.5952\n",
      "The AUROC of Nodule is 0.5337\n",
      "The AUROC of Pneumonia is 0.6066\n",
      "The AUROC of Pneumothorax is 0.6811\n",
      "The AUROC of Consolidation is 0.7416\n",
      "The AUROC of Edema is 0.8138\n",
      "The AUROC of Emphysema is 0.6336\n",
      "The AUROC of Fibrosis is 0.6398\n",
      "The AUROC of Pleural_Thickening is 0.6205\n",
      "The AUROC of Hernia is 0.6848\n",
      "Training one epoch complete in 65m 44s\n",
      "Epoch 10/50\n",
      "----------\n",
      "step: 0 totalloss: 0.611 loss1: 0.663 loss2: 0.626 loss3: 0.181\n",
      "step: 500 totalloss: 0.605 loss1: 0.661 loss2: 0.623 loss3: 0.143\n",
      "step: 1000 totalloss: 0.611 loss1: 0.661 loss2: 0.628 loss3: 0.196\n",
      "step: 1500 totalloss: 0.604 loss1: 0.657 loss2: 0.619 loss3: 0.163\n",
      "step: 2000 totalloss: 0.599 loss1: 0.655 loss2: 0.622 loss3: 0.132\n",
      " Epoch over  Loss: 0.60844\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.486\n",
      "The AUROC of Atelectasis is 0.5081\n",
      "The AUROC of Cardiomegaly is 0.4421\n",
      "The AUROC of Effusion is 0.4824\n",
      "The AUROC of Infiltration is 0.5099\n",
      "The AUROC of Mass is 0.4937\n",
      "The AUROC of Nodule is 0.5050\n",
      "The AUROC of Pneumonia is 0.5442\n",
      "The AUROC of Pneumothorax is 0.5383\n",
      "The AUROC of Consolidation is 0.4788\n",
      "The AUROC of Edema is 0.4292\n",
      "The AUROC of Emphysema is 0.4366\n",
      "The AUROC of Fibrosis is 0.5053\n",
      "The AUROC of Pleural_Thickening is 0.5231\n",
      "The AUROC of Hernia is 0.4048\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.509\n",
      "The AUROC of Atelectasis is 0.5722\n",
      "The AUROC of Cardiomegaly is 0.5069\n",
      "The AUROC of Effusion is 0.4799\n",
      "The AUROC of Infiltration is 0.4950\n",
      "The AUROC of Mass is 0.4938\n",
      "The AUROC of Nodule is 0.4755\n",
      "The AUROC of Pneumonia is 0.5342\n",
      "The AUROC of Pneumothorax is 0.4838\n",
      "The AUROC of Consolidation is 0.4580\n",
      "The AUROC of Edema is 0.5296\n",
      "The AUROC of Emphysema is 0.5286\n",
      "The AUROC of Fibrosis is 0.5068\n",
      "The AUROC of Pleural_Thickening is 0.5094\n",
      "The AUROC of Hernia is 0.5528\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.644\n",
      "The AUROC of Atelectasis is 0.6872\n",
      "The AUROC of Cardiomegaly is 0.6576\n",
      "The AUROC of Effusion is 0.7481\n",
      "The AUROC of Infiltration is 0.6212\n",
      "The AUROC of Mass is 0.5780\n",
      "The AUROC of Nodule is 0.5307\n",
      "The AUROC of Pneumonia is 0.5955\n",
      "The AUROC of Pneumothorax is 0.6776\n",
      "The AUROC of Consolidation is 0.7319\n",
      "The AUROC of Edema is 0.8106\n",
      "The AUROC of Emphysema is 0.5917\n",
      "The AUROC of Fibrosis is 0.6418\n",
      "The AUROC of Pleural_Thickening is 0.6089\n",
      "The AUROC of Hernia is 0.5287\n",
      "Training one epoch complete in 65m 52s\n",
      "Epoch 11/50\n",
      "----------\n",
      "step: 0 totalloss: 0.611 loss1: 0.659 loss2: 0.621 loss3: 0.217\n",
      "step: 500 totalloss: 0.599 loss1: 0.656 loss2: 0.620 loss3: 0.122\n",
      "step: 1000 totalloss: 0.607 loss1: 0.656 loss2: 0.626 loss3: 0.200\n",
      "step: 1500 totalloss: 0.602 loss1: 0.655 loss2: 0.615 loss3: 0.167\n",
      "step: 2000 totalloss: 0.601 loss1: 0.654 loss2: 0.616 loss3: 0.164\n",
      " Epoch over  Loss: 0.60418\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.482\n",
      "The AUROC of Atelectasis is 0.5044\n",
      "The AUROC of Cardiomegaly is 0.4553\n",
      "The AUROC of Effusion is 0.4825\n",
      "The AUROC of Infiltration is 0.5130\n",
      "The AUROC of Mass is 0.5013\n",
      "The AUROC of Nodule is 0.5024\n",
      "The AUROC of Pneumonia is 0.5347\n",
      "The AUROC of Pneumothorax is 0.5315\n",
      "The AUROC of Consolidation is 0.4774\n",
      "The AUROC of Edema is 0.4151\n",
      "The AUROC of Emphysema is 0.4350\n",
      "The AUROC of Fibrosis is 0.4671\n",
      "The AUROC of Pleural_Thickening is 0.5224\n",
      "The AUROC of Hernia is 0.4098\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.505\n",
      "The AUROC of Atelectasis is 0.5788\n",
      "The AUROC of Cardiomegaly is 0.4868\n",
      "The AUROC of Effusion is 0.4811\n",
      "The AUROC of Infiltration is 0.4952\n",
      "The AUROC of Mass is 0.4819\n",
      "The AUROC of Nodule is 0.4865\n",
      "The AUROC of Pneumonia is 0.5274\n",
      "The AUROC of Pneumothorax is 0.4682\n",
      "The AUROC of Consolidation is 0.4627\n",
      "The AUROC of Edema is 0.5718\n",
      "The AUROC of Emphysema is 0.5138\n",
      "The AUROC of Fibrosis is 0.4965\n",
      "The AUROC of Pleural_Thickening is 0.5028\n",
      "The AUROC of Hernia is 0.5186\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.657\n",
      "The AUROC of Atelectasis is 0.6914\n",
      "The AUROC of Cardiomegaly is 0.6645\n",
      "The AUROC of Effusion is 0.7565\n",
      "The AUROC of Infiltration is 0.6220\n",
      "The AUROC of Mass is 0.5945\n",
      "The AUROC of Nodule is 0.5275\n",
      "The AUROC of Pneumonia is 0.6242\n",
      "The AUROC of Pneumothorax is 0.6821\n",
      "The AUROC of Consolidation is 0.6980\n",
      "The AUROC of Edema is 0.8124\n",
      "The AUROC of Emphysema is 0.6021\n",
      "The AUROC of Fibrosis is 0.6478\n",
      "The AUROC of Pleural_Thickening is 0.6368\n",
      "The AUROC of Hernia is 0.6364\n",
      "Training one epoch complete in 65m 36s\n",
      "Epoch 12/50\n",
      "----------\n",
      "step: 0 totalloss: 0.597 loss1: 0.651 loss2: 0.614 loss3: 0.150\n",
      "step: 500 totalloss: 0.598 loss1: 0.650 loss2: 0.618 loss3: 0.163\n",
      "step: 1000 totalloss: 0.596 loss1: 0.649 loss2: 0.618 loss3: 0.152\n",
      "step: 1500 totalloss: 0.603 loss1: 0.651 loss2: 0.619 loss3: 0.199\n",
      "step: 2000 totalloss: 0.597 loss1: 0.651 loss2: 0.614 loss3: 0.148\n",
      " Epoch over  Loss: 0.59997\n",
      "*******testing!*********\n",
      " testing process: = 88Global branch: The average AUROC is 0.484\n",
      "The AUROC of Atelectasis is 0.5090\n",
      "The AUROC of Cardiomegaly is 0.4461\n",
      "The AUROC of Effusion is 0.4824\n",
      "The AUROC of Infiltration is 0.5219\n",
      "The AUROC of Mass is 0.4994\n",
      "The AUROC of Nodule is 0.5044\n",
      "The AUROC of Pneumonia is 0.5362\n",
      "The AUROC of Pneumothorax is 0.5262\n",
      "The AUROC of Consolidation is 0.4857\n",
      "The AUROC of Edema is 0.4191\n",
      "The AUROC of Emphysema is 0.4382\n",
      "The AUROC of Fibrosis is 0.4828\n",
      "The AUROC of Pleural_Thickening is 0.5258\n",
      "The AUROC of Hernia is 0.3926\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.509\n",
      "The AUROC of Atelectasis is 0.5753\n",
      "The AUROC of Cardiomegaly is 0.5033\n",
      "The AUROC of Effusion is 0.4849\n",
      "The AUROC of Infiltration is 0.4982\n",
      "The AUROC of Mass is 0.4912\n",
      "The AUROC of Nodule is 0.4779\n",
      "The AUROC of Pneumonia is 0.5274\n",
      "The AUROC of Pneumothorax is 0.4806\n",
      "The AUROC of Consolidation is 0.4708\n",
      "The AUROC of Edema is 0.5360\n",
      "The AUROC of Emphysema is 0.5484\n",
      "The AUROC of Fibrosis is 0.5208\n",
      "The AUROC of Pleural_Thickening is 0.5029\n",
      "The AUROC of Hernia is 0.5105\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.657\n",
      "The AUROC of Atelectasis is 0.6855\n",
      "The AUROC of Cardiomegaly is 0.6627\n",
      "The AUROC of Effusion is 0.7583\n",
      "The AUROC of Infiltration is 0.6253\n",
      "The AUROC of Mass is 0.5956\n",
      "The AUROC of Nodule is 0.5326\n",
      "The AUROC of Pneumonia is 0.6569\n",
      "The AUROC of Pneumothorax is 0.6695\n",
      "The AUROC of Consolidation is 0.7329\n",
      "The AUROC of Edema is 0.8127\n",
      "The AUROC of Emphysema is 0.6176\n",
      "The AUROC of Fibrosis is 0.6368\n",
      "The AUROC of Pleural_Thickening is 0.6137\n",
      "The AUROC of Hernia is 0.6002\n",
      "Training one epoch complete in 65m 23s\n",
      "Epoch 13/50\n",
      "----------\n",
      "step: 0 totalloss: 0.604 loss1: 0.651 loss2: 0.611 loss3: 0.219\n",
      "step: 500 totalloss: 0.598 loss1: 0.647 loss2: 0.616 loss3: 0.185\n",
      "step: 1000 totalloss: 0.600 loss1: 0.649 loss2: 0.607 loss3: 0.199\n",
      "step: 1500 totalloss: 0.596 loss1: 0.644 loss2: 0.612 loss3: 0.194\n",
      "step: 2000 totalloss: 0.588 loss1: 0.642 loss2: 0.607 loss3: 0.141\n",
      " Epoch over  Loss: 0.59576\n",
      "*******testing!*********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " testing process: = 88Global branch: The average AUROC is 0.487\n",
      "The AUROC of Atelectasis is 0.5098\n",
      "The AUROC of Cardiomegaly is 0.4552\n",
      "The AUROC of Effusion is 0.4867\n",
      "The AUROC of Infiltration is 0.5281\n",
      "The AUROC of Mass is 0.5059\n",
      "The AUROC of Nodule is 0.5058\n",
      "The AUROC of Pneumonia is 0.5266\n",
      "The AUROC of Pneumothorax is 0.5335\n",
      "The AUROC of Consolidation is 0.5015\n",
      "The AUROC of Edema is 0.4294\n",
      "The AUROC of Emphysema is 0.4307\n",
      "The AUROC of Fibrosis is 0.4907\n",
      "The AUROC of Pleural_Thickening is 0.5316\n",
      "The AUROC of Hernia is 0.3793\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.506\n",
      "The AUROC of Atelectasis is 0.5749\n",
      "The AUROC of Cardiomegaly is 0.4944\n",
      "The AUROC of Effusion is 0.4815\n",
      "The AUROC of Infiltration is 0.5030\n",
      "The AUROC of Mass is 0.4956\n",
      "The AUROC of Nodule is 0.4729\n",
      "The AUROC of Pneumonia is 0.5188\n",
      "The AUROC of Pneumothorax is 0.4701\n",
      "The AUROC of Consolidation is 0.4734\n",
      "The AUROC of Edema is 0.5675\n",
      "The AUROC of Emphysema is 0.5314\n",
      "The AUROC of Fibrosis is 0.5049\n",
      "The AUROC of Pleural_Thickening is 0.5011\n",
      "The AUROC of Hernia is 0.4990\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.654\n",
      "The AUROC of Atelectasis is 0.6799\n",
      "The AUROC of Cardiomegaly is 0.7061\n",
      "The AUROC of Effusion is 0.7568\n",
      "The AUROC of Infiltration is 0.6235\n",
      "The AUROC of Mass is 0.6115\n",
      "The AUROC of Nodule is 0.5423\n",
      "The AUROC of Pneumonia is 0.5971\n",
      "The AUROC of Pneumothorax is 0.6963\n",
      "The AUROC of Consolidation is 0.7175\n",
      "The AUROC of Edema is 0.8076\n",
      "The AUROC of Emphysema is 0.6053\n",
      "The AUROC of Fibrosis is 0.6434\n",
      "The AUROC of Pleural_Thickening is 0.6208\n",
      "The AUROC of Hernia is 0.5431\n",
      "Training one epoch complete in 67m 51s\n",
      "Epoch 14/50\n",
      "----------\n",
      "step: 0 totalloss: 0.596 loss1: 0.644 loss2: 0.614 loss3: 0.197\n",
      "step: 500 totalloss: 0.592 loss1: 0.642 loss2: 0.610 loss3: 0.178\n",
      "step: 1000 totalloss: 0.595 loss1: 0.642 loss2: 0.611 loss3: 0.211\n",
      "step: 1500 totalloss: 0.583 loss1: 0.637 loss2: 0.601 loss3: 0.130\n",
      "step: 2000 totalloss: 0.589 loss1: 0.639 loss2: 0.604 loss3: 0.171\n",
      " Epoch over  Loss: 0.59159\n",
      "*******testing!*********\n",
      " testing process: = 2"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "\"\"\"\n",
    "Training implementation\n",
    "Author: Ian Ren\n",
    "Update time: 08/11/2020\n",
    "\"\"\"\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.measure import label\n",
    "from PIL import Image\n",
    "\n",
    "#np.set_printoptions(threshold = np.nan)\n",
    "\n",
    "\n",
    "CKPT_PATH = ''\n",
    "\n",
    "CKPT_PATH_G = ''#'/data/tmpexec/AGCNN/paper/AG_CNN_Global_epoch_1.pkl' \n",
    "CKPT_PATH_L = ''#'/data/tmpexec/AGCNN/paper/AG_CNN_Local_epoch_2.pkl' \n",
    "CKPT_PATH_F = ''#'/data/tmpexec/AGCNN/paper/AG_CNN_Fusion_epoch_23.pkl'\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "# load with your own dataset path\n",
    "DATA_DIR = '/data/fjsdata/NIH-CXR/images/images/'\n",
    "TRAIN_IMAGE_LIST = '/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt'\n",
    "VAL_IMAGE_LIST = '/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt'\n",
    "save_model_path = '/data/tmpexec/AGCNN/'\n",
    "save_model_name = 'AG_CNN'\n",
    "\n",
    "# learning rate\n",
    "LR_G = 1e-8\n",
    "LR_L = 1e-8\n",
    "LR_F = 1e-3\n",
    "num_epochs = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n",
    "\n",
    "\n",
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # feature map -> feature mask (using feature map to crop on the original image) -> crop -> patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda\n",
    "\n",
    "\n",
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "        lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc \n",
    "\n",
    "\n",
    "def main():\n",
    "    print('********************load data********************')\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TRAIN_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(224),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalize,\n",
    "                                    ]))\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=VAL_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalize,\n",
    "                                    ]))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=128,\n",
    "                             shuffle=False, num_workers=0, pin_memory=True)\n",
    "    print('********************load data succeed!********************')\n",
    "\n",
    "\n",
    "    print('********************load model********************')\n",
    "    # initialize and load the model\n",
    "    Global_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Local_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Fusion_Branch_model = Fusion_Branch(input_size = 2048, output_size = N_CLASSES).cuda()\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        # to load state\n",
    "        # Code modified from torchvision densenet source for loading from pre .4 densenet weights.\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        remove_data_parallel = True # Change if you don't want to use nn.DataParallel(model)\n",
    "\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        for key in list(state_dict.keys()):\n",
    "            ori_key =  key\n",
    "            key = key.replace('densenet121.','')\n",
    "            #print('key',key)\n",
    "            match = pattern.match(key)\n",
    "            new_key = match.group(1) + match.group(2) if match else key\n",
    "            new_key = new_key[7:] if remove_data_parallel else new_key\n",
    "            #print('new_key',new_key)\n",
    "            if '.0.' in new_key:\n",
    "                new_key = new_key.replace('0.','')\n",
    "            state_dict[new_key] = state_dict[ori_key]\n",
    "            # Delete old key only if modified.\n",
    "            if match or remove_data_parallel: \n",
    "                del state_dict[ori_key]\n",
    "        \n",
    "        Global_Branch_model.load_state_dict(state_dict)\n",
    "        Local_Branch_model.load_state_dict(state_dict)\n",
    "        print(\"=> loaded baseline checkpoint\")\n",
    "        \n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_G):\n",
    "        checkpoint = torch.load(CKPT_PATH_G)\n",
    "        Global_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Global_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_L):\n",
    "        checkpoint = torch.load(CKPT_PATH_L)\n",
    "        Local_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Local_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_F):\n",
    "        checkpoint = torch.load(CKPT_PATH_F)\n",
    "        Fusion_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Fusion_Branch_model checkpoint\")\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_global = optim.Adam(Global_Branch_model.parameters(), lr=LR_G, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "    lr_scheduler_global = lr_scheduler.StepLR(optimizer_global , step_size = 10, gamma = 1)\n",
    "    \n",
    "    optimizer_local = optim.Adam(Local_Branch_model.parameters(), lr=LR_L, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "    lr_scheduler_local = lr_scheduler.StepLR(optimizer_local , step_size = 10, gamma = 1)\n",
    "    \n",
    "    optimizer_fusion = optim.Adam(Fusion_Branch_model.parameters(), lr=LR_F, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "    lr_scheduler_fusion = lr_scheduler.StepLR(optimizer_fusion , step_size = 15, gamma = 0.1)\n",
    "    print('********************load model succeed!********************')\n",
    "\n",
    "    print('********************begin training!********************')\n",
    "    AUROCs_best = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1 , num_epochs))\n",
    "        print('-' * 10)\n",
    "        #set the mode of model\n",
    "        lr_scheduler_global.step()  #about lr and gamma\n",
    "        lr_scheduler_local.step() \n",
    "        lr_scheduler_fusion.step() \n",
    "        Global_Branch_model.train()  #set model to training mode\n",
    "        Local_Branch_model.train()\n",
    "        Fusion_Branch_model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        #Iterate over data\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            input_var = torch.autograd.Variable(input.cuda())\n",
    "            target_var = torch.autograd.Variable(target.cuda())\n",
    "            optimizer_global.zero_grad()\n",
    "            optimizer_local.zero_grad()\n",
    "            optimizer_fusion.zero_grad()\n",
    "\n",
    "            # compute output\n",
    "            output_global, fm_global, pool_global = Global_Branch_model(input_var)\n",
    "            patchs_var = Attention_gen_patchs(input,fm_global)\n",
    "            output_local, _, pool_local = Local_Branch_model(patchs_var)\n",
    "            #print(fusion_var.shape)\n",
    "            output_fusion = Fusion_Branch_model(pool_global, pool_local)\n",
    "            #\n",
    "            # loss\n",
    "            loss1 = criterion(output_global, target_var)\n",
    "            loss2 = criterion(output_local, target_var)\n",
    "            loss3 = criterion(output_fusion, target_var)\n",
    "            #\n",
    "            loss = loss1*0.8 + loss2*0.1 + loss3*0.1 \n",
    "\n",
    "            if (i%500) == 0: \n",
    "                print('step: {} totalloss: {loss:.3f} loss1: {loss1:.3f} loss2: {loss2:.3f} loss3: {loss3:.3f}'\\\n",
    "                      .format(i, loss = loss, loss1 = loss1, loss2 = loss2, loss3 = loss3))\n",
    "\n",
    "            loss.backward() \n",
    "            optimizer_global.step()  \n",
    "            optimizer_local.step()\n",
    "            optimizer_fusion.step()\n",
    "\n",
    "            #print(loss.data.item())\n",
    "            running_loss += loss.data.item()\n",
    "\n",
    "        epoch_loss = float(running_loss) / float(i)\n",
    "        print(' Epoch over  Loss: {:.5f}'.format(epoch_loss))\n",
    "\n",
    "        print('*******testing!*********')\n",
    "        AUROCs_f = test(Global_Branch_model, Local_Branch_model, Fusion_Branch_model,test_loader)\n",
    "        #break\n",
    "\n",
    "        #save\n",
    "        if epoch % 1 == 0 and AUROCs_best<AUROCs_f:\n",
    "            AUROCs_best = AUROCs_f\n",
    "            save_path = save_model_path\n",
    "            torch.save(Global_Branch_model.state_dict(), save_path+save_model_name+'_Global'+'_epoch_'+str(epoch)+'.pkl')\n",
    "            print('Global_Branch_model already save!')\n",
    "            torch.save(Local_Branch_model.state_dict(), save_path+save_model_name+'_Local'+'_epoch_'+str(epoch)+'.pkl')\n",
    "            print('Local_Branch_model already save!')\n",
    "            torch.save(Fusion_Branch_model.state_dict(), save_path+save_model_name+'_Fusion'+'_epoch_'+str(epoch)+'.pkl')            \n",
    "            print('Fusion_Branch_model already save!')\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training one epoch complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60 , time_elapsed % 60))\n",
    "    \n",
    "\n",
    "def test(model_global, model_local, model_fusion, test_loader):\n",
    "\n",
    "    # initialize the ground truth and output tensor\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred_global = torch.FloatTensor().cuda()\n",
    "    pred_local = torch.FloatTensor().cuda()\n",
    "    pred_fusion = torch.FloatTensor().cuda()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model_global.eval()\n",
    "    model_local.eval()\n",
    "    model_fusion.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    for i, (inp, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            target = target.cuda()\n",
    "            gt = torch.cat((gt, target), 0)\n",
    "            input_var = torch.autograd.Variable(inp.cuda())\n",
    "            #output = model_global(input_var)\n",
    "\n",
    "            output_global, fm_global, pool_global = model_global(input_var)\n",
    "            \n",
    "            patchs_var = Attention_gen_patchs(inp,fm_global)\n",
    "\n",
    "            output_local, _, pool_local = model_local(patchs_var)\n",
    "\n",
    "            output_fusion = model_fusion(pool_global,pool_local)\n",
    "\n",
    "            pred_global = torch.cat((pred_global, output_global.data), 0)\n",
    "            pred_local = torch.cat((pred_local, output_local.data), 0)\n",
    "            pred_fusion = torch.cat((pred_fusion, output_fusion.data), 0)\n",
    "            \n",
    "            sys.stdout.write('\\r testing process: = {}'.format(i+1))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    AUROCs_g = compute_AUCs(gt, pred_global)\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "\n",
    "    AUROCs_l = compute_AUCs(gt, pred_local)\n",
    "    AUROC_avg = np.array(AUROCs_l).mean()\n",
    "    print('\\n')\n",
    "    print('Local branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "    AUROCs_f = compute_AUCs(gt, pred_fusion)\n",
    "    AUROC_avg = np.array(AUROCs_f).mean()\n",
    "    print('\\n')\n",
    "    print('Fusion branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_f[i]))\n",
    "    \n",
    "    return np.array(AUROCs_f).mean()\n",
    "\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************load data********************\n",
      "********************load data succeed!********************\n",
      "********************load model********************\n",
      "=> loaded Global_Branch_model checkpoint\n",
      "=> loaded Local_Branch_model checkpoint\n",
      "=> loaded Fusion_Branch_model checkpoint\n",
      "******************** load model succeed!********************\n",
      "******* begin testing!*********\n",
      " testing process: = 176Global branch: The average AUROC is 0.839\n",
      "The AUROC of Atelectasis is 0.8235533370251485\n",
      "The AUROC of Cardiomegaly is 0.9149242739132466\n",
      "The AUROC of Effusion is 0.8855035262218596\n",
      "The AUROC of Infiltration is 0.7073808055682215\n",
      "The AUROC of Mass is 0.8428857286111491\n",
      "The AUROC of Nodule is 0.7757692210739041\n",
      "The AUROC of Pneumonia is 0.77675317705674\n",
      "The AUROC of Pneumothorax is 0.8680464132603121\n",
      "The AUROC of Consolidation is 0.8127160925962797\n",
      "The AUROC of Edema is 0.8931314367524132\n",
      "The AUROC of Emphysema is 0.9152569924536593\n",
      "The AUROC of Fibrosis is 0.8239410556238518\n",
      "The AUROC of Pleural_Thickening is 0.7841428860783273\n",
      "The AUROC of Hernia is 0.9223130679631059\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.793\n",
      "The AUROC of Atelectasis is 0.7885744513999785\n",
      "The AUROC of Cardiomegaly is 0.8877403992456878\n",
      "The AUROC of Effusion is 0.8589066389184761\n",
      "The AUROC of Infiltration is 0.6849916954206804\n",
      "The AUROC of Mass is 0.7936918687766492\n",
      "The AUROC of Nodule is 0.6992057752248025\n",
      "The AUROC of Pneumonia is 0.719513550836446\n",
      "The AUROC of Pneumothorax is 0.8259616963212608\n",
      "The AUROC of Consolidation is 0.7885186603772226\n",
      "The AUROC of Edema is 0.8655585501184262\n",
      "The AUROC of Emphysema is 0.839955647819275\n",
      "The AUROC of Fibrosis is 0.7559528503065569\n",
      "The AUROC of Pleural_Thickening is 0.7438818926222821\n",
      "The AUROC of Hernia is 0.8491368768489039\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.838\n",
      "The AUROC of Atelectasis is 0.8245042065632546\n",
      "The AUROC of Cardiomegaly is 0.9168662376127226\n",
      "The AUROC of Effusion is 0.8857757605058649\n",
      "The AUROC of Infiltration is 0.706814848865169\n",
      "The AUROC of Mass is 0.8445555030684252\n",
      "The AUROC of Nodule is 0.7730578860981552\n",
      "The AUROC of Pneumonia is 0.7671708916316682\n",
      "The AUROC of Pneumothorax is 0.8670753294151822\n",
      "The AUROC of Consolidation is 0.8117039058739818\n",
      "The AUROC of Edema is 0.8917183476170683\n",
      "The AUROC of Emphysema is 0.9141587172547134\n",
      "The AUROC of Fibrosis is 0.8230497207530395\n",
      "The AUROC of Pleural_Thickening is 0.785003182632633\n",
      "The AUROC of Hernia is 0.9232881621229618\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.measure import label\n",
    "from PIL import Image\n",
    "\n",
    "#np.set_printoptions(threshold = np.nan)\n",
    "\n",
    "\n",
    "CKPT_PATH = ''\n",
    "\n",
    "CKPT_PATH_G = '/data/tmpexec/AGCNN/AG_CNN_Global_epoch_1.pkl' \n",
    "CKPT_PATH_L = '/data/tmpexec/AGCNN/AG_CNN_Local_epoch_2.pkl' \n",
    "CKPT_PATH_F = '/data/tmpexec/AGCNN/AG_CNN_Fusion_epoch_23.pkl'\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "DATA_DIR = '/data/fjsdata/NIH-CXR/images/images/'\n",
    "TRAIN_IMAGE_LIST = '/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt'\n",
    "TEST_IMAGE_LIST = '/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt'\n",
    "\n",
    "num_epochs = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n",
    "\n",
    "\n",
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # fm => mask =>(+ ori-img) => crop = patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda\n",
    "\n",
    "\n",
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "        lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc \n",
    "\n",
    "\n",
    "def main():\n",
    "    print('********************load data********************')\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalize,\n",
    "                                    ]))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=128,\n",
    "                             shuffle=False, num_workers=0, pin_memory=True)\n",
    "    print('********************load data succeed!********************')\n",
    "\n",
    "\n",
    "    print('********************load model********************')\n",
    "    # initialize and load the model\n",
    "    Global_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Local_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Fusion_Branch_model = Fusion_Branch(input_size = 2048, output_size = N_CLASSES).cuda()\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_G):\n",
    "        checkpoint = torch.load(CKPT_PATH_G)\n",
    "        Global_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Global_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_L):\n",
    "        checkpoint = torch.load(CKPT_PATH_L)\n",
    "        Local_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Local_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_F):\n",
    "        checkpoint = torch.load(CKPT_PATH_F)\n",
    "        Fusion_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Fusion_Branch_model checkpoint\")\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    print('******************** load model succeed!********************')\n",
    "\n",
    "    print('******* begin testing!*********')\n",
    "    test(Global_Branch_model, Local_Branch_model, Fusion_Branch_model,test_loader)\n",
    "\n",
    "def test(model_global, model_local, model_fusion, test_loader):\n",
    "\n",
    "    # initialize the ground truth and output tensor\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred_global = torch.FloatTensor().cuda()\n",
    "    pred_local = torch.FloatTensor().cuda()\n",
    "    pred_fusion = torch.FloatTensor().cuda()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model_global.eval()\n",
    "    model_local.eval()\n",
    "    model_fusion.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    for i, (inp, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():     \n",
    "            target = target.cuda()\n",
    "            gt = torch.cat((gt, target), 0)\n",
    "            input_var = torch.autograd.Variable(inp.cuda())\n",
    "\n",
    "            output_global, fm_global, pool_global = model_global(input_var)\n",
    "            \n",
    "            patchs_var = Attention_gen_patchs(inp,fm_global)\n",
    "\n",
    "            output_local, _, pool_local = model_local(patchs_var)\n",
    "\n",
    "            output_fusion = model_fusion(pool_global,pool_local)\n",
    "\n",
    "            pred_global = torch.cat((pred_global, output_global.data), 0)\n",
    "            pred_local = torch.cat((pred_local, output_local.data), 0)\n",
    "            pred_fusion = torch.cat((pred_fusion, output_fusion.data), 0)\n",
    "            \n",
    "            sys.stdout.write('\\r testing process: = {}'.format(i+1))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    AUROCs_g = compute_AUCs(gt, pred_global)\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "\n",
    "    AUROCs_l = compute_AUCs(gt, pred_local)\n",
    "    AUROC_avg = np.array(AUROCs_l).mean()\n",
    "    print('\\n')\n",
    "    print('Local branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "    AUROCs_f = compute_AUCs(gt, pred_fusion)\n",
    "    AUROC_avg = np.array(AUROCs_f).mean()\n",
    "    print('\\n')\n",
    "    print('Fusion branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_f[i]))\n",
    "\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded Global_Branch_model checkpoint\n",
      "=> loaded Local_Branch_model checkpoint\n",
      "=> loaded Fusion_Branch_model checkpoint\n",
      " 2243 / 2244 Global branch: The average AUROC is 0.838\n",
      "The AUROC of Atelectasis is 0.8262332376517247\n",
      "The AUROC of Cardiomegaly is 0.9141369201374948\n",
      "The AUROC of Effusion is 0.8859380050537341\n",
      "The AUROC of Infiltration is 0.7063778922034437\n",
      "The AUROC of Mass is 0.8432511426310141\n",
      "The AUROC of Nodule is 0.7738812774201932\n",
      "The AUROC of Pneumonia is 0.7756925132704011\n",
      "The AUROC of Pneumothorax is 0.8673377455555967\n",
      "The AUROC of Consolidation is 0.8131091098653926\n",
      "The AUROC of Edema is 0.8914614273178907\n",
      "The AUROC of Emphysema is 0.9123397885676864\n",
      "The AUROC of Fibrosis is 0.8216879678365977\n",
      "The AUROC of Pleural_Thickening is 0.7816199794739345\n",
      "The AUROC of Hernia is 0.922022241079005\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.791\n",
      "The AUROC of Atelectasis is 0.7862530677373757\n",
      "The AUROC of Cardiomegaly is 0.8832458854022425\n",
      "The AUROC of Effusion is 0.8591878314338008\n",
      "The AUROC of Infiltration is 0.6836848277251164\n",
      "The AUROC of Mass is 0.7940482702037468\n",
      "The AUROC of Nodule is 0.6943561222942835\n",
      "The AUROC of Pneumonia is 0.7178260973196267\n",
      "The AUROC of Pneumothorax is 0.8251503982857056\n",
      "The AUROC of Consolidation is 0.7895677525280097\n",
      "The AUROC of Edema is 0.8613477072351131\n",
      "The AUROC of Emphysema is 0.8403758796686105\n",
      "The AUROC of Fibrosis is 0.7485864929630668\n",
      "The AUROC of Pleural_Thickening is 0.7421908718153111\n",
      "The AUROC of Hernia is 0.8515166595422055\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.838\n",
      "The AUROC of Atelectasis is 0.8263489578881166\n",
      "The AUROC of Cardiomegaly is 0.916176900064023\n",
      "The AUROC of Effusion is 0.8861884480479598\n",
      "The AUROC of Infiltration is 0.704304115795369\n",
      "The AUROC of Mass is 0.8454842352141683\n",
      "The AUROC of Nodule is 0.7717711496519009\n",
      "The AUROC of Pneumonia is 0.7669200640122513\n",
      "The AUROC of Pneumothorax is 0.8665942941063902\n",
      "The AUROC of Consolidation is 0.8128287551139685\n",
      "The AUROC of Edema is 0.8893290383164766\n",
      "The AUROC of Emphysema is 0.9146340600086958\n",
      "The AUROC of Fibrosis is 0.8227898862811154\n",
      "The AUROC of Pleural_Thickening is 0.7822828448127231\n",
      "The AUROC of Hernia is 0.9258800836220334\n"
     ]
    }
   ],
   "source": [
    "CKPT_PATH_G = '/data/tmpexec/AGCNN/paper/AG_CNN_Global_epoch_1.pkl' \n",
    "CKPT_PATH_L = '/data/tmpexec/AGCNN/paper/AG_CNN_Local_epoch_2.pkl' \n",
    "CKPT_PATH_F = '/data/tmpexec/AGCNN/paper/AG_CNN_Fusion_epoch_23.pkl'\n",
    "# initialize and load the model\n",
    "Global_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "Local_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "Fusion_Branch_model = Fusion_Branch(input_size = 2048, output_size = N_CLASSES).cuda()\n",
    "\n",
    "if os.path.isfile(CKPT_PATH_G):\n",
    "    checkpoint = torch.load(CKPT_PATH_G)\n",
    "    Global_Branch_model.load_state_dict(checkpoint)\n",
    "    print(\"=> loaded Global_Branch_model checkpoint\")\n",
    "\n",
    "if os.path.isfile(CKPT_PATH_L):\n",
    "    checkpoint = torch.load(CKPT_PATH_L)\n",
    "    Local_Branch_model.load_state_dict(checkpoint)\n",
    "    print(\"=> loaded Local_Branch_model checkpoint\")\n",
    "\n",
    "if os.path.isfile(CKPT_PATH_F):\n",
    "    checkpoint = torch.load(CKPT_PATH_F)\n",
    "    Fusion_Branch_model.load_state_dict(checkpoint)\n",
    "    print(\"=> loaded Fusion_Branch_model checkpoint\")\n",
    "        \n",
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "Global_Branch_model.eval()\n",
    "Local_Branch_model.eval()\n",
    "Fusion_Branch_model.eval()\n",
    "cudnn.benchmark = True\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred_global = torch.FloatTensor().cuda()\n",
    "pred_local = torch.FloatTensor().cuda()\n",
    "pred_fusion = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "with torch.no_grad():     \n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        \n",
    "        output_global, fm_global, pool_global = Global_Branch_model(I_batch)\n",
    "        patchs_var = Attention_gen_patchs(I_batch.data.cpu(),fm_global)\n",
    "        output_local, _, pool_local = Local_Branch_model(patchs_var)\n",
    "        output_fusion = Fusion_Branch_model(pool_global,pool_local)\n",
    "\n",
    "        pred_global = torch.cat((pred_global, output_global.data), 0)\n",
    "        pred_local = torch.cat((pred_local, output_local.data), 0)\n",
    "        pred_fusion = torch.cat((pred_fusion, output_fusion.data), 0)\n",
    "            \n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "            \n",
    "AUROCs_g = compute_AUCs(gt, pred_global)\n",
    "AUROC_avg = np.array(AUROCs_g).mean()\n",
    "print('Global branch: The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "\n",
    "AUROCs_l = compute_AUCs(gt, pred_local)\n",
    "AUROC_avg = np.array(AUROCs_l).mean()\n",
    "print('\\n')\n",
    "print('Local branch: The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "AUROCs_f = compute_AUCs(gt, pred_fusion)\n",
    "AUROC_avg = np.array(AUROCs_f).mean()\n",
    "print('\\n')\n",
    "print('Fusion branch: The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs_f[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#https://github.com/liudaizong/AG-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#designed by Jason.F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78468 / 78468 The length of trainset is 78468\n",
      "11219 / 11219 The length of validset is 11219\n",
      "22433 / 22433 The length of testset is 22433\n",
      "The length of boxset is 984\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             #transforms.RandomCrop(crop_size),\n",
    "                                             #transforms.RandomHorizontalFlip(),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "\n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia','Pneumothorax', \\\n",
    "               'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "N_CLASSES = len(CLASS_NAMES) #class numbers\n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs \n",
    "\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "#preparing the trainset and  testset\n",
    "trN, trI, trY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt', \"r\") as file_descriptor: #tarinset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        #if(len(trN)>1001): break\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            trN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            trY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            trI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),78468))\n",
    "        sys.stdout.flush()\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)   \n",
    "print('The length of trainset is %d'%len(trN))\n",
    "        \n",
    "valN, valI, valY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt', \"r\") as file_descriptor: #valset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        #if(len(valN)>1001): break\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            valN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            valY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))\n",
    "            valI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(valN),11219))\n",
    "        sys.stdout.flush()\n",
    "valI = np.array(valI)\n",
    "valY = np.array(valY) \n",
    "print('The length of validset is %d'%len(valN))\n",
    "\n",
    "teN, teI, teY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt', \"r\") as file_descriptor: #testset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        #if(len(teN)>1001): break\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            teN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            teY.append(np.array(image_label))\n",
    "            img = Image_Processing(os.path.join(img_path, image_name))                    \n",
    "            teI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),22433))\n",
    "        sys.stdout.flush()\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)    \n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "#preparing bounding box dataset\n",
    "boxdata = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_BBox.csv\" , sep=',')\n",
    "boxdata = boxdata[['Image Index','Finding Label','Bbox [x', 'y', 'w', 'h]']]\n",
    "#print('Dataset statistic, records: %d, fields: %d' % (boxdata.shape[0], boxdata.shape[1]))\n",
    "#print(boxdata.columns.values.tolist())\n",
    "bbN, bbI, bbY, bBox = [],[],[],[]\n",
    "for _, row in boxdata.iterrows():\n",
    "    bbN.append(row['Image Index'])\n",
    "    \n",
    "    img = Image_Processing(os.path.join(img_path, row['Image Index']))\n",
    "    bbI.append(img)\n",
    "    \n",
    "    labels = np.zeros(len(CLASS_NAMES))\n",
    "    labels[CLASS_NAMES.index(row['Finding Label'])] = 1\n",
    "    bbY.append(labels)\n",
    "    \n",
    "    bBox.append(np.array([row['Bbox [x'], row['y'], row['w'], row['h]']])) #xywh  \n",
    "print('The length of boxset is %d'%len(bbN))\n",
    "bbI = np.array(bbI)\n",
    "bbY = np.array(bbY)\n",
    "bBox = np.array(bBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct model\n",
    "class DenseNet121_AG(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained, fusion_size=2048):\n",
    "        super(DenseNet121_AG, self).__init__()\n",
    "        self.dense_net_121 = torchvision.models.densenet121(pretrained=is_pre_trained)\n",
    "        #num_fc_kernels = self.dense_net_121.classifier.in_features\n",
    "        #self.dense_net_121.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "        #for fusion\n",
    "        self.fc = nn.Linear(fusion_size, num_classes)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #global\n",
    "        features_g = self.dense_net_121.features(x)\n",
    "        out_g = F.relu(features_g, inplace=True)\n",
    "        pooling_g = F.avg_pool2d(out_g, kernel_size=7, stride=1).view(features_g.size(0), -1)\n",
    "        #out_g = self.dense_net_121.classifier(features_g)\n",
    "        #local\n",
    "        patchs_var = Attention_gen_patchs(x, features_g)\n",
    "        features_l = self.dense_net_121.features(patchs_var)\n",
    "        out_l = F.relu(features_l, inplace=True)\n",
    "        pooling_l = F.avg_pool2d(out_l, kernel_size=7, stride=1).view(features_l.size(0), -1) \n",
    "        #fusion\n",
    "        fusion = torch.cat((pooling_g,pooling_l), 1)\n",
    "        out = self.fc(fusion)\n",
    "        out = self.Sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "        lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc \n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n",
    "\n",
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # feature map -> feature mask (using feature map to crop on the original image) -> crop -> patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    ori_image = ori_image.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        #image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = ori_image[i].reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Eopch:     1 val_loss = 0.174227 avg_auroc= 0.636918\n",
      " Eopch:     2 val_loss = 0.173026 avg_auroc= 0.670172\n",
      " Eopch:     3 val_loss = 0.175175 avg_auroc= 0.687696\n",
      " 5899 / 7847 : train loss = 0.088487"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1ab882de39e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#forword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0my_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m#loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-86aa3f2fda25>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#out_g = self.dense_net_121.classifier(features_g)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpatchs_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention_gen_patchs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfeatures_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_net_121\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatchs_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-86aa3f2fda25>\u001b[0m in \u001b[0;36mAttention_gen_patchs\u001b[0;34m(ori_image, fm_cuda)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap_mask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mminh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mminw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mmaxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DenseNet121_AG(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "AUROC_best = 0.\n",
    "batchSize = 10 #'Batch Size': 32\n",
    "for epoch in range(10):#'Max Epoch': 50\n",
    "    model.train()  # set network as train mode\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    num_batches = len(shuffled_idx) // batchSize + 1\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(shuffled_idx), (i+1)*batchSize])\n",
    "            selected_idx = shuffled_idx[min_idx:max_idx]\n",
    "            I_batch = torch.from_numpy(trI[selected_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[selected_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred = torch.FloatTensor().cuda()\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch)#forwordï¼Œ .permute(0, 3, 1, 2)\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            gt = torch.cat((gt, y_batch), 0)\n",
    "            pred = torch.cat((pred, y_outputs.data), 0)\n",
    "            sys.stdout.write('\\r {} / {} : validation loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    AUROCs = compute_AUCs(gt, pred)\n",
    "    AUROC_avg =  np.array(AUROCs).mean()\n",
    "    print(\"\\r Eopch: %5d val_loss = %.6f avg_auroc= %.6f\" % (epoch + 1, np.mean(loss_val), AUROC_avg)) \n",
    "    #if np.mean(loss_val) < best_loss:\n",
    "    if AUROC_avg > AUROC_best:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        AUROC_best = AUROC_avg\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"\\r best_loss = %.6f best_auroc = %0.6f\" % (best_loss, AUROC_best))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2243 / 2244 The average AUROC is 0.6770\n",
      "The AUROC of Atelectasis is 0.6664\n",
      "The AUROC of Cardiomegaly is 0.6957\n",
      "The AUROC of Effusion is 0.7541\n",
      "The AUROC of Infiltration is 0.6342\n",
      "The AUROC of Mass is 0.5953\n",
      "The AUROC of Nodule is 0.5806\n",
      "The AUROC of Pneumonia is 0.6538\n",
      "The AUROC of Pneumothorax is 0.6684\n",
      "The AUROC of Consolidation is 0.7341\n",
      "The AUROC of Edema is 0.8026\n",
      "The AUROC of Emphysema is 0.6738\n",
      "The AUROC of Fibrosis is 0.6843\n",
      "The AUROC of Pleural_Thickening is 0.6295\n",
      "The AUROC of Hernia is 0.7047\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forwordï¼Œ.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
