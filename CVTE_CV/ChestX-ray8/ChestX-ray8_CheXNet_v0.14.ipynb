{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2）Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "torch.cuda.set_device(1)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, path_to_img_dir, path_to_dataset_file, transform=None):\n",
    "        \"\"\"\n",
    "        初始化PyTorch的Dataset类以使用dataloader类\n",
    "        :param path_to_img_dir: 存储ChestX-ray14 Dataset的图片文件的路径\n",
    "        :param path_to_dataset_file: 存储`test.txt`, `train.txt`等文件的路径（训练集、测试集划分及图片所属的标签）\n",
    "        :param transform: 对图片要做的transform处理\n",
    "        \"\"\"\n",
    "        self.list_image_paths = []\n",
    "        self.list_image_labels = []\n",
    "        self.transform = transform\n",
    "        with open(path_to_dataset_file, \"r\") as file_descriptor:\n",
    "            lines = file_descriptor.readlines()\n",
    "            for line in lines:\n",
    "                line_items = line.split()\n",
    "                image_path = os.path.join(path_to_img_dir, line_items[0].split('/')[1])  # line_items为图片的相对路径信息\n",
    "                image_label = line_items[1:]  # 从第二个开始，都为标签信息\n",
    "                image_label = [int(i) for i in image_label]  # 通过list生成向量\n",
    "                self.list_image_paths.append(image_path)\n",
    "                if (np.array(image_label).sum()==0): #normal\n",
    "                    self.list_image_labels.append([1,0])\n",
    "                else: self.list_image_labels.append([0,1]) #disease\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param index: get item 时提供的索引index数值\n",
    "        :return:\n",
    "            imageData: 图片数据\n",
    "            imageLabel: 标签信息\n",
    "        \"\"\"\n",
    "        image_path = self.list_image_paths[index]\n",
    "        image_data = Image.open(image_path).convert('RGB')\n",
    "        image_label = torch.FloatTensor(self.list_image_labels[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "\n",
    "        return image_data, image_label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "            len: 数据集的总长度\n",
    "        \"\"\"\n",
    "        return len(self.list_image_paths)\n",
    "\n",
    "\n",
    "PATH_TO_IMAGES_DIR = '/data/fjsdata/NIH-CXR/images/images/'\n",
    "PATH_TO_TRAIN_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt'\n",
    "PATH_TO_VAL_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt'\n",
    "PATH_TO_TEST_FILE = '/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt'\n",
    "def get_train_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_train = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                     path_to_dataset_file=PATH_TO_TRAIN_FILE, transform=transform_seq)\n",
    "    data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_train\n",
    "\n",
    "\n",
    "def get_validation_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_validation = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                          path_to_dataset_file=PATH_TO_VAL_FILE, transform=transform_seq)\n",
    "    data_loader_validation = DataLoader(dataset=dataset_validation, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_validation\n",
    "\n",
    "\n",
    "def get_test_dataloader(batch_size, shuffle, num_workers, transform_seq):\n",
    "    dataset_test = DatasetGenerator(path_to_img_dir=PATH_TO_IMAGES_DIR,\n",
    "                                    path_to_dataset_file=PATH_TO_TEST_FILE, transform=transform_seq)\n",
    "    data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size,\n",
    "                                   shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.dense_net_121 = torchvision.models.densenet121(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_121.classifier.in_features\n",
    "        self.dense_net_121.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet169(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet169, self).__init__()\n",
    "        self.dense_net_169 = torchvision.models.densenet169(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_169.classifier.in_features\n",
    "        self.dense_net_169.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_169(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet201(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet201, self).__init__()\n",
    "        self.dense_net_201 = torchvision.models.densenet201(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_201.classifier.in_features\n",
    "        self.dense_net_201.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_201(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 50 / Step: 351 : validation loss = 0.542297best_loss = 0.598165\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = 2 #normal and abnormal classification\n",
    "network_model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#network_model = torch.nn.DataParallel(network_model, device_ids=[0,1,2,3,4,5]).cuda()  # make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.RandomResizedCrop(224))\n",
    "transform_list.append(transforms.RandomHorizontalFlip())\n",
    "transform_list.append(transforms.ToTensor())\n",
    "transform_list.append(normalize)\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get data loader object\n",
    "dataloader_train = get_train_dataloader(batch_size=32, shuffle=True, num_workers=0, transform_seq=transform_sequence)\n",
    "dataloader_val = get_validation_dataloader(batch_size=32,shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "optimizer = torch.optim.Adam(network_model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "loss  = torch.nn.BCELoss()\n",
    "# start training network\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch_index in range(50):#max epoch = 1000\n",
    "    network_model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for batch_index, (image, label) in enumerate(dataloader_train):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            loss_tensor = loss(var_output, var_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : train loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%loss_tensor.item())))\n",
    "            sys.stdout.flush()  \n",
    "\n",
    "    # Validation Process\n",
    "    network_model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        loss_val = 0.\n",
    "        mean_loss_tensor = 0.\n",
    "        for batch_index, (image, label) in enumerate(dataloader_val):\n",
    "            label.cuda()\n",
    "            var_image = torch.autograd.Variable(image).cuda()\n",
    "            var_label = torch.autograd.Variable(label).cuda()\n",
    "            var_output = network_model(var_image)\n",
    "\n",
    "            curr_loss_tensor = loss(var_output, var_label)  # the output of loss() is a tensor\n",
    "            mean_loss_tensor += curr_loss_tensor  # tensor op.\n",
    "            loss_val += curr_loss_tensor.item()  # scalar op.\n",
    "\n",
    "            sys.stdout.write('\\r Epoch: {} / Step: {} : validation loss = {}'.format(epoch_index+1, batch_index+1, float('%0.6f'%curr_loss_tensor.item())))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    loss_val = loss_val / len(dataloader_val)  # scalar\n",
    "    mean_loss_tensor = mean_loss_tensor / len(dataloader_val)  # tensor\n",
    "\n",
    "    # End validation process\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    if loss_val < best_loss:\n",
    "        best_loss = loss_val\n",
    "        best_net = copy.deepcopy(network_model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "network_model = network_model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 702Mean AUROC is 0.764562.\n",
      "Normal 0.764564034213212\n",
      "Abnormal 0.7645609457155434\n"
     ]
    }
   ],
   "source": [
    "def compute_auroc(ground_truth, prediction):\n",
    "        out_auroc = []\n",
    "        np_ground_truth = ground_truth.cpu().numpy()\n",
    "        np_prediction = prediction.cpu().numpy()\n",
    "        for i in range(N_CLASSES):\n",
    "            # calculate the roc_auc_score of each class\n",
    "            out_auroc.append(roc_auc_score(np_ground_truth[:, i], np_prediction[:, i]))\n",
    "        return out_auroc\n",
    "    \n",
    "# normalize data with ImageNet mean and standard deviation\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# compose transform operations\n",
    "transform_list = list()\n",
    "transform_list.append(transforms.Resize(256))\n",
    "transform_list.append(transforms.TenCrop(224))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "transform_list.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "transform_sequence = transforms.Compose(transform_list)\n",
    "# get test data loader\n",
    "data_loader_test = get_test_dataloader(batch_size=32, shuffle=False, num_workers=0, transform_seq=transform_sequence)\n",
    "\n",
    "# initialize test output with tensor of type CUDA-float\n",
    "output_ground_truth = torch.FloatTensor().cuda()\n",
    "output_prediction = torch.FloatTensor().cuda()\n",
    "\n",
    "# start testing\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for batch_index, (image, label) in enumerate(data_loader_test):\n",
    "        label = label.cuda()\n",
    "        output_ground_truth = torch.cat((output_ground_truth, label), 0)\n",
    "        batch_size, n_crops, num_channels, height, width = image.size()\n",
    "        var_image = torch.autograd.Variable(image.view(-1, num_channels, height, width).cuda())\n",
    "        out = best_net(var_image)\n",
    "        out_mean = out.view(batch_size, n_crops, -1).mean(1)\n",
    "        output_prediction = torch.cat((output_prediction, out_mean.data), 0)\n",
    "        sys.stdout.write('\\r Step: {}'.format(batch_index+1))\n",
    "        sys.stdout.flush()\n",
    "    auroc_individual = compute_auroc(output_ground_truth, output_prediction)\n",
    "    auroc_mean = np.array(auroc_individual).mean()\n",
    "\n",
    "print('Mean AUROC is %f.' % auroc_mean)\n",
    "CLASS_NAMES = ['Normal', 'Abnormal'] \n",
    "for i in range(len(auroc_individual)):\n",
    "    print(CLASS_NAMES[i], auroc_individual[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
