{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['No Finding', 'Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', \n",
    "       'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "#torch.cuda.set_device(1)\n",
    "#print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86524 / 86524 The length of trainset is 86524\n",
      "25596 / 25596 The length of testset is 25596\n"
     ]
    }
   ],
   "source": [
    "#preparing the trainset and  testset\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "trData = pd.read_csv(\"/data/fjsdata/NIH-CXR/fjs_train.csv\" , sep=',') #trainset\n",
    "trN, trI, trY = [],[],[]\n",
    "for _, row in trData.iterrows():#[:1001]\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        trN.append(name)#'image_index'\n",
    "        trY.append(target)#'target_vector'\n",
    "        img = cv2.resize(cv2.imread(os.path.join(img_path, name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "\n",
    "teData = pd.read_csv(\"/data/fjsdata/NIH-CXR/fjs_test.csv\" , sep=',') #testset\n",
    "teN, teI, teY = [],[],[]\n",
    "for _, row in teData.iterrows():#[:1001]\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        teN.append(name)#'image_index'\n",
    "        teY.append(target)#'target_vector'\n",
    "        img = cv2.resize(cv2.imread(os.path.join(img_path, name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "====================================2020.10.11=========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 866 / 866 : loss = 0.363833Eopch:     1 mean_loss = 0.189883\n",
      " 866 / 866 : loss = 0.373289Eopch:     2 mean_loss = 0.184085\n",
      " 866 / 866 : loss = 0.374589Eopch:     3 mean_loss = 0.181662\n",
      " 866 / 866 : loss = 0.370496Eopch:     4 mean_loss = 0.180667\n",
      " 866 / 866 : loss = 0.358197Eopch:     5 mean_loss = 0.177757\n",
      " 866 / 866 : loss = 0.356606Eopch:     6 mean_loss = 0.176455\n",
      " 866 / 866 : loss = 0.352629Eopch:     7 mean_loss = 0.175392\n",
      " 866 / 866 : loss = 0.348436Eopch:     8 mean_loss = 0.174355\n",
      " 866 / 866 : loss = 0.350465Eopch:     9 mean_loss = 0.173616\n",
      " 866 / 866 : loss = 0.354101Eopch:    10 mean_loss = 0.172488\n",
      "best_loss = 0.172488\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 15 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 100\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #loss\n",
    "        loss = criterion(y_outputs, y_batch)\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()#release gpu memory\n",
    "I_batch = I_batch.cpu()\n",
    "y_batch = y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 255 / 256 The average AUROC is 0.6535\n",
      "The AUROC of No Finding is 0.6965\n",
      "The AUROC of Atelectasis is 0.6779\n",
      "The AUROC of Cardiomegaly is 0.6761\n",
      "The AUROC of Effusion is 0.7775\n",
      "The AUROC of Infiltration is 0.6087\n",
      "The AUROC of Mass is 0.6185\n",
      "The AUROC of Nodule is 0.5929\n",
      "The AUROC of Pneumonia is 0.6224\n",
      "The AUROC of Pneumothorax is 0.6310\n",
      "The AUROC of Consolidation is 0.6906\n",
      "The AUROC of Edema is 0.7417\n",
      "The AUROC of Emphysema is 0.6053\n",
      "The AUROC of Fibrosis is 0.6148\n",
      "The AUROC of Pleural_Thickening is 0.6495\n",
      "The AUROC of Hernia is 0.5993\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', \\\n",
    "       'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 866 / 866 : loss = 0.377945Eopch:     1 mean_loss = 0.157334\n",
      " 866 / 866 : loss = 0.355685Eopch:     2 mean_loss = 0.152673\n",
      " 866 / 866 : loss = 0.359542Eopch:     3 mean_loss = 0.150143\n",
      " 866 / 866 : loss = 0.355822Eopch:     4 mean_loss = 0.148482\n",
      " 866 / 866 : loss = 0.346721Eopch:     5 mean_loss = 0.147016\n",
      " 866 / 866 : loss = 0.361655Eopch:     6 mean_loss = 0.145787\n",
      " 866 / 866 : loss = 0.346072Eopch:     7 mean_loss = 0.144734\n",
      " 866 / 866 : loss = 0.346776Eopch:     8 mean_loss = 0.143769\n",
      " 866 / 866 : loss = 0.346223Eopch:     9 mean_loss = 0.142909\n",
      " 866 / 866 : loss = 0.341287Eopch:    10 mean_loss = 0.143084\n",
      "best_loss = 0.142909\n"
     ]
    }
   ],
   "source": [
    "trY_ab = trY[:,1:]\n",
    "teY_ab = teY[:,1:]#get rid of 'no finding' label, turn to 14 class\n",
    "N_CLASSES = 14 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 100\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY_ab) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_ab), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(trY_ab[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #loss\n",
    "        loss = criterion(y_outputs, y_batch)\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 255 / 256 The average AUROC is 0.6485\n",
      "The AUROC of Atelectasis is 0.6646\n",
      "The AUROC of Cardiomegaly is 0.6910\n",
      "The AUROC of Effusion is 0.7758\n",
      "The AUROC of Infiltration is 0.6205\n",
      "The AUROC of Mass is 0.6252\n",
      "The AUROC of Nodule is 0.5981\n",
      "The AUROC of Pneumonia is 0.6271\n",
      "The AUROC of Pneumothorax is 0.6132\n",
      "The AUROC of Consolidation is 0.6978\n",
      "The AUROC of Edema is 0.7578\n",
      "The AUROC of Emphysema is 0.5906\n",
      "The AUROC of Fibrosis is 0.6222\n",
      "The AUROC of Pleural_Thickening is 0.6262\n",
      "The AUROC of Hernia is 0.5689\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY_ab) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY_ab), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY_ab[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 866 / 866 : loss = 0.361723Eopch:     1 mean_loss = 0.190226\n",
      " 866 / 866 : loss = 0.361804Eopch:     2 mean_loss = 0.183519\n",
      " 866 / 866 : loss = 0.348654Eopch:     3 mean_loss = 0.180285\n",
      " 866 / 866 : loss = 0.355258Eopch:     4 mean_loss = 0.178179\n",
      " 866 / 866 : loss = 0.356647Eopch:     5 mean_loss = 0.176347\n",
      " 866 / 866 : loss = 0.385051Eopch:     6 mean_loss = 0.175353\n",
      " 866 / 866 : loss = 0.357464Eopch:     7 mean_loss = 0.174459\n",
      " 866 / 866 : loss = 0.354676Eopch:     8 mean_loss = 0.173964\n",
      " 866 / 866 : loss = 0.353243Eopch:     9 mean_loss = 0.172115\n",
      " 866 / 866 : loss = 0.360465Eopch:    10 mean_loss = 0.171444\n",
      " 866 / 866 : loss = 0.360942Eopch:    11 mean_loss = 0.170444\n",
      " 866 / 866 : loss = 0.351964Eopch:    12 mean_loss = 0.172223\n",
      " 866 / 866 : loss = 0.346954Eopch:    13 mean_loss = 0.169429\n",
      " 866 / 866 : loss = 0.345182Eopch:    14 mean_loss = 0.168490\n",
      " 866 / 866 : loss = 0.342252Eopch:    15 mean_loss = 0.168124\n",
      " 866 / 866 : loss = 0.331435Eopch:    16 mean_loss = 0.167197\n",
      " 866 / 866 : loss = 0.322907Eopch:    17 mean_loss = 0.166513\n",
      " 866 / 866 : loss = 0.334013Eopch:    18 mean_loss = 0.166195\n",
      " 866 / 866 : loss = 0.327436Eopch:    19 mean_loss = 0.165784\n",
      " 866 / 866 : loss = 0.351278Eopch:    20 mean_loss = 0.164902\n",
      " 866 / 866 : loss = 0.338592Eopch:    21 mean_loss = 0.170846\n",
      " 866 / 866 : loss = 0.331286Eopch:    22 mean_loss = 0.165799\n",
      " 866 / 866 : loss = 0.326641Eopch:    23 mean_loss = 0.164025\n",
      " 866 / 866 : loss = 0.321717Eopch:    24 mean_loss = 0.162988\n",
      " 866 / 866 : loss = 0.312756Eopch:    25 mean_loss = 0.162537\n",
      " 866 / 866 : loss = 0.329392Eopch:    26 mean_loss = 0.162684\n",
      " 866 / 866 : loss = 0.316404Eopch:    27 mean_loss = 0.164124\n",
      " 866 / 866 : loss = 0.317287Eopch:    28 mean_loss = 0.161493\n",
      " 866 / 866 : loss = 0.328613Eopch:    29 mean_loss = 0.160883\n",
      " 866 / 866 : loss = 0.327253Eopch:    30 mean_loss = 0.160369\n",
      " 866 / 866 : loss = 0.320446Eopch:    31 mean_loss = 0.160030\n",
      " 866 / 866 : loss = 0.329084Eopch:    32 mean_loss = 0.162969\n",
      " 866 / 866 : loss = 0.312839Eopch:    33 mean_loss = 0.159348\n",
      " 866 / 866 : loss = 0.307716Eopch:    34 mean_loss = 0.158211\n",
      " 866 / 866 : loss = 0.314399Eopch:    35 mean_loss = 0.157767\n",
      " 866 / 866 : loss = 0.315896Eopch:    36 mean_loss = 0.156717\n",
      " 866 / 866 : loss = 0.312009Eopch:    37 mean_loss = 0.156578\n",
      " 866 / 866 : loss = 0.305294Eopch:    38 mean_loss = 0.155422\n",
      " 866 / 866 : loss = 0.301925Eopch:    39 mean_loss = 0.154869\n",
      " 866 / 866 : loss = 0.292543Eopch:    40 mean_loss = 0.154170\n",
      " 866 / 866 : loss = 0.302052Eopch:    41 mean_loss = 0.153432\n",
      " 866 / 866 : loss = 0.306392Eopch:    42 mean_loss = 0.152837\n",
      " 866 / 866 : loss = 0.298282Eopch:    43 mean_loss = 0.152129\n",
      " 866 / 866 : loss = 0.301453Eopch:    44 mean_loss = 0.154507\n",
      " 866 / 866 : loss = 0.299025Eopch:    45 mean_loss = 0.150701\n",
      " 866 / 866 : loss = 0.291158Eopch:    46 mean_loss = 0.149644\n",
      " 866 / 866 : loss = 0.294787Eopch:    47 mean_loss = 0.148683\n",
      " 866 / 866 : loss = 0.307443Eopch:    48 mean_loss = 0.147751\n",
      " 866 / 866 : loss = 0.287752Eopch:    49 mean_loss = 0.148118\n",
      " 866 / 866 : loss = 0.295905Eopch:    50 mean_loss = 0.147529\n",
      " 866 / 866 : loss = 0.284469Eopch:    51 mean_loss = 0.145771\n",
      " 866 / 866 : loss = 0.281361Eopch:    52 mean_loss = 0.144585\n",
      " 866 / 866 : loss = 0.286851Eopch:    53 mean_loss = 0.144094\n",
      " 866 / 866 : loss = 0.291716Eopch:    54 mean_loss = 0.142934\n",
      " 866 / 866 : loss = 0.268099Eopch:    55 mean_loss = 0.141617\n",
      " 866 / 866 : loss = 0.283767Eopch:    56 mean_loss = 0.141935\n",
      " 866 / 866 : loss = 0.276754Eopch:    57 mean_loss = 0.140422\n",
      " 866 / 866 : loss = 0.298155Eopch:    58 mean_loss = 0.139576\n",
      " 866 / 866 : loss = 0.279501Eopch:    59 mean_loss = 0.139777\n",
      " 866 / 866 : loss = 0.272979Eopch:    60 mean_loss = 0.137137\n",
      " 866 / 866 : loss = 0.273444Eopch:    61 mean_loss = 0.136709\n",
      " 866 / 866 : loss = 0.276159Eopch:    62 mean_loss = 0.135480\n",
      " 866 / 866 : loss = 0.275987Eopch:    63 mean_loss = 0.134169\n",
      " 866 / 866 : loss = 0.300532Eopch:    64 mean_loss = 0.134017\n",
      " 866 / 866 : loss = 0.298085Eopch:    65 mean_loss = 0.158501\n",
      " 866 / 866 : loss = 0.283959Eopch:    66 mean_loss = 0.141443\n",
      " 866 / 866 : loss = 0.281029Eopch:    67 mean_loss = 0.135764\n",
      " 866 / 866 : loss = 0.279112Eopch:    68 mean_loss = 0.132859\n",
      " 866 / 866 : loss = 0.273226Eopch:    69 mean_loss = 0.131451\n",
      " 866 / 866 : loss = 0.264523Eopch:    70 mean_loss = 0.130905\n",
      " 866 / 866 : loss = 0.256644Eopch:    71 mean_loss = 0.130461\n",
      " 866 / 866 : loss = 0.258916Eopch:    72 mean_loss = 0.128818\n",
      " 866 / 866 : loss = 0.270622Eopch:    73 mean_loss = 0.127398\n",
      " 866 / 866 : loss = 0.262653Eopch:    74 mean_loss = 0.127147\n",
      " 866 / 866 : loss = 0.258505Eopch:    75 mean_loss = 0.125736\n",
      " 866 / 866 : loss = 0.263916Eopch:    76 mean_loss = 0.125673\n",
      " 866 / 866 : loss = 0.259433Eopch:    77 mean_loss = 0.124070\n",
      " 866 / 866 : loss = 0.253677Eopch:    78 mean_loss = 0.123469\n",
      " 866 / 866 : loss = 0.255843Eopch:    79 mean_loss = 0.122315\n",
      " 866 / 866 : loss = 0.256661Eopch:    80 mean_loss = 0.121706\n",
      " 866 / 866 : loss = 0.244161Eopch:    81 mean_loss = 0.121432\n",
      " 866 / 866 : loss = 0.244557Eopch:    82 mean_loss = 0.119644\n",
      " 866 / 866 : loss = 0.250206Eopch:    83 mean_loss = 0.119120\n",
      " 866 / 866 : loss = 0.250754Eopch:    84 mean_loss = 0.118937\n",
      " 866 / 866 : loss = 0.233866Eopch:    85 mean_loss = 0.118491\n",
      " 866 / 866 : loss = 0.244074Eopch:    86 mean_loss = 0.117146\n",
      " 866 / 866 : loss = 0.235137Eopch:    87 mean_loss = 0.121308\n",
      " 866 / 866 : loss = 0.230554Eopch:    88 mean_loss = 0.116580\n",
      " 866 / 866 : loss = 0.237402Eopch:    89 mean_loss = 0.115429\n",
      " 866 / 866 : loss = 0.242765Eopch:    90 mean_loss = 0.115424\n",
      " 866 / 866 : loss = 0.250637Eopch:    91 mean_loss = 0.114963\n",
      " 866 / 866 : loss = 0.239528Eopch:    92 mean_loss = 0.115037\n",
      " 866 / 866 : loss = 0.227664Eopch:    93 mean_loss = 0.114229\n",
      " 866 / 866 : loss = 0.237456Eopch:    94 mean_loss = 0.113027\n",
      " 866 / 866 : loss = 0.232103Eopch:    95 mean_loss = 0.112590\n",
      " 866 / 866 : loss = 0.237648Eopch:    96 mean_loss = 0.112436\n",
      " 866 / 866 : loss = 0.223612Eopch:    97 mean_loss = 0.111217\n",
      " 866 / 866 : loss = 0.240321Eopch:    98 mean_loss = 0.110752\n",
      " 866 / 866 : loss = 0.234867Eopch:    99 mean_loss = 0.110311\n",
      " 866 / 866 : loss = 0.242811Eopch:   100 mean_loss = 0.109740\n",
      "best_loss = 0.109740\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 15 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 100\n",
    "for epoch in range(100):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #loss\n",
    "        loss = criterion(y_outputs, y_batch)\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 255 / 256 The average AUROC is 0.6555\n",
      "The AUROC of No Finding is 0.6081\n",
      "The AUROC of Atelectasis is 0.6636\n",
      "The AUROC of Cardiomegaly is 0.7062\n",
      "The AUROC of Effusion is 0.7520\n",
      "The AUROC of Infiltration is 0.5791\n",
      "The AUROC of Mass is 0.6987\n",
      "The AUROC of Nodule is 0.6253\n",
      "The AUROC of Pneumonia is 0.6063\n",
      "The AUROC of Pneumothorax is 0.7065\n",
      "The AUROC of Consolidation is 0.6629\n",
      "The AUROC of Edema is 0.7419\n",
      "The AUROC of Emphysema is 0.6478\n",
      "The AUROC of Fibrosis is 0.6017\n",
      "The AUROC of Pleural_Thickening is 0.6496\n",
      "The AUROC of Hernia is 0.5835\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', \\\n",
    "       'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
