{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2ï¼‰Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', \\\n",
    "       'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.filters as filters\n",
    "from scipy.ndimage import binary_dilation\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86524 / 86524 The length of trainset is 86524\n",
      "25596 / 25596 The length of testset is 25596\n",
      "The length of testset is 984\n"
     ]
    }
   ],
   "source": [
    "def Image_Processing(img_path, crop_size=224):\n",
    "    img = Image.open(img_path).convert('RGB').resize((256, 256),Image.ANTIALIAS) #open and resize\n",
    "    #crop and normalize\n",
    "    transform_sequence = transforms.Compose([\n",
    "                                             #transforms.ToPILImage(), #if not PILImage\n",
    "                                             transforms.CenterCrop(crop_size),\n",
    "                                             transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                             #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                            ])\n",
    "    img = transform_sequence(img).numpy() #tensor to numpy\n",
    "    return img\n",
    "\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia','Pneumothorax', \\\n",
    "               'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'] \n",
    "#preparing the trainset and  testset\n",
    "trData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_train.csv\" , sep=',') #trainset\n",
    "trN, trI, trY = [],[],[]\n",
    "for _, row in trData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        trN.append(name)#'image_index'\n",
    "        trY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        trI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "\n",
    "teData = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_test.csv\" , sep=',') #testset\n",
    "teN, teI, teY = [],[],[]\n",
    "for _, row in teData.iterrows():\n",
    "    name = row['image_index']\n",
    "    target = np.fromstring(row['target_vector'].strip('[').strip(']'), dtype=int, sep=' ') #turn string to numpy.ndarray\n",
    "    try:\n",
    "        teN.append(name)#'image_index'\n",
    "        teY.append(target)#'target_vector'\n",
    "        img = Image_Processing(os.path.join(img_path, name))\n",
    "        teI.append(img)\n",
    "    except:\n",
    "        print(name+\":\"+str(os.path.join(img_path, name)))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)\n",
    "\n",
    "#preparing bounding box dataset\n",
    "boxdata = pd.read_csv(\"/data/fjsdata/NIH-CXR/chexnet_dataset/fjs_BBox.csv\" , sep=',')\n",
    "boxdata = boxdata[['Image Index','Finding Label','Bbox [x', 'y', 'w', 'h]']]\n",
    "#print('Dataset statistic, records: %d, fields: %d' % (boxdata.shape[0], boxdata.shape[1]))\n",
    "#print(boxdata.columns.values.tolist())\n",
    "bbN, bbI, bbY, bBox = [],[],[],[]\n",
    "for _, row in boxdata.iterrows():\n",
    "    bbN.append(row['Image Index'])\n",
    "    \n",
    "    img = Image_Processing(os.path.join(img_path, row['Image Index']))\n",
    "    bbI.append(img)\n",
    "    \n",
    "    labels = np.zeros(len(CLASS_NAMES))\n",
    "    labels[CLASS_NAMES.index(row['Finding Label'])] = 1\n",
    "    bbY.append(labels)\n",
    "    \n",
    "    bBox.append(np.array([row['Bbox [x'], row['y'], row['w'], row['h]']])) #xywh  \n",
    "print('The length of testset is %d'%len(bbN))\n",
    "bbI = np.array(bbI)\n",
    "bbY = np.array(bbY)\n",
    "bBox = np.array(bBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/zhouyuangan/SE_DenseNet\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        assert channel > reduction, \"Make sure your input channel bigger than reduction which equals to {}\".format(reduction)\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, channel // reduction),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channel // reduction, channel),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "    \n",
    "__all__ = ['SEDenseNet', 'se_densenet121', 'se_densenet169', 'se_densenet201', 'se_densenet161']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def se_densenet121(pretrained=False, is_strict=False, **kwargs):\n",
    "    r\"\"\"Densenet-121 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SEDenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                     **kwargs)\n",
    "    if pretrained:\n",
    "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "        # They are also in the checkpoints in model_urls. This pattern is used\n",
    "        # to find such keys.\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
    "        for key in list(state_dict.keys()):\n",
    "            res = pattern.match(key)\n",
    "            if res:\n",
    "                new_key = res.group(1) + res.group(2)\n",
    "                state_dict[new_key] = state_dict[key]\n",
    "                del state_dict[key]\n",
    "        model.load_state_dict(state_dict, strict=is_strict)\n",
    "    return model\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        # Add SELayer at here, like SE-PRE block in original paper illustrates\n",
    "        self.add_module(\"selayer\", SELayer(channel=num_input_features)),\n",
    "\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),        \n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class SEDenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
    "\n",
    "        super(SEDenseNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # Add SELayer at first convolution\n",
    "        self.features.add_module(\"SELayer_0a\", SELayer(channel=num_init_features))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            # Add a SELayer \n",
    "            self.features.add_module(\"SELayer_%da\" % (i + 1), SELayer(channel=num_features))\n",
    "\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "\n",
    "            if i != len(block_config) - 1:\n",
    "                # Add a SELayer behind each transition block\n",
    "                self.features.add_module(\"SELayer_%db\" % (i + 1), SELayer(channel=num_features))\n",
    "\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Add SELayer\n",
    "        self.features.add_module(\"SELayer_0b\", SELayer(channel=num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4327 / 4327 : train loss = 0.371377Eopch:     1 mean_loss = 0.194174\n",
      " 4327 / 4327 : train loss = 0.359695Eopch:     2 mean_loss = 0.189467\n",
      " 4327 / 4327 : train loss = 0.364817Eopch:     3 mean_loss = 0.187301\n",
      " 4327 / 4327 : train loss = 0.363436Eopch:     4 mean_loss = 0.185852\n",
      " 4327 / 4327 : train loss = 0.357042Eopch:     5 mean_loss = 0.184770\n",
      " 4327 / 4327 : train loss = 0.355626Eopch:     6 mean_loss = 0.183880\n",
      " 4327 / 4327 : train loss = 0.354741Eopch:     7 mean_loss = 0.183087\n",
      " 4327 / 4327 : train loss = 0.360168Eopch:     8 mean_loss = 0.182678\n",
      " 4327 / 4327 : train loss = 0.350223Eopch:     9 mean_loss = 0.181980\n",
      " 4327 / 4327 : train loss = 0.347146Eopch:    10 mean_loss = 0.181541\n",
      " 4327 / 4327 : train loss = 0.352829Eopch:    11 mean_loss = 0.180982\n",
      " 4327 / 4327 : train loss = 0.355467Eopch:    12 mean_loss = 0.180689\n",
      " 4327 / 4327 : train loss = 0.353653Eopch:    13 mean_loss = 0.180350\n",
      " 4327 / 4327 : train loss = 0.352599Eopch:    14 mean_loss = 0.180087\n",
      " 4327 / 4327 : train loss = 0.348231Eopch:    15 mean_loss = 0.179675\n",
      " 4327 / 4327 : train loss = 0.358938Eopch:    16 mean_loss = 0.179346\n",
      " 4327 / 4327 : train loss = 0.364947Eopch:    17 mean_loss = 0.178933\n",
      " 4327 / 4327 : train loss = 0.364469Eopch:    18 mean_loss = 0.178708\n",
      " 4327 / 4327 : train loss = 0.365696Eopch:    19 mean_loss = 0.178235\n",
      " 4327 / 4327 : train loss = 0.369997Eopch:    20 mean_loss = 0.178137\n",
      " 4327 / 4327 : train loss = 0.371484Eopch:    21 mean_loss = 0.177760\n",
      " 4327 / 4327 : train loss = 0.353159Eopch:    22 mean_loss = 0.177619\n",
      " 4327 / 4327 : train loss = 0.372961Eopch:    23 mean_loss = 0.177264\n",
      " 4327 / 4327 : train loss = 0.358788Eopch:    24 mean_loss = 0.177016\n",
      " 4327 / 4327 : train loss = 0.364203Eopch:    25 mean_loss = 0.176827\n",
      " 4327 / 4327 : train loss = 0.351123Eopch:    26 mean_loss = 0.176568\n",
      " 4327 / 4327 : train loss = 0.360872Eopch:    27 mean_loss = 0.176386\n",
      " 4327 / 4327 : train loss = 0.364384Eopch:    28 mean_loss = 0.176147\n",
      " 4327 / 4327 : train loss = 0.363732Eopch:    29 mean_loss = 0.175940\n",
      " 4327 / 4327 : train loss = 0.365345Eopch:    30 mean_loss = 0.175775\n",
      "best_loss = 0.175775\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = len(CLASS_NAMES) #class numbers\n",
    "model = se_densenet121(num_classes=N_CLASSES).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 20 #'Batch Size': 32\n",
    "for epoch in range(30):#'Max Epoch': 1000\n",
    "    losses = []\n",
    "    losses_tensor = 0.\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch)#permute the dims of matrixï¼Œ .permute(0, 3, 1, 2)\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()  \n",
    "            losses.append(loss.item())\n",
    "            losses_tensor += loss\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    scheduler.step(losses_tensor.item())\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1263 / 1280 "
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    gt = torch.cat((gt, y_batch), 0)\n",
    "    y_outputs = best_net(I_batch)#forword\n",
    "    pred = torch.cat((pred, y_outputs.data), 0)\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32 / 33 The average AUROC is 0.5322\n",
      "The AUROC of Atelectasis is 0.5168\n",
      "The AUROC of Cardiomegaly is 0.4978\n",
      "The AUROC of Effusion is 0.5841\n",
      "The AUROC of Infiltration is 0.5661\n",
      "The AUROC of Mass is 0.4416\n",
      "The AUROC of Nodule is 0.5807\n",
      "The AUROC of Pneumonia is 0.5044\n",
      "The AUROC of Pneumothorax is 0.5662\n"
     ]
    }
   ],
   "source": [
    "#performance of boxset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(bbY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(bbY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(bbI)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(bbY)[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch)#forwordï¼Œ.permute(0, 3, 1, 2)\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the normal samples.\n",
    "index = np.where(np.sum(trY, axis=1) != 0 )[0] \n",
    "trY_ex = trY[index]\n",
    "trI_ex = trI[index]\n",
    "print(trI_ex.shape)\n",
    "index = np.where(np.sum(valY, axis=1) != 0 )[0]\n",
    "valY_ex = valY[index]\n",
    "valI_ex = valI[index]\n",
    "print(valI_ex.shape)\n",
    "index = np.where(np.sum(teY, axis=1) != 0 )[0] \n",
    "teY_ex = teY[index]\n",
    "teI_ex = teI[index]\n",
    "print(teI_ex.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
