{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Chest X-Ray8\n",
    "https://www.kaggle.com/nih-chest-xrays/data\n",
    "https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
    "1) 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "2）Label:['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "        'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "torch.cuda.set_device(6)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78468 / 78468 The length of trainset is 78468\n",
      "11219 / 11219 The length of validset is 11219\n",
      "22433 / 22433 The length of testset is 22433\n"
     ]
    }
   ],
   "source": [
    "#preparing the trainset and  testset\n",
    "img_path = '/data/fjsdata/NIH-CXR/images/images/' \n",
    "trN, trI, trY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/train.txt', \"r\") as file_descriptor: #tarinset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            trN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            trY.append(np.array(image_label))\n",
    "            img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            trI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),78468))\n",
    "        sys.stdout.flush()\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)   \n",
    "print('The length of trainset is %d'%len(trN))\n",
    "        \n",
    "valN, valI, valY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/val.txt', \"r\") as file_descriptor: #valset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            valN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            valY.append(np.array(image_label))\n",
    "            img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            valI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(valN),11219))\n",
    "        sys.stdout.flush()\n",
    "valI = np.array(valI)\n",
    "valY = np.array(valY) \n",
    "print('The length of validset is %d'%len(valN))\n",
    "\n",
    "teN, teI, teY = [],[],[]\n",
    "with open('/data/fjsdata/NIH-CXR/chexnet_dataset/test.txt', \"r\") as file_descriptor: #testset\n",
    "    lines = file_descriptor.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line_items = line.split()\n",
    "            image_name = line_items[0].split('/')[1]\n",
    "            teN.append(image_name)\n",
    "            image_label = line_items[1:]  # 14 labels from index 2\n",
    "            image_label = [int(i) for i in image_label]  \n",
    "            teY.append(np.array(image_label))\n",
    "            img = cv2.resize(cv2.imread(os.path.join(img_path, image_name)).astype(np.float32), (256, 256))#(256,256,3)\n",
    "            teI.append(img)\n",
    "        except:\n",
    "            print(image_name+\":\"+str(os.path.join(img_path, image_name)))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),22433))\n",
    "        sys.stdout.flush()\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)    \n",
    "print('The length of testset is %d'%len(teN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.dense_net_121 = torchvision.models.densenet121(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_121.classifier.in_features\n",
    "        self.dense_net_121.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet169(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet169, self).__init__()\n",
    "        self.dense_net_169 = torchvision.models.densenet169(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_169.classifier.in_features\n",
    "        self.dense_net_169.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_169(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet201(nn.Module):\n",
    "    def __init__(self, num_classes, is_pre_trained):\n",
    "        super(DenseNet201, self).__init__()\n",
    "        self.dense_net_201 = torchvision.models.densenet201(pretrained=is_pre_trained)\n",
    "        num_fc_kernels = self.dense_net_201.classifier.in_features\n",
    "        self.dense_net_201.classifier = nn.Sequential(nn.Linear(num_fc_kernels, num_classes), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_net_201(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1122 / 1122 : loss = 0.229734Eopch:     1 val_loss = 0.179797\n",
      " 1122 / 1122 : loss = 0.224769Eopch:     2 val_loss = 0.178051\n",
      " 1122 / 1122 : loss = 0.219881Eopch:     3 val_loss = 0.174272\n",
      " 1122 / 1122 : loss = 0.222542Eopch:     4 val_loss = 0.172049\n",
      " 1122 / 1122 : loss = 0.225083Eopch:     5 val_loss = 0.170893\n",
      " 1122 / 1122 : loss = 0.219798Eopch:     6 val_loss = 0.170776\n",
      " 1122 / 1122 : loss = 0.222643Eopch:     7 val_loss = 0.169828\n",
      " 1122 / 1122 : loss = 0.223932Eopch:     8 val_loss = 0.169610\n",
      " 1122 / 1122 : loss = 0.223391Eopch:     9 val_loss = 0.169516\n",
      " 1122 / 1122 : loss = 0.226725Eopch:    10 val_loss = 0.168812\n",
      "best_loss = 0.168812\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 14 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10 #'Batch Size': 32\n",
    "for epoch in range(10):#'Max Epoch': 1000\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    print(\"Eopch: %5d val_loss = %.6f\" % (epoch + 1, np.mean(loss_val)))\n",
    "    if np.mean(loss_val) < best_loss:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "I_batch = I_batch.cpu()\n",
    "y_batch = y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2243 / 2244 The average AUROC is 0.6997\n",
      "The AUROC of Atelectasis is 0.7278\n",
      "The AUROC of Cardiomegaly is 0.6968\n",
      "The AUROC of Effusion is 0.8015\n",
      "The AUROC of Infiltration is 0.6485\n",
      "The AUROC of Mass is 0.6341\n",
      "The AUROC of Nodule is 0.5937\n",
      "The AUROC of Pneumonia is 0.6514\n",
      "The AUROC of Pneumothorax is 0.6878\n",
      "The AUROC of Consolidation is 0.7600\n",
      "The AUROC of Edema is 0.8164\n",
      "The AUROC of Emphysema is 0.6528\n",
      "The AUROC of Fibrosis is 0.7062\n",
      "The AUROC of Pleural_Thickening is 0.6628\n",
      "The AUROC of Hernia is 0.7562\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/checkpoints/densenet169-b2777c0a.pth\n",
      "100%|██████████| 57365526/57365526 [07:50<00:00, 121986.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1122 / 1122 : loss = 0.306353Eopch:     1 val_loss = 0.266647\n",
      " 1122 / 1122 : loss = 0.225867Eopch:     2 val_loss = 0.180029\n",
      " 1122 / 1122 : loss = 0.217373Eopch:     3 val_loss = 0.176112\n",
      " 1122 / 1122 : loss = 0.220139Eopch:     4 val_loss = 0.176237\n",
      " 1122 / 1122 : loss = 0.230699Eopch:     5 val_loss = 0.178417\n",
      " 1122 / 1122 : loss = 0.218961Eopch:     6 val_loss = 0.176261\n",
      " 1122 / 1122 : loss = 0.222816Eopch:     7 val_loss = 0.173360\n",
      " 1122 / 1122 : loss = 0.224277Eopch:     8 val_loss = 0.171827\n",
      " 1122 / 1122 : loss = 0.225518Eopch:     9 val_loss = 0.170091\n",
      " 1122 / 1122 : loss = 0.226122Eopch:    10 val_loss = 0.168863\n",
      "best_loss = 0.168863\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 14 #class numbers\n",
    "model = DenseNet169(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10 #'Batch Size': 32\n",
    "for epoch in range(10):#'Max Epoch': 1000\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    print(\"Eopch: %5d val_loss = %.6f\" % (epoch + 1, np.mean(loss_val)))\n",
    "    if np.mean(loss_val) < best_loss:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "I_batch = I_batch.cpu()\n",
    "y_batch = y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2243 / 2244 The average AUROC is 0.6858\n",
      "The AUROC of Atelectasis is 0.7172\n",
      "The AUROC of Cardiomegaly is 0.6627\n",
      "The AUROC of Effusion is 0.7969\n",
      "The AUROC of Infiltration is 0.6481\n",
      "The AUROC of Mass is 0.6212\n",
      "The AUROC of Nodule is 0.5825\n",
      "The AUROC of Pneumonia is 0.6580\n",
      "The AUROC of Pneumothorax is 0.6671\n",
      "The AUROC of Consolidation is 0.7678\n",
      "The AUROC of Edema is 0.8258\n",
      "The AUROC of Emphysema is 0.6450\n",
      "The AUROC of Fibrosis is 0.7055\n",
      "The AUROC of Pleural_Thickening is 0.6343\n",
      "The AUROC of Hernia is 0.6687\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36063, 256, 256, 3)\n",
      "(5140, 14)\n",
      "(10505, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#Exclude the normal samples.\n",
    "index = np.where(np.sum(trY, axis=1) != 0 )[0] \n",
    "trY_ex = trY[index]\n",
    "trI_ex = trI[index]\n",
    "print(trI_ex.shape)\n",
    "index = np.where(np.sum(valY, axis=1) != 0 )[0]\n",
    "valY_ex = valY[index]\n",
    "valI_ex = valI[index]\n",
    "print(valI_ex.shape)\n",
    "index = np.where(np.sum(teY, axis=1) != 0 )[0] \n",
    "teY_ex = teY[index]\n",
    "teI_ex = teI[index]\n",
    "print(teI_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 514 / 514 : validation loss = 0.255188Eopch:     1 val_loss = 0.320859\n",
      " 514 / 514 : validation loss = 0.250327Eopch:     2 val_loss = 0.300148\n",
      " 514 / 514 : validation loss = 0.238933Eopch:     3 val_loss = 0.299890\n",
      " 514 / 514 : validation loss = 0.227912Eopch:     4 val_loss = 0.294252\n",
      " 514 / 514 : validation loss = 0.235433Eopch:     5 val_loss = 0.293694\n",
      " 514 / 514 : validation loss = 0.230859Eopch:     6 val_loss = 0.290944\n",
      " 514 / 514 : validation loss = 0.233728Eopch:     7 val_loss = 0.291892\n",
      " 514 / 514 : validation loss = 0.258102Eopch:     8 val_loss = 0.296948\n",
      " 514 / 514 : validation loss = 0.266383Eopch:     9 val_loss = 0.298607\n",
      " 514 / 514 : validation loss = 0.251328Eopch:    10 val_loss = 0.296055\n",
      "best_loss = 0.290944\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 14 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10 #'Batch Size': 32\n",
    "for epoch in range(10):#'Max Epoch': 1000\n",
    "    num_batches = len(trY_ex) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY_ex), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI_ex[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY_ex[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : train loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY_ex) // batchSize #+1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY_ex), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI_ex[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY_ex[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            sys.stdout.write('\\r {} / {} : validation loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY_ex)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    print(\"Eopch: %5d val_loss = %.6f\" % (epoch + 1, np.mean(loss_val)))\n",
    "    if np.mean(loss_val) < best_loss:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "I_batch = I_batch.cpu()\n",
    "y_batch = y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2243 / 2244 The average AUROC is 0.6489\n",
      "The AUROC of Atelectasis is 0.6657\n",
      "The AUROC of Cardiomegaly is 0.6783\n",
      "The AUROC of Effusion is 0.7411\n",
      "The AUROC of Infiltration is 0.5947\n",
      "The AUROC of Mass is 0.5074\n",
      "The AUROC of Nodule is 0.5416\n",
      "The AUROC of Pneumonia is 0.6522\n",
      "The AUROC of Pneumothorax is 0.6274\n",
      "The AUROC of Consolidation is 0.7321\n",
      "The AUROC of Edema is 0.7948\n",
      "The AUROC of Emphysema is 0.5760\n",
      "The AUROC of Fibrosis is 0.6518\n",
      "The AUROC of Pleural_Thickening is 0.5812\n",
      "The AUROC of Hernia is 0.7399\n"
     ]
    }
   ],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-daead0fc4b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#permute the dims of matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-8c877928b015>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpos_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mneg_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpos_pair_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mneg_pair_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "N_CLASSES = 14 #class numbers\n",
    "model = DenseNet121(num_classes=N_CLASSES, is_pre_trained=True).cuda()#initialize model\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7]).cuda()# make model available multi GPU cores training\n",
    "#torch.backends.cudnn.benchmark = True  # improve train speed slightly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = CircleLoss()\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10 #'Batch Size': 32\n",
    "for epoch in range(10):#'Max Epoch': 1000\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    model.train()  # set network as train mode\n",
    "    with torch.autograd.enable_grad():\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()#grad vanish\n",
    "            min_idx = i * batchSize\n",
    "            max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(trY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            #forword\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "            #loss\n",
    "            loss = criterion(y_outputs, y_batch)\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "            sys.stdout.flush()     \n",
    "    #validation process\n",
    "    loss_val = []\n",
    "    mean_loss_tensor = 0.\n",
    "    num_batches = len(valY) // batchSize  +1\n",
    "    model.eval()  # set network as eval mode without BN & Dropout\n",
    "    with torch.autograd.no_grad():\n",
    "        for j in range(num_batches):\n",
    "            min_idx = j * batchSize\n",
    "            max_idx = np.min([len(valY), (j+1)*batchSize])\n",
    "            I_batch = torch.from_numpy(valI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_batch = torch.from_numpy(valY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "            y_outputs = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "            curr_loss = criterion(y_outputs, y_batch)\n",
    "            sys.stdout.write('\\r {} / {} : loss = {}'.format(j + 1, num_batches, float('%0.6f'%curr_loss.item()) ) )\n",
    "            sys.stdout.flush()  \n",
    "            mean_loss_tensor += curr_loss  # tensor op.\n",
    "            loss_val.append(curr_loss.item())\n",
    "    mean_loss_tensor = mean_loss_tensor / len(valY)  # tensor\n",
    "    scheduler.step(mean_loss_tensor.item())\n",
    "    print(\"Eopch: %5d val_loss = %.6f\" % (epoch + 1, np.mean(loss_val)))\n",
    "    if np.mean(loss_val) < best_loss:\n",
    "        best_loss = np.mean(loss_val)\n",
    "        best_net = copy.deepcopy(model)        \n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "I_batch = I_batch.cpu()\n",
    "y_batch = y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance of testset\n",
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().cuda()\n",
    "pred = torch.FloatTensor().cuda()\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "best_net.eval()  # set network as eval mode without BN & Dropout\n",
    "with torch.autograd.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(teY[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        gt = torch.cat((gt, y_batch), 0)\n",
    "        y_outputs = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "        pred = torch.cat((pred, y_outputs.data), 0)\n",
    "        sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion','Infiltration', 'Mass', 'Nodule', 'Pneumonia', \\\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n",
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "    print('The AUROC of {} is {:.4f}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=====================================split===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assert that there is no patient overlap between the splits\n",
    "for i in range(len(trN)):\n",
    "    for j in range(len(teN)):\n",
    "        if(trN[i].split('_')[0] == teN[j].split('_')[0]):\n",
    "            print(trN[i])\n",
    "for i in range(len(valN)):\n",
    "    for j in range(len(teN)):\n",
    "        if(valN[i].split('_')[0] == teN[j].split('_')[0]):\n",
    "            print(valN[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Interval: 20.204\n",
      "95% likelihood that the true value is between 162.920 and 203.328\n",
      "True value: 180.955\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression prediction with prediction interval\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from numpy import power\n",
    "from numpy import sqrt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import sum as arraysum\n",
    "from scipy.stats import linregress\n",
    "from matplotlib import pyplot\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# prepare data\n",
    "x = 20 * randn(1000) + 100\n",
    "y = x + (10 * randn(1000) + 50)\n",
    "# fit linear regression model\n",
    "b1, b0, r_value, p_value, std_err = linregress(x, y)\n",
    "# make predictions\n",
    "yhat = b0 + b1 * x\n",
    "# define new input, expected value and prediction\n",
    "x_in = x[0]\n",
    "y_out = y[0]\n",
    "yhat_out = yhat[0]\n",
    "# estimate stdev of yhat\n",
    "sum_errs = arraysum((y - yhat)**2)\n",
    "stdev = sqrt(1/(len(y)-2) * sum_errs)\n",
    "# calculate prediction interval\n",
    "interval = 1.96 * stdev #95%\n",
    "print('Prediction Interval: %.3f' % interval)\n",
    "lower, upper = yhat_out - interval, yhat_out + interval\n",
    "print('95%% likelihood that the true value is between %.3f and %.3f' % (lower, upper))\n",
    "print('True value: %.3f' % y_out)\n",
    "# plot dataset and prediction with interval\n",
    "pyplot.scatter(x, y)\n",
    "pyplot.plot(x, yhat, color='red')\n",
    "pyplot.errorbar(x_in, yhat_out, yerr=interval, color='black', fmt='o')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
