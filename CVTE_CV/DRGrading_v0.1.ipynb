{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: Fundus-DR https://www.kaggle.com/c/diabetic-retinopathy-detection/data\n",
    "           https://www.kaggle.com/tanlikesmath/diabetic-retinopathy-resized\n",
    "        1)Label:0 - No DR,1 - Mild,2 - Moderate,3 - Severe,4 - Proliferative DR\n",
    "        2)Dataset: \n",
    "        trainset(0-23236, 1-2196, 2-4751, 3-796, 4-634)\n",
    "        testset(0-2574, 1-247, 2-541, 3-77, 4-74)\n",
    "3.Performance Metric: \n",
    "  1)mAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  2)Feature computation time, Retrieval time, Training time, Memory cost.\n",
    "临床问题：彩色眼底照\n",
    "1）在发现伴有黄斑水肿的视网膜增厚时，以及发现细微的 NVD 或 NVE 方面，不足；\n",
    "2）当仅有轻微的糖尿病视网膜病变，或从上次眼底照相以来病变无明显变化时，不足；\n",
    "术语：\n",
    "1)视乳头新生血管（new vessels at the optic disc, NVD）和视网膜其他区域的新生血管（new vessels elsewhere in the retina, NVE）\n",
    "2)黄斑水肿（clinically significant macular edema, CSME），累及或即将累及黄斑中央部的视网膜增 厚和/或邻近的硬性渗出\n",
    "3)IRMA：视网膜内血管异常；NPDR：非增生性糖尿病视网膜病变；PDR：增生性糖尿病视网膜病变(proliferative diabetic retinopathy)\n",
    "4)Macular edema:黄斑水肿：在黄斑中央的 1 或 2 个视乳头直径范围内的视网膜增厚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(3)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31613 / 31613 The length of train set is 31613\n",
      "3513 / 3513 The length of train set is 3513\n",
      "Completed buliding index in 6190 seconds\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Name:[name],I:[img],Y[type]\n",
    "root_dir = '/data/fjsdata/fundus/kaggle_DR/train/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/kaggle_DR/CBIR_train.csv\" , sep=',')#load dataset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/kaggle_DR/CBIR_test.csv\" , sep=',')#load dataset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trN, trI, trY = [],[],[]\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, iname+'.jpeg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "        trN.append(iname)\n",
    "        trI.append(img)\n",
    "        trY.append(itype)  \n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trainset.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trN))\n",
    "#read test image with CV\n",
    "teN, teI, teY = [],[],[]\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, iname+'.jpeg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "        teN.append(iname)\n",
    "        teI.append(img)\n",
    "        teY.append(itype)  \n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),testset.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(teN))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multi-scale Attention (salient regions) + Circle loss for DR grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss\n",
    "\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        #x = avg_out*max_out\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class NNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks=[2,2,2,2], code_size=5):\n",
    "        super(NNet, self).__init__()\n",
    "        \n",
    "        #layer1: (3,256,256)->(8,128,128)\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        #residual blocks\n",
    "        self.in_planes = 8 \n",
    "        self.scale1 = self._make_layer(block, 8, num_blocks[0], stride=1)\n",
    "        self.scale2 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.scale3 = self._make_layer(block, 32, num_blocks[2], stride=1)\n",
    "        self.scale4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        #Spatial Attention\n",
    "        self.sa = SpatialAttention() #spatial-attention\n",
    "        #layer2: (256,32,32)->(128,16,16)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        #code_size: bits of hash code or classes\n",
    "        self.dense = nn.Linear(128*16*16, code_size) \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))#(3,256,256)->(8,128,128)\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=1, padding=1)#(8,128,128)->(8,128,128)\n",
    "        #scale 1：\n",
    "        x = self.scale1(x)#(8,128,128)->(32,128,128)\n",
    "        x = self.sa(x)*x\n",
    "        #scale  2：\n",
    "        x = self.scale2(x)#(32,128,128)->(64,64,64)\n",
    "        x = self.sa(x)*x\n",
    "        #scale  3：\n",
    "        x = self.scale3(x)#(64,64,64)->(128,64,64)\n",
    "        x = self.sa(x)*x\n",
    "        #scale  4：\n",
    "        x = self.scale4(x)#(128,64,64)->(256,32,32)\n",
    "        x = self.sa(x)*x\n",
    "        #layer2:\n",
    "        x = F.relu(self.bn2(self.conv2(x)))#(256,32,32)->(128,16,16)\n",
    "        x = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)#(128,16,16)->(128,16,16)\n",
    "        #Dense\n",
    "        x = x.view(x.size(0),-1)\n",
    "        opt = self.dense(x)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "net = NNet(block=Bottleneck)\n",
    "fms = net(Variable(torch.randn(10,3,256,256)))\n",
    "for fm in fms:\n",
    "    print(fm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3162 / 3162 : loss = 6.0730926Eopch:     1 mean_loss = 21.449644\n",
      " 3162 / 3162 : loss = 0.0599655Eopch:     2 mean_loss = 20.815165\n",
      " 3162 / 3162 : loss = 12.584155Eopch:     3 mean_loss = 20.705597\n",
      " 3162 / 3162 : loss = 10.861746Eopch:     4 mean_loss = 20.782755\n",
      " 3162 / 3162 : loss = 0.0322638Eopch:     5 mean_loss = 20.730175\n",
      " 3162 / 3162 : loss = 8.7811358Eopch:     6 mean_loss = 20.549238\n",
      " 3162 / 3162 : loss = 0.0378073Eopch:     7 mean_loss = 20.561304\n",
      " 3162 / 3162 : loss = 0.0084469Eopch:     8 mean_loss = 20.509758\n",
      " 3162 / 3162 : loss = 0.0924438Eopch:     9 mean_loss = 20.333445\n",
      " 3162 / 3162 : loss = 0.0964363Eopch:    10 mean_loss = 20.649014\n",
      "best_loss = 20.333445\n",
      " 351 / 352 Accuracy: 0.117279\n",
      "[[ 346    0    0    0 2228]\n",
      " [  44    0    0    0  203]\n",
      " [  85    0    0    0  456]\n",
      " [  12    0    0    0   65]\n",
      " [   8    0    0    0   66]]\n",
      "Specificity of No DR: 0.134421\n",
      "Sensitivity of Mild DR: 0.000000\n",
      "Sensitivity of Moderate DR: 0.000000\n",
      "Sensitivity of Severe DR: 0.000000\n",
      "Sensitivity of Proliferative DR: 0.891892\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = NNet(block=Bottleneck).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "circleloss = CircleLoss().cuda() #define loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = circleloss(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        loss.backward()#backward\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "circleloss = circleloss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#predicting\n",
    "teY_pred = []\n",
    "teI = np.array(teI)\n",
    "teY = np.array(teY)\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(teI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "    x_feat = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    x_feat = F.log_softmax(x_feat,dim=1) \n",
    "    y_pred = x_feat.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(y_pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#classification performance\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))#performance of classification\n",
    "labels = list(set(teY))\n",
    "#0 - No DR,1 - Mild,2 - Moderate,3 - Severe,4 - Proliferative DR\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) \n",
    "print (cm)\n",
    "print ('Specificity of No DR: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Mild DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Moderate DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Severe DR: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Proliferative DR: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "circleloss = circleloss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multi-scale Attention + R-MAC for DR Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(L2Normalization, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.is_cuda:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps])).cuda(torch.cuda.device_of(x).idx)\n",
    "        else:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps]))\n",
    "        x = torch.div(x.transpose(0,1),x.max(1)[0]).transpose(0,1) # max_normed\n",
    "        norm = torch.norm(x,2,1) + caped_eps.expand(x.size()[0])\n",
    "        y = torch.div(x.transpose(0,1),norm).transpose(0,1)\n",
    "        return y\n",
    "    \n",
    "class RMAC(nn.Module):\n",
    "    \"\"\"\n",
    "    Regional Maximum activation of convolutions (R-MAC).\n",
    "    c.f. https://arxiv.org/pdf/1511.05879.pdf\n",
    "    Args:\n",
    "        level_n (int): number of levels for selecting regions.\n",
    "    \"\"\"\n",
    "    def __init__(self,level_n:int):\n",
    "        super(RMAC, self).__init__()\n",
    "        self.first_show = True\n",
    "        self.cached_regions = dict()\n",
    "        self.level_n = level_n\n",
    "\n",
    "    def _get_regions(self, h: int, w: int) -> List:\n",
    "        \"\"\"\n",
    "        Divide the image into several regions.\n",
    "        Args:\n",
    "            h (int): height for dividing regions.\n",
    "            w (int): width for dividing regions.\n",
    "        Returns:\n",
    "            regions (List): a list of region positions.\n",
    "        \"\"\"\n",
    "        if (h, w) in self.cached_regions:\n",
    "            return self.cached_regions[(h, w)]\n",
    "\n",
    "        m = 1\n",
    "        n_h, n_w = 1, 1\n",
    "        regions = list()\n",
    "        if h != w:\n",
    "            min_edge = min(h, w)\n",
    "            left_space = max(h, w) - min(h, w)\n",
    "            iou_target = 0.4\n",
    "            iou_best = 1.0\n",
    "            while True:\n",
    "                iou_tmp = (min_edge ** 2 - min_edge * (left_space // m)) / (min_edge ** 2)\n",
    "\n",
    "                # small m maybe result in non-overlap\n",
    "                if iou_tmp <= 0:\n",
    "                    m += 1\n",
    "                    continue\n",
    "\n",
    "                if abs(iou_tmp - iou_target) <= iou_best:\n",
    "                    iou_best = abs(iou_tmp - iou_target)\n",
    "                    m += 1\n",
    "                else:\n",
    "                    break\n",
    "            if h < w:\n",
    "                n_w = m\n",
    "            else:\n",
    "                n_h = m\n",
    "\n",
    "        for i in range(self.level_n):\n",
    "            region_width = int(2 * 1.0 / (i + 2) * min(h, w))\n",
    "            step_size_h = (h - region_width) // n_h\n",
    "            step_size_w = (w - region_width) // n_w\n",
    "\n",
    "            for x in range(n_h):\n",
    "                for y in range(n_w):\n",
    "                    st_x = step_size_h * x\n",
    "                    ed_x = st_x + region_width - 1\n",
    "                    assert ed_x < h\n",
    "                    st_y = step_size_w * y\n",
    "                    ed_y = st_y + region_width - 1\n",
    "                    assert ed_y < w\n",
    "                    regions.append((st_x, st_y, ed_x, ed_y))\n",
    "\n",
    "            n_h += 1\n",
    "            n_w += 1\n",
    "\n",
    "        self.cached_regions[(h, w)] = regions\n",
    "        return regions\n",
    "\n",
    "    def forward(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            h, w = fea.shape[2:]       \n",
    "            regions = self._get_regions(h, w)\n",
    "            for _, r in enumerate(regions):\n",
    "                st_x, st_y, ed_x, ed_y = r\n",
    "                region_fea = (fea[:, :, st_x: ed_x, st_y: ed_y].max(dim=3)[0]).max(dim=2)[0]#max-pooling\n",
    "                region_fea = region_fea / torch.norm(region_fea, dim=1, keepdim=True)#PCA-whitening\n",
    "                if final_fea is None:\n",
    "                    final_fea = region_fea\n",
    "                else:\n",
    "                    final_fea = final_fea + region_fea\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[RMAC Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "        return final_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        #x = avg_out*max_out\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class NNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks=[2,2,2,2], code_size=5):\n",
    "        super(NNet, self).__init__()\n",
    "        # Bottom-up layers，classifcation loss\n",
    "        self.in_planes = 8  #3 D->64 channels\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        #residual blocks\n",
    "        self.layer2 = self._make_layer(block, 8, num_blocks[0], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 32, num_blocks[2], stride=1)\n",
    "        self.layer5 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        #attention+R-MAC\n",
    "        self.conv2 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.sa = SpatialAttention() #spatial-attention\n",
    "        self.r_mac_pool = RMAC(level_n=3) \n",
    "        self.l2norm = L2Normalization()\n",
    "        #code_size: bits of hash code or classes\n",
    "        self.fc1 = nn.Linear(512*16*16, code_size) \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _upsample_add(self, x, y):\n",
    "        '''Upsample and add two feature maps.\n",
    "        Args:\n",
    "          x: (Variable) top feature map to be upsampled.\n",
    "          y: (Variable) lateral feature map.\n",
    "        Returns:\n",
    "          (Variable) added feature map.\n",
    "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
    "        with `F.upsample(..., scale_factor=2, mode='nearest')`\n",
    "        maybe not equal to the lateral feature map size.\n",
    "        e.g.\n",
    "        original input size: [N,_,15,15] ->\n",
    "        conv2d feature map size: [N,_,8,8] ->\n",
    "        upsampled feature map size: [N,_,16,16]\n",
    "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
    "        '''\n",
    "        _,_,H,W = y.size()\n",
    "        return F.upsample(x, size=(H,W), mode='bilinear') + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bottom-up, classifcation loss\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))#(3,256,256)->(8,128,128)\n",
    "        x1 = F.max_pool2d(x1, kernel_size=3, stride=2, padding=1)#(8,128,128)->(8,64,64)\n",
    "        \n",
    "        x2 = self.layer2(x1)#(8,64,64)->(32,64,64)\n",
    "        x3 = self.layer3(x2)#(32,64,64)->(64,32,32)\n",
    "        x4 = self.layer4(x3)#(64,32,32)->(128,16,16)\n",
    "        x5 = self.layer5(x4)#(128,16,16)->(256,8,8)\n",
    "        \n",
    "        #Hash, ranking loss\n",
    "        x6 = self.conv2(x5)#(256,8,8)->(512,8,8)\n",
    "        x7 = self.sa(x6)*x6#(512,8,8)->(512,8,8)\n",
    "        #x8 = self.r_mac_pool(x7) \n",
    "        #x8 = self.l2norm(x8) #512\n",
    "        \n",
    "        x8 = x7.view(x7.size(0),-1)\n",
    "        feat = self.fc1(x8)\n",
    "        return feat\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "net = NNet(block=Bottleneck)\n",
    "fms = net(Variable(torch.randn(1,3,256,256)))\n",
    "for fm in fms:\n",
    "    print(fm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3162 / 3162 : loss = 3.078689Eopch:     1 mean_loss = 3.655127\n",
      " 3162 / 3162 : loss = 2.819617Eopch:     2 mean_loss = 3.280059\n",
      " 3162 / 3162 : loss = 2.032035Eopch:     3 mean_loss = 2.892059\n",
      " 3162 / 3162 : loss = 1.203855Eopch:     4 mean_loss = 2.308646\n",
      " 3162 / 3162 : loss = 1.180685Eopch:     5 mean_loss = 1.722709\n",
      " 3162 / 3162 : loss = 0.802653Eopch:     6 mean_loss = 1.271809\n",
      " 3162 / 3162 : loss = 0.831619Eopch:     7 mean_loss = 0.943923\n",
      " 3162 / 3162 : loss = 0.084877Eopch:     8 mean_loss = 0.753168\n",
      " 3162 / 3162 : loss = 0.596839Eopch:     9 mean_loss = 0.615420\n",
      " 3162 / 3162 : loss = 0.231338Eopch:    10 mean_loss = 0.525177\n",
      " 3162 / 3162 : loss = 0.059364Eopch:    11 mean_loss = 0.445723\n",
      " 3162 / 3162 : loss = 0.015173Eopch:    12 mean_loss = 0.396761\n",
      " 3162 / 3162 : loss = 0.054097Eopch:    13 mean_loss = 0.351930\n",
      " 3162 / 3162 : loss = 0.046997Eopch:    14 mean_loss = 0.325794\n",
      " 3162 / 3162 : loss = 0.006061Eopch:    15 mean_loss = 0.300368\n",
      " 3162 / 3162 : loss = 0.040487Eopch:    16 mean_loss = 0.273957\n",
      " 3162 / 3162 : loss = 0.009451Eopch:    17 mean_loss = 0.250404\n",
      " 3162 / 3162 : loss = 0.007111Eopch:    18 mean_loss = 0.238876\n",
      " 3162 / 3162 : loss = 0.007381Eopch:    19 mean_loss = 0.258610\n",
      " 3162 / 3162 : loss = 0.004633Eopch:    20 mean_loss = 0.193753\n",
      "best_loss = 0.193753\n",
      " 351 / 352 Accuracy: 0.634216\n",
      "[[2087  165  277   33   12]\n",
      " [ 192   15   34    4    2]\n",
      " [ 370   40  110    9   12]\n",
      " [  45    3   17    7    5]\n",
      " [  43    1   15    6    9]]\n",
      "Specificity of No DR: 0.810800\n",
      "Sensitivity of Mild DR: 0.060729\n",
      "Sensitivity of Moderate DR: 0.203327\n",
      "Sensitivity of Severe DR: 0.090909\n",
      "Sensitivity of Proliferative DR: 0.121622\n"
     ]
    }
   ],
   "source": [
    "#sample  triplet labels\n",
    "#trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = NNet(block=Bottleneck).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes #F.log_softmax+F.nll_loss\n",
    "#mse_loss  = nn.MSELoss().cuda() #define mseloss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "#trI_t = np.array(trI)\n",
    "#trY_t = np.array(trY)\n",
    "for epoch in range(20):#iteration\n",
    "    losses = []\n",
    "    #shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    #train_q = trQ_sf[shuffled_idx]\n",
    "    #train_q_y = trQ_y[shuffled_idx]\n",
    "    #train_p = trP_sf[shuffled_idx]\n",
    "    #train_p_y = trP_y[shuffled_idx]\n",
    "    #train_n = trN_sf[shuffled_idx]\n",
    "    #train_n_y = trN_y[shuffled_idx]\n",
    "    num_batches = len(trQ_y) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_y), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(trQ_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(trQ_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(trP_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(trP_y[min_idx:max_idx]).type(torch.LongTensor).cuda()      \n",
    "        N_batch = torch.from_numpy(trN_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(trN_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_feat = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_feat = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_feat = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #I_batch = torch.from_numpy(trI_t[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #y_batch = torch.from_numpy(trY_t[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #I_feat = model(I_batch.permute(0, 3, 1, 2))\n",
    "        #loss\n",
    "        \n",
    "        loss = ce_loss(Q_feat,Q_y_batch) + ce_loss(P_feat,P_y_batch) +  ce_loss(N_feat,N_y_batch)\n",
    "        loss.backward() \n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#predicting\n",
    "teY_pred = []\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_feat = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    x_feat = F.log_softmax(x_feat,dim=1) \n",
    "    y_pred = x_feat.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(y_pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#classification performance\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))#performance of classification\n",
    "labels = list(set(teY))\n",
    "#0 - No DR,1 - Mild,2 - Moderate,3 - Severe,4 - Proliferative DR\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) \n",
    "print (cm)\n",
    "print ('Specificity of No DR: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Mild DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Moderate DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Severe DR: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Proliferative DR: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ATH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATH model with Tripet loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        #x = torch.cat([avg_out, max_out], dim=1)\n",
    "        #x = self.conv1(x)\n",
    "        x = avg_out*max_out\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, type_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.hashlayer = nn.Linear(1*32*32, hash_size)\n",
    "        self.typelayer = nn.Linear(1*32*32, type_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hashlayer(x)\n",
    "        x_type = self.typelayer(x)\n",
    "        return x_hash, x_type\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3162 / 3162 : loss = 22.745653Eopch:     1 mean_loss = 21.510958\n",
      " 3162 / 3162 : loss = 22.383627Eopch:     2 mean_loss = 21.451411\n",
      " 3162 / 3162 : loss = 24.110266Eopch:     3 mean_loss = 21.299927\n",
      " 3162 / 3162 : loss = 21.224382Eopch:     4 mean_loss = 21.242353\n",
      " 3162 / 3162 : loss = 24.726742Eopch:     5 mean_loss = 21.062715\n",
      " 3162 / 3162 : loss = 23.904427Eopch:     6 mean_loss = 20.814984\n",
      " 3162 / 3162 : loss = 22.468147Eopch:     7 mean_loss = 20.584147\n",
      " 3162 / 3162 : loss = 20.771657Eopch:     8 mean_loss = 20.404425\n",
      " 3162 / 3162 : loss = 16.048782Eopch:     9 mean_loss = 20.161052\n",
      " 3162 / 3162 : loss = 11.542614Eopch:    10 mean_loss = 19.877010\n",
      "best_loss = 19.877010\n",
      " 351 / 352 2 Completed buliding index in 1 seconds\n",
      "mAP@5=0.4939\n",
      "mAP@10=0.4666\n",
      "mAP@20=0.4474\n",
      "mAP@50=0.4322\n",
      "Accuracy: 0.681184\n",
      "[[2337    7  216   11    3]\n",
      " [ 225    2   20    0    0]\n",
      " [ 483    3   53    2    0]\n",
      " [  63    1   13    0    0]\n",
      " [  53    3   15    2    1]]\n",
      "Specificity of No DR: 0.907925\n",
      "Sensitivity of Mild DR: 0.008097\n",
      "Sensitivity of Moderate DR: 0.097967\n",
      "Sensitivity of Severe DR: 0.000000\n",
      "Sensitivity of Proliferative DR: 0.013514\n"
     ]
    }
   ],
   "source": [
    "#sample  triplet labels\n",
    "#trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    #shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    #train_q = trQ_sf[shuffled_idx]\n",
    "    #train_q_y = trQ_y[shuffled_idx]\n",
    "    #train_p = trP_sf[shuffled_idx]\n",
    "    #train_p_y = trP_y[shuffled_idx]\n",
    "    #train_n = trN_sf[shuffled_idx]\n",
    "    #train_n_y = trN_y[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(train_q_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(train_p_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(train_n_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, Q_type = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, P_type = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, N_type = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss\n",
    "        hash_loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        type_loss = ce_loss(Q_type,Q_y_batch) + ce_loss(P_type,P_y_batch) + ce_loss(N_type,N_y_batch) #F.log_softmax+F.nll_loss\n",
    "        loss = hash_loss+type_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "\n",
    "#hash code of train data from model\n",
    "#trainset\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1 \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "#testset\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5,10,20,50]:#performance of retrieval\n",
    "    mAP = [] #mean average precision\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "    print(\"mAP@{}={:.4f}\".format(topk, np.mean(mAP)))\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))#performance of classification\n",
    "labels = list(set(teY))\n",
    "#0 - No DR,1 - Mild,2 - Moderate,3 - Severe,4 - Proliferative DR\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) \n",
    "print (cm)\n",
    "print ('Specificity of No DR: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Mild DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Moderate DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Severe DR: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Proliferative DR: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ASH Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        #x = torch.cat([avg_out, max_out], dim=1)\n",
    "        #x = self.conv1(x)\n",
    "        x = avg_out*max_out\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHResNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=8, stride=2), #(3,256,256)->(6,128,128)\n",
    "            ResBlock(in_channels=8, out_channels=16, stride=2),#(6,128,128)->(16,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=32, stride=2),#(16,64,64)->(32,32,32)\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.linear = nn.Linear(32*32*32, code_size)\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "    \n",
    "class PairwiseLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs(spls=len(trY)):\n",
    "    idx_sf = random.sample(range(0, len(trY)),spls-1)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1581 / 1581 : loss = 0.0163552Eopch:     1 mean_loss = 7.010426\n",
      " 1581 / 1581 : loss = 0.0082832Eopch:     2 mean_loss = 6.955029\n",
      " 1581 / 1581 : loss = 0.0018359Eopch:     3 mean_loss = 6.954692\n",
      " 1581 / 1581 : loss = 0.0007095Eopch:     4 mean_loss = 6.953930\n",
      " 1581 / 1581 : loss = 0.0006333Eopch:     5 mean_loss = 6.952892\n",
      " 1581 / 1581 : loss = 0.0001684Eopch:     6 mean_loss = 6.952832\n",
      " 1581 / 1581 : loss = 0.0009243Eopch:     7 mean_loss = 6.980902\n",
      " 1581 / 1581 : loss = 0.0004695Eopch:     8 mean_loss = 6.952910\n",
      " 1581 / 1581 : loss = 0.0002366Eopch:     9 mean_loss = 6.952799\n",
      " 1581 / 1581 : loss = 0.0001839Eopch:    10 mean_loss = 6.952826\n",
      "best_loss = 6.952799\n",
      " 351 / 352 2 Completed buliding index in 2 seconds\n",
      "mAP@5=0.4783\n",
      "mAP@10=0.4536\n",
      "mAP@20=0.4350\n",
      "mAP@50=0.4192\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = ASHResNet(code_size=64).cuda()\n",
    "criterion  = PairwiseLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "num_batches = len(trY_sf) // batchSize + 1\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    for i in range(num_batches): \n",
    "        optimizer.zero_grad() #grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)#binary-like loss\n",
    "        loss.backward()#backward       \n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()#release gpu memory\n",
    "\n",
    "#feature extraction\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []#train\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    trF.extend(x_hash.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "teF = [] #test\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#model evaluation\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(64) # buliding index of trainset\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#retrieval performance\n",
    "for topk in [5,10,20,50]:\n",
    "    mAP = [] #mean average precision\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "    print(\"mAP@{}={:.4f}\".format(topk, np.mean(mAP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()#release gpu memory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------split line--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'level']\n",
      "(35126, 2)\n",
      "0    25810\n",
      "2     5292\n",
      "1     2443\n",
      "3      873\n",
      "4      708\n",
      "Name: level, dtype: int64\n",
      "(31613, 2)\n",
      "0    23236\n",
      "2     4751\n",
      "1     2196\n",
      "3      796\n",
      "4      634\n",
      "Name: level, dtype: int64\n",
      "(3513, 2)\n",
      "0    2574\n",
      "2     541\n",
      "1     247\n",
      "3      77\n",
      "4      74\n",
      "Name: level, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate training set and test set.\n",
    "dataset = pd.read_csv(\"/data/fjsdata/fundus/kaggle_DR/trainLabels.csv\" , sep=',')#load dataset\n",
    "print(dataset.columns.values.tolist())\n",
    "print (dataset.shape)\n",
    "print (dataset['level'].value_counts())\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['image'], dataset['level'], test_size=0.10, random_state=42)\n",
    "trainset =  pd.concat([X_train, y_train],axis=1)#column\n",
    "print(trainset.shape)\n",
    "print (trainset['level'].value_counts())\n",
    "testset = pd.concat([X_test, y_test],axis=1)#column\n",
    "print(testset.shape)\n",
    "print (testset['level'].value_counts())\n",
    "pd.DataFrame(trainset).to_csv('/data/fjsdata/fundus/kaggle_DR/CBIR_train.csv',index=False)\n",
    "pd.DataFrame(testset).to_csv('/data/fjsdata/fundus/kaggle_DR/CBIR_test.csv',index=False)\n",
    "del dataset,trainset,testset\n",
    "gc.collect() #release cpu memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
